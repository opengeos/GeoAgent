{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"GeoAgent","text":"<p>An AI agent for geospatial data analysis and visualization.</p> <ul> <li>Documentation: https://geoagent.gishub.org</li> <li>Source code: https://github.com/opengeos/GeoAgent</li> <li>PyPI: https://pypi.python.org/pypi/geoagent</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Natural language interface for geospatial data workflows</li> <li>4-agent LangGraph pipeline: Planner, Data, Analysis, Visualization</li> <li>Multi-LLM support (OpenAI, Anthropic, Google Gemini, Ollama)</li> <li>Multi-catalog STAC search (Earth Search, Planetary Computer, USGS, NASA CMR)</li> <li>Code transparency showing generated Python code at each step</li> <li>Jupyter-native with interactive MapLibre maps via leafmap</li> <li>DuckDB spatial SQL for GeoParquet and Overture Maps</li> <li>Raster analysis with xarray, rioxarray, and rasterio</li> <li>Vector operations with geopandas</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install geoagent\n</code></pre> <p>With all optional dependencies:</p> <pre><code>pip install \"geoagent[all]\"\n</code></pre>"},{"location":"#llm-setup","title":"LLM Setup","text":"<p>GeoAgent supports multiple LLM providers. You need at least one configured to use the agent.</p>"},{"location":"#supported-providers","title":"Supported Providers","text":"Provider Default Model API Key Env Variable Install Extra OpenAI <code>gpt-4.1</code> <code>OPENAI_API_KEY</code> (included) Anthropic <code>claude-sonnet-4-5-20250929</code> <code>ANTHROPIC_API_KEY</code> <code>pip install \"geoagent[llm]\"</code> Google Gemini <code>gemini-2.5-flash</code> <code>GOOGLE_API_KEY</code> <code>pip install \"geoagent[llm]\"</code> Ollama (local) <code>llama3.1</code> (none needed) <code>pip install \"geoagent[ollama]\"</code>"},{"location":"#setting-api-keys","title":"Setting API Keys","text":"<p>Set your API key as an environment variable:</p> <pre><code># OpenAI (included by default)\nexport OPENAI_API_KEY=\"your-openai-key\"\n\n# Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-key\"\n\n# Google Gemini\nexport GOOGLE_API_KEY=\"your-google-key\"\n</code></pre> <p>You can also add these to a <code>.env</code> file or your shell profile (<code>~/.bashrc</code>, <code>~/.zshrc</code>).</p>"},{"location":"#choosing-a-provider","title":"Choosing a Provider","text":"<p>By default, GeoAgent auto-detects available providers by checking environment variables in order: OpenAI \u2192 Anthropic \u2192 Google \u2192 Ollama. The first available provider is used.</p> <p>To specify a provider and model explicitly:</p> <pre><code>from geoagent import GeoAgent\n\n# Use the default provider (auto-detected)\nagent = GeoAgent()\n\n# Use a specific provider\nagent = GeoAgent(provider=\"anthropic\")\n\n# Use a specific provider and model\nagent = GeoAgent(provider=\"openai\", model=\"gpt-4o-mini\")\nagent = GeoAgent(provider=\"google\", model=\"gemini-2.5-flash\")\n</code></pre>"},{"location":"#using-ollama-local-llms","title":"Using Ollama (Local LLMs)","text":"<p>To run GeoAgent with a local LLM via Ollama, no API key is needed:</p> <pre><code># Install Ollama and pull a model\nollama pull llama3.1\n\n# Install the Ollama extra\npip install \"geoagent[ollama]\"\n</code></pre> <pre><code>agent = GeoAgent(provider=\"ollama\", model=\"llama3.1\")\n</code></pre>"},{"location":"#using-a-custom-llm-instance","title":"Using a Custom LLM Instance","text":"<p>You can pass any LangChain-compatible chat model directly:</p> <pre><code>from langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\nagent = GeoAgent(llm=llm)\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from geoagent import GeoAgent\n\nagent = GeoAgent()\nresult = agent.chat(\"Show NDVI for San Francisco in July 2024\")\nresult.map   # displays interactive map in Jupyter\nprint(result.code)  # shows the generated Python code\n</code></pre>"},{"location":"#web-ui","title":"Web UI","text":"<p>GeoAgent includes a Solara-based chat interface with a persistent, interactive map.</p> <pre><code>pip install \"geoagent[ui]\"\ngeoagent ui\n</code></pre> <p>The UI opens on a home page \u2014 click Chat to start querying. See Web UI for full details.</p>"},{"location":"#architecture","title":"Architecture","text":"<p>GeoAgent uses a 4-agent pipeline orchestrated by LangGraph:</p> <ol> <li>Planner parses natural language into structured parameters</li> <li>Data Agent searches STAC catalogs and retrieves geospatial data</li> <li>Analysis Agent computes indices and statistics with transparent code generation</li> <li>Visualization Agent renders results on interactive leafmap MapLibre maps</li> </ol>"},{"location":"#license","title":"License","text":"<p>MIT</p>"},{"location":"analysis_agent/","title":"Analysis Agent","text":"<p>The Analysis Agent performs geospatial analysis with transparent, reproducible code generation.</p>"},{"location":"analysis_agent/#geoagent.core.analysis_agent","title":"<code>geoagent.core.analysis_agent</code>","text":"<p>Analysis Agent for performing geospatial analysis operations.</p> <p>The Analysis Agent takes data references and performs various geospatial analyses while generating transparent Python code for reproducibility.</p>"},{"location":"analysis_agent/#geoagent.core.analysis_agent.AnalysisAgent","title":"<code> AnalysisAgent        </code>","text":"<p>Agent responsible for geospatial analysis operations.</p> <p>The Analysis Agent performs raster and vector analysis operations and generates Python code showing exactly what was computed.</p> Source code in <code>geoagent/core/analysis_agent.py</code> <pre><code>class AnalysisAgent:\n    \"\"\"Agent responsible for geospatial analysis operations.\n\n    The Analysis Agent performs raster and vector analysis operations\n    and generates Python code showing exactly what was computed.\n    \"\"\"\n\n    def __init__(self, llm: Any, tools: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the Analysis Agent.\n\n        Args:\n            llm: Language model instance for analysis planning\n            tools: Dictionary of available analysis tools (raster, vector, etc.)\n        \"\"\"\n        self.llm = llm\n        self.tools = tools or {}\n        self._setup_tools()\n\n    def _setup_tools(self):\n        \"\"\"Setup and initialize analysis tools.\"\"\"\n        try:\n            # TODO: Import and register RasterAnalysisTool and VectorAnalysisTool\n            # once the tool implementations are finalized.\n\n            logger.info(\"Analysis tools setup (using placeholders)\")\n\n        except ImportError as e:\n            logger.warning(f\"Some analysis tools not available: {e}\")\n            # Graceful fallback - tools will be added when available\n\n    def analyze(self, plan: PlannerOutput, data: DataResult) -&gt; AnalysisResult:\n        \"\"\"Perform analysis on the provided data.\n\n        Args:\n            plan: Original query plan with analysis intent\n            data: Data retrieved by the Data Agent\n\n        Returns:\n            AnalysisResult with computed results and generated code\n        \"\"\"\n        logger.info(f\"Starting analysis for intent: {plan.intent}\")\n\n        try:\n            # Determine analysis type based on intent and data type\n            analysis_type = self._determine_analysis_type(plan, data)\n\n            if analysis_type == \"land_cover\":\n                return self._handle_land_cover(plan, data)\n            elif analysis_type == \"elevation\":\n                return self._handle_elevation(plan, data)\n            elif analysis_type == \"spectral_index\":\n                return self._compute_spectral_index(plan, data)\n            elif analysis_type == \"zonal_statistics\":\n                return self._compute_zonal_statistics(plan, data)\n            elif analysis_type == \"time_series\":\n                return self._compute_time_series(plan, data)\n            elif analysis_type == \"change_detection\":\n                return self._compute_change_detection(plan, data)\n            elif analysis_type == \"vector_analysis\":\n                return self._perform_vector_analysis(plan, data)\n            else:\n                return self._perform_general_analysis(plan, data)\n\n        except Exception as e:\n            logger.error(f\"Analysis failed: {e}\")\n            return AnalysisResult(\n                result_data={\"error\": str(e)},\n                code_generated=f\"# Analysis failed: {e}\",\n                success=False,\n                error_message=str(e),\n            )\n\n    def _determine_analysis_type(self, plan: PlannerOutput, data: DataResult) -&gt; str:\n        \"\"\"Determine the type of analysis to perform.\n\n        Args:\n            plan: Query plan with intent\n            data: Available data\n\n        Returns:\n            Analysis type string\n        \"\"\"\n        intent = plan.intent.lower()\n        analysis_type_hint = (plan.analysis_type or \"\").lower()\n\n        # Check plan.analysis_type first (most reliable signal from planner)\n        if analysis_type_hint in (\"land_cover\", \"classification\", \"lulc\"):\n            return \"land_cover\"\n        if analysis_type_hint in (\"elevation\", \"dem\", \"terrain\", \"slope\", \"hillshade\"):\n            return \"elevation\"\n        if analysis_type_hint in (\"ndvi\", \"evi\", \"savi\", \"ndbi\", \"ndwi\", \"mndwi\"):\n            return \"spectral_index\"\n\n        # Land cover analysis (from intent keywords)\n        if any(\n            term in intent\n            for term in [\n                \"land_cover\",\n                \"land cover\",\n                \"landcover\",\n                \"lulc\",\n                \"land use\",\n                \"classification\",\n            ]\n        ):\n            return \"land_cover\"\n\n        # DEM / elevation analysis (from intent keywords)\n        if any(\n            term in intent\n            for term in [\n                \"dem\",\n                \"elevation\",\n                \"terrain\",\n                \"slope\",\n                \"hillshade\",\n                \"topograph\",\n            ]\n        ):\n            return \"elevation\"\n\n        # Spectral index analysis\n        if any(\n            index in intent\n            for index in [\"ndvi\", \"evi\", \"savi\", \"ndbi\", \"spectral\", \"index\"]\n        ):\n            return \"spectral_index\"\n\n        # Zonal statistics\n        if any(\n            term in intent\n            for term in [\"zonal\", \"statistics\", \"mean\", \"median\", \"sum\", \"aggregate\"]\n        ):\n            return \"zonal_statistics\"\n\n        # Time series analysis\n        if any(\n            term in intent\n            for term in [\"time series\", \"temporal\", \"trend\", \"change over time\"]\n        ):\n            return \"time_series\"\n\n        # Change detection\n        if any(\n            term in intent\n            for term in [\"change\", \"detection\", \"difference\", \"before\", \"after\"]\n        ):\n            return \"change_detection\"\n\n        # Vector operations\n        if data.data_type == \"vector\" or any(\n            term in intent for term in [\"buffer\", \"intersect\", \"union\", \"clip\"]\n        ):\n            return \"vector_analysis\"\n\n        return \"general\"\n\n    def _compute_spectral_index(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Compute spectral indices from satellite imagery.\n\n        Args:\n            plan: Query plan with index specifications\n            data: Satellite imagery data\n\n        Returns:\n            AnalysisResult with computed indices\n        \"\"\"\n        intent = plan.intent.lower()\n\n        # Determine which index to compute\n        if \"ndvi\" in intent:\n            index_type = \"ndvi\"\n        elif \"evi\" in intent:\n            index_type = \"evi\"\n        elif \"savi\" in intent:\n            index_type = \"savi\"\n        else:\n            index_type = \"ndvi\"  # Default\n\n        # Try real computation first\n        if index_type == \"ndvi\" and data.items:\n            try:\n                return self._compute_ndvi_real(plan, data)\n            except Exception as e:\n                logger.warning(f\"Real NDVI computation failed: {e}\")\n\n        # Fall back to mock if real computation fails\n        return self._create_mock_analysis(index_type, data)\n\n    def _compute_ndvi_real(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Actually compute NDVI from STAC item COG bands.\n\n        Uses rasterio to read red/NIR bands and compute NDVI,\n        then saves result as a temporary GeoTIFF for visualization.\n        \"\"\"\n        import numpy as np\n        import rasterio\n        from rasterio.windows import from_bounds\n\n        # Find first item with red and nir bands\n        # Planetary Computer uses B04 (red) and B08 (NIR); other catalogs use\n        # lowercase \"red\"/\"nir\"\n        RED_KEYS = [\"red\", \"B04\", \"b04\", \"Red\"]\n        NIR_KEYS = [\"nir\", \"B08\", \"b08\", \"Nir\", \"NIR\"]\n\n        item = None\n        red_key = None\n        nir_key = None\n        for candidate in data.items:\n            assets = candidate.get(\"assets\", {})\n            found_red = next((k for k in RED_KEYS if k in assets), None)\n            found_nir = next((k for k in NIR_KEYS if k in assets), None)\n            if found_red and found_nir:\n                red_href = assets[found_red].get(\"href\", \"\")\n                nir_href = assets[found_nir].get(\"href\", \"\")\n                if red_href.startswith(\"http\") and nir_href.startswith(\"http\"):\n                    item = candidate\n                    red_key = found_red\n                    nir_key = found_nir\n                    break\n\n        if item is None:\n            raise ValueError(\"No STAC item found with red and nir COG bands\")\n\n        red_url = item[\"assets\"][red_key][\"href\"]\n        nir_url = item[\"assets\"][nir_key][\"href\"]\n        item_id = item.get(\"id\", \"unknown\")\n\n        logger.info(f\"Computing NDVI for item {item_id}\")\n\n        # Read within bbox if available (windowed read for performance)\n        bbox_wgs84 = None\n        if plan.location and \"bbox\" in plan.location:\n            bbox_wgs84 = plan.location[\"bbox\"]\n\n        with rasterio.open(red_url) as red_src:\n            if bbox_wgs84:\n                # Transform bbox from WGS84 to raster CRS if needed\n                from pyproj import Transformer\n\n                raster_crs = red_src.crs\n                if raster_crs and str(raster_crs) != \"EPSG:4326\":\n                    transformer = Transformer.from_crs(\n                        \"EPSG:4326\", raster_crs, always_xy=True\n                    )\n                    x_min, y_min = transformer.transform(bbox_wgs84[0], bbox_wgs84[1])\n                    x_max, y_max = transformer.transform(bbox_wgs84[2], bbox_wgs84[3])\n                    bbox_native = [x_min, y_min, x_max, y_max]\n                else:\n                    bbox_native = bbox_wgs84\n\n                window = from_bounds(*bbox_native, red_src.transform)\n                # Ensure window has positive dimensions\n                window = window.round_offsets().round_lengths()\n                if window.width &lt; 1 or window.height &lt; 1:\n                    raise ValueError(\"Bbox too small for raster resolution\")\n                red = red_src.read(1, window=window).astype(\"float32\")\n                win_transform = red_src.window_transform(window)\n            else:\n                red = red_src.read(1).astype(\"float32\")\n                win_transform = red_src.transform\n                window = None\n            red_profile = red_src.profile.copy()\n\n        with rasterio.open(nir_url) as nir_src:\n            if window is not None:\n                nir = nir_src.read(1, window=window).astype(\"float32\")\n            else:\n                nir = nir_src.read(1).astype(\"float32\")\n\n        # Compute NDVI\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            ndvi = (nir - red) / (nir + red)\n            ndvi = np.where(np.isfinite(ndvi), ndvi, np.nan)\n\n        # Compute statistics\n        valid = ndvi[np.isfinite(ndvi)]\n        stats = {\n            \"mean\": float(np.nanmean(valid)) if len(valid) &gt; 0 else None,\n            \"min\": float(np.nanmin(valid)) if len(valid) &gt; 0 else None,\n            \"max\": float(np.nanmax(valid)) if len(valid) &gt; 0 else None,\n            \"std\": float(np.nanstd(valid)) if len(valid) &gt; 0 else None,\n            \"pixels\": int(len(valid)),\n        }\n\n        # Save NDVI as temporary GeoTIFF\n        ndvi_path = os.path.join(tempfile.gettempdir(), f\"ndvi_{item_id}.tif\")\n        out_profile = red_profile.copy()\n        out_profile.update(\n            dtype=\"float32\",\n            count=1,\n            driver=\"GTiff\",\n            compress=\"deflate\",\n            height=ndvi.shape[0],\n            width=ndvi.shape[1],\n            transform=win_transform,\n            nodata=np.nan,\n        )\n        with rasterio.open(ndvi_path, \"w\", **out_profile) as dst:\n            dst.write(ndvi, 1)\n\n        logger.info(f\"NDVI saved to {ndvi_path}, mean={stats['mean']:.3f}\")\n\n        # Generate reproducible code\n        code = f\"\"\"import os\nimport rasterio\nimport numpy as np\nfrom rasterio.windows import from_bounds\nfrom pyproj import Transformer\n\nos.environ[\"AWS_NO_SIGN_REQUEST\"] = \"YES\"\n\nred_url = \"{red_url}\"\nnir_url = \"{nir_url}\"\nbbox_wgs84 = {bbox_wgs84}  # [west, south, east, north] in EPSG:4326\n\n# Read red and NIR bands (windowed read within bbox)\nwith rasterio.open(red_url) as red_src:\n    # Transform bbox to raster CRS\n    transformer = Transformer.from_crs(\"EPSG:4326\", red_src.crs, always_xy=True)\n    x_min, y_min = transformer.transform(bbox_wgs84[0], bbox_wgs84[1])\n    x_max, y_max = transformer.transform(bbox_wgs84[2], bbox_wgs84[3])\n    window = from_bounds(x_min, y_min, x_max, y_max, red_src.transform)\n    red = red_src.read(1, window=window).astype(\"float32\")\n    profile = red_src.profile.copy()\n    transform = red_src.window_transform(window)\n\nwith rasterio.open(nir_url) as nir_src:\n    nir = nir_src.read(1, window=window).astype(\"float32\")\n\n# Compute NDVI = (NIR - Red) / (NIR + Red)\nndvi = (nir - red) / (nir + red)\nndvi = np.where(np.isfinite(ndvi), ndvi, np.nan)\n\nprint(f\"NDVI shape: {{ndvi.shape}}\")\nprint(f\"NDVI range: {{np.nanmin(ndvi):.3f}} to {{np.nanmax(ndvi):.3f}}\")\nprint(f\"NDVI mean: {{np.nanmean(ndvi):.3f}}\")\n\"\"\"\n\n        result_data = {\n            \"analysis_type\": \"ndvi\",\n            \"item_id\": item_id,\n            \"ndvi_stats\": stats,\n            \"ndvi_path\": ndvi_path,\n        }\n\n        viz_hints = {\n            \"type\": \"ndvi\",\n            \"ndvi_path\": ndvi_path,\n            \"colormap\": \"RdYlGn\",\n            \"vmin\": -0.2,\n            \"vmax\": 0.8,\n            \"title\": f\"NDVI - {item_id}\",\n        }\n\n        return AnalysisResult(\n            result_data=result_data,\n            code_generated=code,\n            visualization_hints=viz_hints,\n        )\n\n    def _handle_land_cover(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Handle land cover data - passthrough with appropriate viz hints.\n\n        Args:\n            plan: Query plan\n            data: Land cover data from STAC\n\n        Returns:\n            AnalysisResult with land cover viz configuration\n        \"\"\"\n        location_name = \"\"\n        if plan.location:\n            location_name = plan.location.get(\"name\", \"\")\n\n        result_data = {\n            \"analysis_type\": \"land_cover\",\n            \"data_type\": \"categorical\",\n            \"items_found\": data.total_items,\n            \"collection\": (data.items[0].get(\"collection\", \"\") if data.items else \"\"),\n        }\n\n        bbox = plan.location.get(\"bbox\") if plan.location else None\n        code = f\"\"\"import planetary_computer\nimport leafmap.maplibregl as leafmap\nfrom pystac_client import Client\n\n# Search for land cover data - {location_name}\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\nsearch = catalog.search(\n    collections=[\"io-lulc-9-class\"],\n    bbox={bbox},\n    max_items=1,\n)\n\nitems = list(search.items())\nprint(f\"Found {{len(items)}} land cover items\")\n\n# Visualize\nm = leafmap.Map()\nif items:\n    item = items[0]\n    m.add_stac_layer(\n        collection=\"io-lulc-9-class\",\n        item=item.id,\n        assets=[\"data\"],\n        titiler_endpoint=\"planetary-computer\",\n        name=\"Land Cover\",\n        fit_bounds=True,\n    )\nm\n\"\"\"\n\n        viz_hints = {\n            \"type\": \"land_cover\",\n            \"asset_key\": \"data\",\n            \"title\": f\"Land Cover - {location_name}\" if location_name else \"Land Cover\",\n        }\n\n        return AnalysisResult(\n            result_data=result_data,\n            code_generated=code,\n            visualization_hints=viz_hints,\n        )\n\n    def _handle_elevation(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Handle DEM/elevation data - passthrough with appropriate viz hints.\n\n        Args:\n            plan: Query plan\n            data: DEM data from STAC\n\n        Returns:\n            AnalysisResult with elevation viz configuration\n        \"\"\"\n        location_name = \"\"\n        if plan.location:\n            location_name = plan.location.get(\"name\", \"\")\n\n        result_data = {\n            \"analysis_type\": \"elevation\",\n            \"data_type\": \"continuous\",\n            \"items_found\": data.total_items,\n            \"collection\": (data.items[0].get(\"collection\", \"\") if data.items else \"\"),\n        }\n\n        bbox = plan.location.get(\"bbox\") if plan.location else None\n        code = f\"\"\"import planetary_computer\nimport leafmap.maplibregl as leafmap\nfrom pystac_client import Client\n\n# Search for DEM data - {location_name}\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\nsearch = catalog.search(\n    collections=[\"cop-dem-glo-30\"],\n    bbox={bbox},\n    max_items=1,\n)\n\nitems = list(search.items())\nprint(f\"Found {{len(items)}} DEM items\")\n\n# Visualize\nm = leafmap.Map()\nif items:\n    item = items[0]\n    m.add_stac_layer(\n        collection=\"cop-dem-glo-30\",\n        item=item.id,\n        assets=[\"data\"],\n        titiler_endpoint=\"planetary-computer\",\n        name=\"Elevation (DEM)\",\n        fit_bounds=True,\n    )\nm\n\"\"\"\n\n        viz_hints = {\n            \"type\": \"elevation\",\n            \"colormap\": \"terrain\",\n            \"asset_key\": \"data\",\n            \"title\": (\n                f\"Elevation (DEM) - {location_name}\"\n                if location_name\n                else \"Elevation (DEM)\"\n            ),\n        }\n\n        return AnalysisResult(\n            result_data=result_data,\n            code_generated=code,\n            visualization_hints=viz_hints,\n        )\n\n    def _compute_zonal_statistics(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Compute zonal statistics for areas of interest.\n\n        Args:\n            plan: Query plan with zones specification\n            data: Raster or vector data\n\n        Returns:\n            AnalysisResult with computed statistics\n        \"\"\"\n        if \"raster\" in self.tools:\n            try:\n                raster_tool = self.tools[\"raster\"]\n\n                # Extract zones from plan parameters or location\n                zones = plan.parameters.get(\"zones\") or plan.location\n\n                result = raster_tool.zonal_statistics(data.items, zones)\n                code = self._generate_zonal_code(data.items, zones)\n\n                viz_hints = {\n                    \"type\": \"choropleth\",\n                    \"color_column\": \"mean\",\n                    \"colormap\": \"viridis\",\n                }\n\n                return AnalysisResult(\n                    result_data=result,\n                    code_generated=code,\n                    visualization_hints=viz_hints,\n                )\n\n            except Exception as e:\n                logger.error(f\"Zonal statistics failed: {e}\")\n                return self._create_mock_analysis(\"zonal\", data)\n        else:\n            return self._create_mock_analysis(\"zonal\", data)\n\n    def _compute_time_series(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Compute time series analysis from temporal data.\n\n        Args:\n            plan: Query plan with temporal specifications\n            data: Time series data\n\n        Returns:\n            AnalysisResult with time series analysis\n        \"\"\"\n        if \"raster\" in self.tools:\n            try:\n                raster_tool = self.tools[\"raster\"]\n\n                # Extract location for time series\n                location = plan.location\n\n                result = raster_tool.time_series_analysis(data.items, location)\n                code = self._generate_timeseries_code(data.items, location)\n\n                viz_hints = {\n                    \"type\": \"time_series\",\n                    \"x_column\": \"date\",\n                    \"y_column\": \"value\",\n                    \"title\": \"Time Series Analysis\",\n                }\n\n                return AnalysisResult(\n                    result_data=result,\n                    code_generated=code,\n                    visualization_hints=viz_hints,\n                )\n\n            except Exception as e:\n                logger.error(f\"Time series analysis failed: {e}\")\n                return self._create_mock_analysis(\"time_series\", data)\n        else:\n            return self._create_mock_analysis(\"time_series\", data)\n\n    def _compute_change_detection(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Perform change detection analysis.\n\n        Args:\n            plan: Query plan with change detection parameters\n            data: Multi-temporal data\n\n        Returns:\n            AnalysisResult with change analysis\n        \"\"\"\n        if \"raster\" in self.tools:\n            try:\n                raster_tool = self.tools[\"raster\"]\n\n                result = raster_tool.change_detection(data.items)\n                code = self._generate_change_code(data.items)\n\n                viz_hints = {\n                    \"type\": \"change_map\",\n                    \"colormap\": \"RdYlBu\",\n                    \"center_zero\": True,\n                }\n\n                return AnalysisResult(\n                    result_data=result,\n                    code_generated=code,\n                    visualization_hints=viz_hints,\n                )\n\n            except Exception as e:\n                logger.error(f\"Change detection failed: {e}\")\n                return self._create_mock_analysis(\"change\", data)\n        else:\n            return self._create_mock_analysis(\"change\", data)\n\n    def _perform_vector_analysis(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Perform vector analysis operations.\n\n        Args:\n            plan: Query plan with vector operations\n            data: Vector data\n\n        Returns:\n            AnalysisResult with vector analysis results\n        \"\"\"\n        if \"vector\" in self.tools:\n            try:\n                vector_tool = self.tools[\"vector\"]\n\n                # Determine vector operation\n                intent = plan.intent.lower()\n                if \"buffer\" in intent:\n                    distance = plan.parameters.get(\"distance\", 1000)\n                    result = vector_tool.buffer(data.items, distance)\n                    code = self._generate_buffer_code(data.items, distance)\n                elif \"intersect\" in intent:\n                    result = vector_tool.intersect(data.items)\n                    code = self._generate_intersect_code(data.items)\n                else:\n                    result = vector_tool.general_analysis(data.items, plan.intent)\n                    code = self._generate_general_vector_code(data.items, plan.intent)\n\n                viz_hints = {\n                    \"type\": \"vector_map\",\n                    \"style\": {\"color\": \"blue\", \"weight\": 2},\n                }\n\n                return AnalysisResult(\n                    result_data=result,\n                    code_generated=code,\n                    visualization_hints=viz_hints,\n                )\n\n            except Exception as e:\n                logger.error(f\"Vector analysis failed: {e}\")\n                return self._create_mock_analysis(\"vector\", data)\n        else:\n            return self._create_mock_analysis(\"vector\", data)\n\n    def _perform_general_analysis(\n        self, plan: PlannerOutput, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Perform general analysis when specific type cannot be determined.\n\n        Args:\n            plan: Query plan\n            data: Available data\n\n        Returns:\n            AnalysisResult with general analysis\n        \"\"\"\n        # Basic data summary\n        result = {\n            \"data_summary\": {\n                \"total_items\": data.total_items,\n                \"data_type\": data.data_type,\n                \"intent\": plan.intent,\n            },\n            \"items_preview\": data.items[:5] if data.items else [],\n        }\n\n        code = f\"\"\"# General analysis for: {plan.intent}\n# Data type: {data.data_type}\n# Total items: {data.total_items}\n\nimport json\ndata_summary = {json.dumps(result, indent=2)}\nprint(\"Analysis Summary:\", data_summary)\n\"\"\"\n\n        viz_hints = {\"type\": \"summary\", \"show_data_info\": True}\n\n        return AnalysisResult(\n            result_data=result, code_generated=code, visualization_hints=viz_hints\n        )\n\n    def _generate_index_code(self, items: List[Dict], index_type: str) -&gt; str:\n        \"\"\"Generate Python code for spectral index calculation.\n\n        Args:\n            items: STAC items or data references\n            index_type: Type of spectral index\n\n        Returns:\n            Generated Python code string\n        \"\"\"\n        if index_type == \"ndvi\":\n            return f\"\"\"# NDVI Calculation\nimport rasterio\nimport numpy as np\n\n# Load red and NIR bands from STAC items\nitems = {json.dumps(items[:2], indent=2)}\n\ndef calculate_ndvi(red_band, nir_band):\n    \\\"\\\"\\\"Calculate NDVI from red and NIR bands.\\\"\\\"\\\"\n    ndvi = (nir_band - red_band) / (nir_band + red_band)\n    return ndvi\n\n# Process each item\nfor item in items:\n    red_asset = item['assets']['red']['href']\n    nir_asset = item['assets']['nir']['href']\n\n    with rasterio.open(red_asset) as red_src:\n        red = red_src.read(1).astype(float)\n\n    with rasterio.open(nir_asset) as nir_src:\n        nir = nir_src.read(1).astype(float)\n\n    ndvi = calculate_ndvi(red, nir)\n    print(f\"NDVI calculated for {{item['id']}}\")\n    print(f\"NDVI range: {{np.nanmin(ndvi):.3f}} to {{np.nanmax(ndvi):.3f}}\")\n\"\"\"\n\n        elif index_type == \"evi\":\n            return f\"\"\"# EVI Calculation\nimport rasterio\nimport numpy as np\n\n# Enhanced Vegetation Index calculation\nitems = {json.dumps(items[:2], indent=2)}\n\ndef calculate_evi(red, nir, blue, G=2.5, C1=6.0, C2=7.5, L=1.0):\n    \\\"\\\"\\\"Calculate EVI from RGB and NIR bands.\\\"\\\"\\\"\n    evi = G * ((nir - red) / (nir + C1*red - C2*blue + L))\n    return evi\n\n# Process items for EVI\nfor item in items:\n    # Load required bands\n    red_asset = item['assets']['red']['href']\n    nir_asset = item['assets']['nir']['href']\n    blue_asset = item['assets']['blue']['href']\n\n    # Calculate EVI\n    evi = calculate_evi(red, nir, blue)\n    print(f\"EVI calculated for {{item['id']}}\")\n\"\"\"\n\n        return f\"# {index_type.upper()} calculation code would be generated here\"\n\n    def _generate_zonal_code(self, items: List[Dict], zones: Any) -&gt; str:\n        \"\"\"Generate code for zonal statistics.\"\"\"\n        return f\"\"\"# Zonal Statistics Calculation\nimport rasterio\nimport geopandas as gpd\nfrom rasterio.mask import mask\nimport numpy as np\n\n# Load raster data\nitems = {json.dumps(items[:1], indent=2)}\nzones = {json.dumps(zones, default=str)}\n\ndef zonal_statistics(raster_path, zones_geom):\n    \\\"\\\"\\\"Calculate zonal statistics for geometries.\\\"\\\"\\\"\n    with rasterio.open(raster_path) as src:\n        # Mask raster with each zone\n        stats = []\n        for zone in zones_geom:\n            masked, transform = mask(src, [zone], crop=True)\n            data = masked[0]\n            valid_data = data[data != src.nodata]\n\n            if len(valid_data) &gt; 0:\n                zone_stats = {{\n                    'mean': float(np.mean(valid_data)),\n                    'median': float(np.median(valid_data)),\n                    'std': float(np.std(valid_data)),\n                    'min': float(np.min(valid_data)),\n                    'max': float(np.max(valid_data))\n                }}\n            else:\n                zone_stats = {{'mean': None, 'median': None}}\n\n            stats.append(zone_stats)\n\n    return stats\n\n# Calculate statistics for each zone\nprint(\"Computing zonal statistics...\")\n\"\"\"\n\n    def _generate_timeseries_code(self, items: List[Dict], location: Any) -&gt; str:\n        \"\"\"Generate code for time series analysis.\"\"\"\n        return f\"\"\"# Time Series Analysis\nimport rasterio\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\n# Time series data\nitems = {json.dumps(items[:5], indent=2)}\nlocation = {json.dumps(location, default=str)}\n\ndef extract_time_series(items, point_location):\n    \\\"\\\"\\\"Extract time series values at a location.\\\"\\\"\\\"\n    ts_data = []\n\n    for item in items:\n        # Get date from item\n        date_str = item['properties']['datetime']\n        date = pd.to_datetime(date_str)\n\n        # Extract value at location\n        asset_href = item['assets']['red']['href']  # or chosen band\n        with rasterio.open(asset_href) as src:\n            # Convert location to raster coordinates\n            row, col = src.index(location['lon'], location['lat'])\n            value = src.read(1)[row, col]\n\n            ts_data.append({{\n                'date': date,\n                'value': float(value) if value != src.nodata else None\n            }})\n\n    return pd.DataFrame(ts_data)\n\n# Extract time series\nts_df = extract_time_series(items, location)\nprint(\"Time series extracted:\")\nprint(ts_df.head())\n\"\"\"\n\n    def _generate_change_code(self, items: List[Dict]) -&gt; str:\n        \"\"\"Generate code for change detection.\"\"\"\n        return f\"\"\"# Change Detection Analysis\nimport rasterio\nimport numpy as np\n\n# Multi-temporal data\nitems = {json.dumps(items[:2], indent=2)}\n\ndef detect_change(before_raster, after_raster):\n    \\\"\\\"\\\"Compute change between two raster datasets.\\\"\\\"\\\"\n    with rasterio.open(before_raster) as src1:\n        before = src1.read(1).astype(float)\n\n    with rasterio.open(after_raster) as src2:\n        after = src2.read(1).astype(float)\n\n    # Calculate change\n    change = after - before\n    percent_change = ((after - before) / before) * 100\n\n    return {{\n        'absolute_change': change,\n        'percent_change': percent_change,\n        'change_stats': {{\n            'mean_change': float(np.nanmean(change)),\n            'std_change': float(np.nanstd(change))\n        }}\n    }}\n\n# Detect changes between time periods\nif len(items) &gt;= 2:\n    before_asset = items[0]['assets']['red']['href']\n    after_asset = items[-1]['assets']['red']['href']\n\n    change_result = detect_change(before_asset, after_asset)\n    print(\"Change detection completed\")\n    print(f\"Mean change: {{change_result['change_stats']['mean_change']:.3f}}\")\n\"\"\"\n\n    def _generate_buffer_code(self, items: List[Dict], distance: float) -&gt; str:\n        \"\"\"Generate code for buffer analysis.\"\"\"\n        return f\"\"\"# Buffer Analysis\nimport geopandas as gpd\n\n# Vector data\nitems = {json.dumps(items[:1], indent=2)}\nbuffer_distance = {distance}\n\ndef create_buffer(geometries, distance):\n    \\\"\\\"\\\"Create buffer around geometries.\\\"\\\"\\\"\n    gdf = gpd.GeoDataFrame(items)\n    buffered = gdf.buffer(distance)\n    return buffered\n\n# Create buffers\nbuffered_geoms = create_buffer(items, buffer_distance)\nprint(f\"Created buffers with {{buffer_distance}}m radius\")\n\"\"\"\n\n    def _generate_intersect_code(self, items: List[Dict]) -&gt; str:\n        \"\"\"Generate code for intersection analysis.\"\"\"\n        return f\"\"\"# Intersection Analysis\nimport geopandas as gpd\n\n# Vector data for intersection\nitems = {json.dumps(items[:2], indent=2)}\n\ndef intersect_geometries(geom_list):\n    \\\"\\\"\\\"Find intersections between geometries.\\\"\\\"\\\"\n    gdf1 = gpd.GeoDataFrame([geom_list[0]])\n    gdf2 = gpd.GeoDataFrame([geom_list[1]])\n\n    intersection = gpd.overlay(gdf1, gdf2, how='intersection')\n    return intersection\n\n# Perform intersection\nintersections = intersect_geometries(items)\nprint(\"Intersection analysis completed\")\n\"\"\"\n\n    def _generate_general_vector_code(self, items: List[Dict], intent: str) -&gt; str:\n        \"\"\"Generate general vector analysis code.\"\"\"\n        return f\"\"\"# General Vector Analysis: {intent}\nimport geopandas as gpd\nimport pandas as pd\n\n# Vector data\nitems = {json.dumps(items[:3], indent=2)}\n\ndef analyze_vector_data(data, intent):\n    \\\"\\\"\\\"Perform general vector analysis.\\\"\\\"\\\"\n    gdf = gpd.GeoDataFrame(data)\n\n    analysis_result = {{\n        'total_features': len(gdf),\n        'geometry_types': gdf.geom_type.value_counts().to_dict(),\n        'bounds': gdf.total_bounds.tolist(),\n        'area_stats': {{\n            'mean_area': float(gdf.area.mean()),\n            'total_area': float(gdf.area.sum())\n        }} if 'Polygon' in gdf.geom_type.values else None\n    }}\n\n    return analysis_result\n\n# Analyze vector data\nresult = analyze_vector_data(items, \"{intent}\")\nprint(\"Vector analysis completed:\")\nprint(result)\n\"\"\"\n\n    def _get_index_viz_hints(self, index_type: str, result: Dict) -&gt; Dict[str, Any]:\n        \"\"\"Get visualization hints for spectral indices.\"\"\"\n        index_configs = {\n            \"ndvi\": {\"colormap\": \"RdYlGn\", \"vmin\": -1, \"vmax\": 1, \"title\": \"NDVI\"},\n            \"evi\": {\"colormap\": \"Greens\", \"vmin\": -1, \"vmax\": 1, \"title\": \"EVI\"},\n            \"savi\": {\"colormap\": \"YlOrRd\", \"vmin\": -1, \"vmax\": 1, \"title\": \"SAVI\"},\n        }\n\n        return index_configs.get(\n            index_type, {\"colormap\": \"viridis\", \"title\": index_type.upper()}\n        )\n\n    def _create_mock_analysis(\n        self, analysis_type: str, data: DataResult\n    ) -&gt; AnalysisResult:\n        \"\"\"Create mock analysis result when tools are not available.\n\n        Args:\n            analysis_type: Type of analysis attempted\n            data: Input data\n\n        Returns:\n            Mock AnalysisResult for development\n        \"\"\"\n        logger.info(f\"Creating mock {analysis_type} analysis result\")\n\n        mock_result = {\n            \"analysis_type\": analysis_type,\n            \"data_processed\": data.total_items,\n            \"mock\": True,\n            \"summary\": f\"Mock {analysis_type} analysis completed\",\n        }\n\n        if analysis_type == \"ndvi\":\n            mock_result.update(\n                {\"ndvi_stats\": {\"mean\": 0.65, \"min\": -0.2, \"max\": 0.95, \"std\": 0.18}}\n            )\n\n        mock_code = f\"\"\"# Mock {analysis_type} analysis\n# This is a placeholder while tools are being developed\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Mock analysis for {analysis_type}\nprint(\"Mock {analysis_type} analysis completed\")\nresult = {mock_result}\n\"\"\"\n\n        return AnalysisResult(\n            result_data=mock_result,\n            code_generated=mock_code,\n            visualization_hints={\"type\": analysis_type, \"mock\": True},\n        )\n</code></pre>"},{"location":"analysis_agent/#geoagent.core.analysis_agent.AnalysisAgent.__init__","title":"<code>__init__(self, llm, tools=None)</code>  <code>special</code>","text":"<p>Initialize the Analysis Agent.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>Any</code> <p>Language model instance for analysis planning</p> required <code>tools</code> <code>Optional[Dict[str, Any]]</code> <p>Dictionary of available analysis tools (raster, vector, etc.)</p> <code>None</code> Source code in <code>geoagent/core/analysis_agent.py</code> <pre><code>def __init__(self, llm: Any, tools: Optional[Dict[str, Any]] = None):\n    \"\"\"Initialize the Analysis Agent.\n\n    Args:\n        llm: Language model instance for analysis planning\n        tools: Dictionary of available analysis tools (raster, vector, etc.)\n    \"\"\"\n    self.llm = llm\n    self.tools = tools or {}\n    self._setup_tools()\n</code></pre>"},{"location":"analysis_agent/#geoagent.core.analysis_agent.AnalysisAgent.analyze","title":"<code>analyze(self, plan, data)</code>","text":"<p>Perform analysis on the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>PlannerOutput</code> <p>Original query plan with analysis intent</p> required <code>data</code> <code>DataResult</code> <p>Data retrieved by the Data Agent</p> required <p>Returns:</p> Type Description <code>AnalysisResult</code> <p>AnalysisResult with computed results and generated code</p> Source code in <code>geoagent/core/analysis_agent.py</code> <pre><code>def analyze(self, plan: PlannerOutput, data: DataResult) -&gt; AnalysisResult:\n    \"\"\"Perform analysis on the provided data.\n\n    Args:\n        plan: Original query plan with analysis intent\n        data: Data retrieved by the Data Agent\n\n    Returns:\n        AnalysisResult with computed results and generated code\n    \"\"\"\n    logger.info(f\"Starting analysis for intent: {plan.intent}\")\n\n    try:\n        # Determine analysis type based on intent and data type\n        analysis_type = self._determine_analysis_type(plan, data)\n\n        if analysis_type == \"land_cover\":\n            return self._handle_land_cover(plan, data)\n        elif analysis_type == \"elevation\":\n            return self._handle_elevation(plan, data)\n        elif analysis_type == \"spectral_index\":\n            return self._compute_spectral_index(plan, data)\n        elif analysis_type == \"zonal_statistics\":\n            return self._compute_zonal_statistics(plan, data)\n        elif analysis_type == \"time_series\":\n            return self._compute_time_series(plan, data)\n        elif analysis_type == \"change_detection\":\n            return self._compute_change_detection(plan, data)\n        elif analysis_type == \"vector_analysis\":\n            return self._perform_vector_analysis(plan, data)\n        else:\n            return self._perform_general_analysis(plan, data)\n\n    except Exception as e:\n        logger.error(f\"Analysis failed: {e}\")\n        return AnalysisResult(\n            result_data={\"error\": str(e)},\n            code_generated=f\"# Analysis failed: {e}\",\n            success=False,\n            error_message=str(e),\n        )\n</code></pre>"},{"location":"catalogs/","title":"STAC Catalogs","text":"<p>GeoAgent includes a registry of pre-configured STAC catalog endpoints.</p>"},{"location":"catalogs/#built-in-catalogs","title":"Built-in Catalogs","text":"Catalog URL Auth Required Earth Search (AWS) <code>earth-search.aws.element84.com/v1</code> No Planetary Computer <code>planetarycomputer.microsoft.com/api/stac/v1</code> No (signing optional) USGS Landsat <code>landsatlook.usgs.gov/stac-server</code> No NASA CMR-STAC <code>cmr.earthdata.nasa.gov/stac</code> Yes (<code>NASA_EARTHDATA_TOKEN</code>)"},{"location":"catalogs/#catalog-registry","title":"Catalog Registry","text":""},{"location":"catalogs/#geoagent.catalogs.registry","title":"<code>geoagent.catalogs.registry</code>","text":"<p>STAC catalog registry with pre-configured endpoints and extensibility.</p>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogInfo","title":"<code> CatalogInfo        </code>  <code>dataclass</code>","text":"<p>Information about a STAC catalog.</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>@dataclass\nclass CatalogInfo:\n    \"\"\"Information about a STAC catalog.\"\"\"\n\n    name: str\n    url: str\n    description: str\n    requires_auth: bool = False\n    auth_env_var: Optional[str] = None\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry","title":"<code> CatalogRegistry        </code>","text":"<p>Registry for STAC catalogs with built-in and custom endpoints.</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>class CatalogRegistry:\n    \"\"\"Registry for STAC catalogs with built-in and custom endpoints.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the catalog registry with built-in catalogs.\"\"\"\n        self._catalogs: Dict[str, CatalogInfo] = BUILTIN_CATALOGS.copy()\n        # Cache for catalog collections: {catalog_name: [{\"id\": str, \"title\": str}, ...]}\n        # Cached per session to avoid repeated network calls\n        self.__class__._collection_cache = getattr(\n            self.__class__, \"_collection_cache\", {}\n        )\n\n    def list_catalogs(self) -&gt; List[CatalogInfo]:\n        \"\"\"\n        List all available catalogs.\n\n        Returns:\n            List of CatalogInfo objects\n        \"\"\"\n        return list(self._catalogs.values())\n\n    def get_catalog(self, name: str) -&gt; Optional[CatalogInfo]:\n        \"\"\"\n        Get catalog information by name.\n\n        Args:\n            name: Catalog name\n\n        Returns:\n            CatalogInfo object or None if not found\n        \"\"\"\n        return self._catalogs.get(name)\n\n    def add_catalog(\n        self,\n        name: str,\n        url: str,\n        description: str,\n        requires_auth: bool = False,\n        auth_env_var: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"\n        Add a custom catalog to the registry.\n\n        Args:\n            name: Unique catalog name\n            url: STAC API endpoint URL\n            description: Human-readable description\n            requires_auth: Whether authentication is required\n            auth_env_var: Environment variable name for auth token\n        \"\"\"\n        self._catalogs[name] = CatalogInfo(\n            name=name,\n            url=url,\n            description=description,\n            requires_auth=requires_auth,\n            auth_env_var=auth_env_var,\n        )\n        logger.info(f\"Added catalog '{name}' to registry\")\n\n    def get_client(self, name: Optional[str] = None) -&gt; pystac_client.Client:\n        \"\"\"\n        Get a pystac_client.Client for the specified catalog.\n\n        Args:\n            name: Catalog name. Uses default if None.\n\n        Returns:\n            Configured pystac_client.Client instance\n\n        Raises:\n            ValueError: If catalog not found\n            RuntimeError: If authentication required but credentials missing\n        \"\"\"\n        if name is None:\n            name = DEFAULT_CATALOG\n\n        catalog = self.get_catalog(name)\n        if not catalog:\n            available = \", \".join(self._catalogs.keys())\n            raise ValueError(f\"Catalog '{name}' not found. Available: {available}\")\n\n        # Check authentication\n        if catalog.requires_auth and catalog.auth_env_var:\n            if not os.getenv(catalog.auth_env_var):\n                raise RuntimeError(\n                    f\"Catalog '{name}' requires authentication. \"\n                    f\"Set environment variable: {catalog.auth_env_var}\"\n                )\n\n        client_kwargs = {}\n\n        # Handle authentication for specific catalogs\n        if name == \"nasa_cmr\" and catalog.auth_env_var:\n            token = os.getenv(catalog.auth_env_var)\n            if token:\n                client_kwargs[\"headers\"] = {\"Authorization\": f\"Bearer {token}\"}\n\n        # Create the client\n        try:\n            client = pystac_client.Client.open(catalog.url, **client_kwargs)\n\n            # Special handling for Planetary Computer signing\n            if name == \"planetary_computer\":\n                try:\n                    import planetary_computer\n\n                    # Wrap the client with signing capability\n                    original_search = client.search\n\n                    def signed_search(*args, **kwargs):\n                        \"\"\"Search wrapper that signs items for access.\"\"\"\n                        search_result = original_search(*args, **kwargs)\n                        # Sign the items in the search result for direct access\n                        search_result.sign = lambda: planetary_computer.sign(\n                            search_result\n                        )\n                        return search_result\n\n                    client.search = signed_search\n                    logger.info(\"Planetary Computer signing enabled\")\n\n                except ImportError:\n                    logger.warning(\n                        \"planetary-computer package not available. \"\n                        \"Some data access may be slower. \"\n                        \"Install with: pip install planetary-computer\"\n                    )\n\n            return client\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to connect to catalog '{name}': {str(e)}\")\n\n    def get_collection_index(\n        self, catalog_name: str = \"planetary_computer\"\n    ) -&gt; List[Dict[str, str]]:\n        \"\"\"Fetch and cache a simple index of collections for a catalog.\n\n        The index contains dicts with collection id and title, e.g.:\n        [{\"id\": \"sentinel-2-l2a\", \"title\": \"Sentinel-2 Level-2A\"}, ...]\n\n        Results are cached in-memory for the duration of the session.\n\n        Args:\n            catalog_name: Name of the catalog as registered in this registry\n\n        Returns:\n            List of dicts with keys \"id\" and \"title\"\n        \"\"\"\n        # Return cached if available\n        cache = self.__class__._collection_cache\n        if catalog_name in cache:\n            return cache[catalog_name]\n\n        client = self.get_client(catalog_name)\n        collections: List[Dict[str, str]] = []\n        try:\n            for col in client.get_collections():\n                col_id = getattr(col, \"id\", None) or col.to_dict().get(\"id\")\n                title = (\n                    getattr(col, \"title\", None) or col.to_dict().get(\"title\") or col_id\n                )\n                if col_id:\n                    collections.append({\"id\": col_id, \"title\": title})\n        except Exception as e:\n            raise RuntimeError(f\"Failed to list collections for '{catalog_name}': {e}\")\n\n        # Cache and return\n        cache[catalog_name] = collections\n        return collections\n\n    def remove_catalog(self, name: str) -&gt; bool:\n        \"\"\"\n        Remove a catalog from the registry.\n\n        Args:\n            name: Catalog name to remove\n\n        Returns:\n            True if catalog was removed, False if not found\n\n        Note:\n            Built-in catalogs cannot be removed, only custom ones\n        \"\"\"\n        if name in BUILTIN_CATALOGS:\n            logger.warning(f\"Cannot remove built-in catalog '{name}'\")\n            return False\n\n        if name in self._catalogs:\n            del self._catalogs[name]\n            logger.info(f\"Removed catalog '{name}' from registry\")\n            return True\n\n        return False\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry.__init__","title":"<code>__init__(self)</code>  <code>special</code>","text":"<p>Initialize the catalog registry with built-in catalogs.</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the catalog registry with built-in catalogs.\"\"\"\n    self._catalogs: Dict[str, CatalogInfo] = BUILTIN_CATALOGS.copy()\n    # Cache for catalog collections: {catalog_name: [{\"id\": str, \"title\": str}, ...]}\n    # Cached per session to avoid repeated network calls\n    self.__class__._collection_cache = getattr(\n        self.__class__, \"_collection_cache\", {}\n    )\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry.add_catalog","title":"<code>add_catalog(self, name, url, description, requires_auth=False, auth_env_var=None)</code>","text":"<p>Add a custom catalog to the registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Unique catalog name</p> required <code>url</code> <code>str</code> <p>STAC API endpoint URL</p> required <code>description</code> <code>str</code> <p>Human-readable description</p> required <code>requires_auth</code> <code>bool</code> <p>Whether authentication is required</p> <code>False</code> <code>auth_env_var</code> <code>Optional[str]</code> <p>Environment variable name for auth token</p> <code>None</code> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def add_catalog(\n    self,\n    name: str,\n    url: str,\n    description: str,\n    requires_auth: bool = False,\n    auth_env_var: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Add a custom catalog to the registry.\n\n    Args:\n        name: Unique catalog name\n        url: STAC API endpoint URL\n        description: Human-readable description\n        requires_auth: Whether authentication is required\n        auth_env_var: Environment variable name for auth token\n    \"\"\"\n    self._catalogs[name] = CatalogInfo(\n        name=name,\n        url=url,\n        description=description,\n        requires_auth=requires_auth,\n        auth_env_var=auth_env_var,\n    )\n    logger.info(f\"Added catalog '{name}' to registry\")\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry.get_catalog","title":"<code>get_catalog(self, name)</code>","text":"<p>Get catalog information by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Catalog name</p> required <p>Returns:</p> Type Description <code>Optional[geoagent.catalogs.registry.CatalogInfo]</code> <p>CatalogInfo object or None if not found</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def get_catalog(self, name: str) -&gt; Optional[CatalogInfo]:\n    \"\"\"\n    Get catalog information by name.\n\n    Args:\n        name: Catalog name\n\n    Returns:\n        CatalogInfo object or None if not found\n    \"\"\"\n    return self._catalogs.get(name)\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry.get_client","title":"<code>get_client(self, name=None)</code>","text":"<p>Get a pystac_client.Client for the specified catalog.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Catalog name. Uses default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Client</code> <p>Configured pystac_client.Client instance</p> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If catalog not found</p> <code>RuntimeError</code> <p>If authentication required but credentials missing</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def get_client(self, name: Optional[str] = None) -&gt; pystac_client.Client:\n    \"\"\"\n    Get a pystac_client.Client for the specified catalog.\n\n    Args:\n        name: Catalog name. Uses default if None.\n\n    Returns:\n        Configured pystac_client.Client instance\n\n    Raises:\n        ValueError: If catalog not found\n        RuntimeError: If authentication required but credentials missing\n    \"\"\"\n    if name is None:\n        name = DEFAULT_CATALOG\n\n    catalog = self.get_catalog(name)\n    if not catalog:\n        available = \", \".join(self._catalogs.keys())\n        raise ValueError(f\"Catalog '{name}' not found. Available: {available}\")\n\n    # Check authentication\n    if catalog.requires_auth and catalog.auth_env_var:\n        if not os.getenv(catalog.auth_env_var):\n            raise RuntimeError(\n                f\"Catalog '{name}' requires authentication. \"\n                f\"Set environment variable: {catalog.auth_env_var}\"\n            )\n\n    client_kwargs = {}\n\n    # Handle authentication for specific catalogs\n    if name == \"nasa_cmr\" and catalog.auth_env_var:\n        token = os.getenv(catalog.auth_env_var)\n        if token:\n            client_kwargs[\"headers\"] = {\"Authorization\": f\"Bearer {token}\"}\n\n    # Create the client\n    try:\n        client = pystac_client.Client.open(catalog.url, **client_kwargs)\n\n        # Special handling for Planetary Computer signing\n        if name == \"planetary_computer\":\n            try:\n                import planetary_computer\n\n                # Wrap the client with signing capability\n                original_search = client.search\n\n                def signed_search(*args, **kwargs):\n                    \"\"\"Search wrapper that signs items for access.\"\"\"\n                    search_result = original_search(*args, **kwargs)\n                    # Sign the items in the search result for direct access\n                    search_result.sign = lambda: planetary_computer.sign(\n                        search_result\n                    )\n                    return search_result\n\n                client.search = signed_search\n                logger.info(\"Planetary Computer signing enabled\")\n\n            except ImportError:\n                logger.warning(\n                    \"planetary-computer package not available. \"\n                    \"Some data access may be slower. \"\n                    \"Install with: pip install planetary-computer\"\n                )\n\n        return client\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to connect to catalog '{name}': {str(e)}\")\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry.get_collection_index","title":"<code>get_collection_index(self, catalog_name='planetary_computer')</code>","text":"<p>Fetch and cache a simple index of collections for a catalog.</p> <p>The index contains dicts with collection id and title, e.g.: [{\"id\": \"sentinel-2-l2a\", \"title\": \"Sentinel-2 Level-2A\"}, ...]</p> <p>Results are cached in-memory for the duration of the session.</p> <p>Parameters:</p> Name Type Description Default <code>catalog_name</code> <code>str</code> <p>Name of the catalog as registered in this registry</p> <code>'planetary_computer'</code> <p>Returns:</p> Type Description <code>List[Dict[str, str]]</code> <p>List of dicts with keys \"id\" and \"title\"</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def get_collection_index(\n    self, catalog_name: str = \"planetary_computer\"\n) -&gt; List[Dict[str, str]]:\n    \"\"\"Fetch and cache a simple index of collections for a catalog.\n\n    The index contains dicts with collection id and title, e.g.:\n    [{\"id\": \"sentinel-2-l2a\", \"title\": \"Sentinel-2 Level-2A\"}, ...]\n\n    Results are cached in-memory for the duration of the session.\n\n    Args:\n        catalog_name: Name of the catalog as registered in this registry\n\n    Returns:\n        List of dicts with keys \"id\" and \"title\"\n    \"\"\"\n    # Return cached if available\n    cache = self.__class__._collection_cache\n    if catalog_name in cache:\n        return cache[catalog_name]\n\n    client = self.get_client(catalog_name)\n    collections: List[Dict[str, str]] = []\n    try:\n        for col in client.get_collections():\n            col_id = getattr(col, \"id\", None) or col.to_dict().get(\"id\")\n            title = (\n                getattr(col, \"title\", None) or col.to_dict().get(\"title\") or col_id\n            )\n            if col_id:\n                collections.append({\"id\": col_id, \"title\": title})\n    except Exception as e:\n        raise RuntimeError(f\"Failed to list collections for '{catalog_name}': {e}\")\n\n    # Cache and return\n    cache[catalog_name] = collections\n    return collections\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry.list_catalogs","title":"<code>list_catalogs(self)</code>","text":"<p>List all available catalogs.</p> <p>Returns:</p> Type Description <code>List[geoagent.catalogs.registry.CatalogInfo]</code> <p>List of CatalogInfo objects</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def list_catalogs(self) -&gt; List[CatalogInfo]:\n    \"\"\"\n    List all available catalogs.\n\n    Returns:\n        List of CatalogInfo objects\n    \"\"\"\n    return list(self._catalogs.values())\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.CatalogRegistry.remove_catalog","title":"<code>remove_catalog(self, name)</code>","text":"<p>Remove a catalog from the registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Catalog name to remove</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if catalog was removed, False if not found</p> <p>Note</p> <p>Built-in catalogs cannot be removed, only custom ones</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def remove_catalog(self, name: str) -&gt; bool:\n    \"\"\"\n    Remove a catalog from the registry.\n\n    Args:\n        name: Catalog name to remove\n\n    Returns:\n        True if catalog was removed, False if not found\n\n    Note:\n        Built-in catalogs cannot be removed, only custom ones\n    \"\"\"\n    if name in BUILTIN_CATALOGS:\n        logger.warning(f\"Cannot remove built-in catalog '{name}'\")\n        return False\n\n    if name in self._catalogs:\n        del self._catalogs[name]\n        logger.info(f\"Removed catalog '{name}' from registry\")\n        return True\n\n    return False\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.get_catalog_client","title":"<code>get_catalog_client(name=None)</code>","text":"<p>Get a STAC client for the specified catalog.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Catalog name. Uses default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Client</code> <p>Configured pystac_client.Client instance</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def get_catalog_client(name: Optional[str] = None) -&gt; pystac_client.Client:\n    \"\"\"\n    Get a STAC client for the specified catalog.\n\n    Args:\n        name: Catalog name. Uses default if None.\n\n    Returns:\n        Configured pystac_client.Client instance\n    \"\"\"\n    return _global_registry.get_client(name)\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.get_collection_index","title":"<code>get_collection_index(catalog_name='planetary_computer')</code>","text":"<p>Convenience accessor for a catalog's collection index.</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def get_collection_index(catalog_name: str = \"planetary_computer\") -&gt; list:\n    \"\"\"Convenience accessor for a catalog's collection index.\"\"\"\n    return _global_registry.get_collection_index(catalog_name)\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.get_registry","title":"<code>get_registry()</code>","text":"<p>Get the global catalog registry instance.</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def get_registry() -&gt; CatalogRegistry:\n    \"\"\"Get the global catalog registry instance.\"\"\"\n    return _global_registry\n</code></pre>"},{"location":"catalogs/#geoagent.catalogs.registry.list_catalogs","title":"<code>list_catalogs()</code>","text":"<p>List all available catalogs from the global registry.</p> Source code in <code>geoagent/catalogs/registry.py</code> <pre><code>def list_catalogs() -&gt; List[CatalogInfo]:\n    \"\"\"List all available catalogs from the global registry.\"\"\"\n    return _global_registry.list_catalogs()\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/opengeos/GeoAgent/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>GeoAgent could always use more documentation, whether as part of the official GeoAgent docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/opengeos/GeoAgent/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up GeoAgent for local development.</p> <ol> <li> <p>Fork the GeoAgent repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/GeoAgent.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv GeoAgent\n$ cd GeoAgent/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 GeoAgent tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/opengeos/GeoAgent/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"data_agent/","title":"Data Agent","text":"<p>The Data Agent searches and retrieves geospatial data from STAC catalogs and other sources.</p>"},{"location":"data_agent/#geoagent.core.data_agent","title":"<code>geoagent.core.data_agent</code>","text":"<p>Data Agent for fetching geospatial data from various sources.</p> <p>The Data Agent is responsible for searching and retrieving geospatial data based on structured query parameters from the Planner Agent.</p>"},{"location":"data_agent/#geoagent.core.data_agent.DataAgent","title":"<code> DataAgent        </code>","text":"<p>Agent responsible for fetching geospatial data from various sources.</p> <p>The Data Agent takes structured query parameters and searches for relevant geospatial data using STAC catalogs, DuckDB queries, and other data sources.</p> Source code in <code>geoagent/core/data_agent.py</code> <pre><code>class DataAgent:\n    \"\"\"Agent responsible for fetching geospatial data from various sources.\n\n    The Data Agent takes structured query parameters and searches for relevant\n    geospatial data using STAC catalogs, DuckDB queries, and other data sources.\n    \"\"\"\n\n    def __init__(self, llm: Any, tools: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the Data Agent.\n\n        Args:\n            llm: Language model instance for decision making\n            tools: Dictionary of available data tools (stac, duckdb, etc.)\n        \"\"\"\n        self.llm = llm\n        self.tools = tools or {}\n        self._setup_tools()\n\n    def _setup_tools(self):\n        \"\"\"Setup and initialize data tools.\"\"\"\n        try:\n            if \"stac\" not in self.tools:\n                self.tools[\"stac\"] = STACSearchWrapper()\n            logger.info(\"Data tools initialized (STAC search available)\")\n        except Exception as e:\n            logger.warning(f\"Some data tools not available: {e}\")\n\n    def search_data(self, plan: PlannerOutput) -&gt; DataResult:\n        \"\"\"Search for geospatial data based on the query plan.\n\n        Args:\n            plan: Structured query parameters from Planner Agent\n\n        Returns:\n            DataResult containing found data items and metadata\n        \"\"\"\n        logger.info(f\"Searching data for intent: {plan.intent}\")\n\n        try:\n            # Determine data type based on intent and dataset\n            data_type = self._determine_data_type(plan)\n\n            if data_type == \"raster\":\n                return self._search_raster_data(plan)\n            elif data_type == \"vector\":\n                return self._search_vector_data(plan)\n            elif data_type == \"tabular\":\n                return self._search_tabular_data(plan)\n            else:\n                # Fallback: try multiple sources\n                return self._search_multi_source(plan)\n\n        except Exception as e:\n            logger.error(f\"Error searching data: {e}\")\n            return DataResult(\n                items=[], metadata={\"error\": str(e)}, data_type=\"unknown\", total_items=0\n            )\n\n    def _determine_data_type(self, plan: PlannerOutput) -&gt; str:\n        \"\"\"Determine the primary data type needed based on the query plan.\n\n        Args:\n            plan: Query plan with intent and parameters\n\n        Returns:\n            Data type: \"raster\", \"vector\", or \"tabular\"\n        \"\"\"\n        intent = plan.intent.lower()\n        dataset = (plan.dataset or \"\").lower()\n\n        # Raster analysis indicators\n        raster_keywords = [\n            \"ndvi\",\n            \"spectral\",\n            \"index\",\n            \"satellite\",\n            \"imagery\",\n            \"sentinel\",\n            \"landsat\",\n            \"modis\",\n            \"pixel\",\n            \"band\",\n        ]\n\n        # Vector analysis indicators\n        vector_keywords = [\n            \"boundary\",\n            \"polygon\",\n            \"point\",\n            \"line\",\n            \"geometry\",\n            \"administrative\",\n            \"road\",\n            \"building\",\n            \"parcel\",\n        ]\n\n        # Check for explicit raster datasets\n        if any(sat in dataset for sat in [\"sentinel\", \"landsat\", \"modis\", \"aster\"]):\n            return \"raster\"\n\n        # Check intent for raster operations\n        if any(keyword in intent for keyword in raster_keywords):\n            return \"raster\"\n\n        # Check intent for vector operations\n        if any(keyword in intent for keyword in vector_keywords):\n            return \"vector\"\n\n        # Default to raster for satellite-based analysis\n        return \"raster\"\n\n    def _search_raster_data(self, plan: PlannerOutput) -&gt; DataResult:\n        \"\"\"Search for raster/satellite imagery using STAC catalogs.\n\n        Args:\n            plan: Query plan with spatial/temporal parameters\n\n        Returns:\n            DataResult with STAC items\n        \"\"\"\n        if \"stac\" not in self.tools:\n            logger.warning(\"STAC tool not available\")\n            return self._create_mock_result(\"raster\", plan)\n\n        try:\n            # Build STAC search parameters\n            search_params = self._build_stac_params(plan)\n\n            # Execute STAC search\n            stac_tool = self.tools[\"stac\"]\n            items = stac_tool.search(**search_params)\n\n            return DataResult(\n                items=items,\n                metadata={\n                    \"search_params\": search_params,\n                    \"catalog\": getattr(stac_tool, \"catalog_url\", \"unknown\"),\n                },\n                data_type=\"raster\",\n                total_items=len(items),\n                search_query=search_params,\n            )\n\n        except Exception as e:\n            logger.error(f\"STAC search failed: {e}\")\n            return self._create_mock_result(\"raster\", plan)\n\n    def _search_vector_data(self, plan: PlannerOutput) -&gt; DataResult:\n        \"\"\"Search for vector data using various sources.\n\n        Args:\n            plan: Query plan with spatial parameters\n\n        Returns:\n            DataResult with vector data references\n        \"\"\"\n        if \"duckdb\" not in self.tools:\n            logger.warning(\"DuckDB tool not available\")\n            return self._create_mock_result(\"vector\", plan)\n\n        try:\n            # Build query for vector data\n            query_params = self._build_vector_params(plan)\n\n            # Execute DuckDB query\n            duckdb_tool = self.tools[\"duckdb\"]\n            results = duckdb_tool.query(**query_params)\n\n            return DataResult(\n                items=results,\n                metadata={\"query_params\": query_params, \"source\": \"duckdb\"},\n                data_type=\"vector\",\n                total_items=len(results),\n                search_query=query_params,\n            )\n\n        except Exception as e:\n            logger.error(f\"Vector search failed: {e}\")\n            return self._create_mock_result(\"vector\", plan)\n\n    def _search_tabular_data(self, plan: PlannerOutput) -&gt; DataResult:\n        \"\"\"Search for tabular data using DuckDB.\n\n        Args:\n            plan: Query plan with data requirements\n\n        Returns:\n            DataResult with tabular data\n        \"\"\"\n        if \"duckdb\" not in self.tools:\n            logger.warning(\"DuckDB tool not available\")\n            return self._create_mock_result(\"tabular\", plan)\n\n        try:\n            # Build tabular query\n            query_params = self._build_tabular_params(plan)\n\n            # Execute query\n            duckdb_tool = self.tools[\"duckdb\"]\n            results = duckdb_tool.query(**query_params)\n\n            return DataResult(\n                items=results,\n                metadata={\"query_params\": query_params, \"source\": \"duckdb\"},\n                data_type=\"tabular\",\n                total_items=len(results),\n                search_query=query_params,\n            )\n\n        except Exception as e:\n            logger.error(f\"Tabular search failed: {e}\")\n            return self._create_mock_result(\"tabular\", plan)\n\n    def _search_multi_source(self, plan: PlannerOutput) -&gt; DataResult:\n        \"\"\"Search across multiple data sources and combine results.\n\n        Args:\n            plan: Query plan\n\n        Returns:\n            Combined DataResult\n        \"\"\"\n        # Try raster first, then vector if no results\n        raster_result = self._search_raster_data(plan)\n\n        if raster_result.total_items &gt; 0:\n            return raster_result\n\n        vector_result = self._search_vector_data(plan)\n        if vector_result.total_items &gt; 0:\n            return vector_result\n\n        # Return empty result if nothing found\n        return DataResult(\n            items=[],\n            metadata={\"searched_sources\": [\"raster\", \"vector\"]},\n            data_type=\"unknown\",\n            total_items=0,\n        )\n\n    def _build_stac_params(self, plan: PlannerOutput) -&gt; Dict[str, Any]:\n        \"\"\"Build STAC search parameters from query plan.\n\n        Args:\n            plan: Query plan with spatial/temporal info\n\n        Returns:\n            STAC search parameters dictionary\n        \"\"\"\n        params = {}\n\n        # Add spatial parameters\n        if plan.location:\n            if \"bbox\" in plan.location:\n                params[\"bbox\"] = plan.location[\"bbox\"]\n            elif \"geometry\" in plan.location:\n                params[\"intersects\"] = plan.location[\"geometry\"]\n\n        # Add temporal parameters\n        if plan.time_range:\n            start_date = plan.time_range.get(\"start_date\")\n            end_date = plan.time_range.get(\"end_date\")\n            if start_date and end_date:\n                params[\"datetime\"] = f\"{start_date}/{end_date}\"\n\n        # Add collection/dataset filters\n        if plan.dataset:\n            # Use the planner-provided dataset directly as the collection ID\n            params[\"collections\"] = [plan.dataset]\n\n        # Resolve collection from analysis_type or intent if not already set\n        if \"collections\" not in params:\n            analysis_type = (plan.analysis_type or \"\").lower()\n            intent_lower = plan.intent.lower()\n\n            # Check analysis_type first (most reliable signal from planner)\n            if analysis_type in (\"land_cover\", \"classification\", \"lulc\"):\n                params[\"collections\"] = [\"io-lulc-9-class\"]\n            elif analysis_type in (\n                \"elevation\",\n                \"dem\",\n                \"terrain\",\n                \"slope\",\n                \"hillshade\",\n            ):\n                params[\"collections\"] = [\"cop-dem-glo-30\"]\n            # Then check intent keywords\n            elif any(\n                kw in intent_lower\n                for kw in [\"land cover\", \"landcover\", \"lulc\", \"land use\"]\n            ):\n                params[\"collections\"] = [\"io-lulc-9-class\"]\n            elif any(\n                kw in intent_lower\n                for kw in [\"dem\", \"elevation\", \"terrain\", \"height\", \"topograph\"]\n            ):\n                params[\"collections\"] = [\"cop-dem-glo-30\"]\n            elif any(\n                kw in intent_lower\n                for kw in [\n                    \"ndvi\",\n                    \"evi\",\n                    \"vegetation\",\n                    \"spectral\",\n                    \"band\",\n                    \"imagery\",\n                ]\n            ):\n                params[\"collections\"] = [\"sentinel-2-l2a\"]\n\n        # Add cloud cover filter only for imagery collections (not DEM/land cover)\n        # Heuristic: imagery collections often contain these keywords\n        current_collections = set(params.get(\"collections\", []))\n        imagery_keywords = (\"sentinel\", \"landsat\", \"naip\", \"modis\")\n        is_imagery = any(\n            any(kw in (c or \"\").lower() for kw in imagery_keywords)\n            for c in current_collections\n        )\n        if is_imagery:\n            max_cloud = plan.parameters.get(\"max_cloud_cover\") or plan.parameters.get(\n                \"cloud_cover\"\n            )\n            if max_cloud is not None:\n                params[\"query\"] = {\"eo:cloud_cover\": {\"lt\": max_cloud}}\n\n        # Add limit to prevent too many results\n        params[\"max_items\"] = plan.parameters.get(\"max_items\", 10)\n\n        return params\n\n    def _build_vector_params(self, plan: PlannerOutput) -&gt; Dict[str, Any]:\n        \"\"\"Build vector query parameters from plan.\n\n        Args:\n            plan: Query plan\n\n        Returns:\n            Vector query parameters\n        \"\"\"\n        params = {\n            \"intent\": plan.intent,\n            \"location\": plan.location,\n            \"parameters\": plan.parameters,\n        }\n        return params\n\n    def _build_tabular_params(self, plan: PlannerOutput) -&gt; Dict[str, Any]:\n        \"\"\"Build tabular query parameters from plan.\n\n        Args:\n            plan: Query plan\n\n        Returns:\n            Tabular query parameters\n        \"\"\"\n        params = {\n            \"intent\": plan.intent,\n            \"dataset\": plan.dataset,\n            \"parameters\": plan.parameters,\n        }\n        return params\n\n    def _create_mock_result(self, data_type: str, plan: PlannerOutput) -&gt; DataResult:\n        \"\"\"Create a mock result when tools are not available.\n\n        Args:\n            data_type: Type of data that was requested\n            plan: Original query plan\n\n        Returns:\n            Mock DataResult for development/testing\n        \"\"\"\n        logger.info(f\"Creating mock {data_type} result for development\")\n\n        mock_items = []\n        if data_type == \"raster\":\n            mock_items = [\n                {\n                    \"id\": \"mock_sentinel2_item\",\n                    \"collection\": \"sentinel-2-l2a\",\n                    \"geometry\": (\n                        plan.location.get(\"geometry\") if plan.location else None\n                    ),\n                    \"properties\": {\n                        \"datetime\": \"2024-07-15T10:30:00Z\",\n                        \"cloud_cover\": 5.2,\n                    },\n                    \"assets\": {\n                        \"red\": {\"href\": \"mock://red.tif\"},\n                        \"nir\": {\"href\": \"mock://nir.tif\"},\n                    },\n                }\n            ]\n\n        return DataResult(\n            items=mock_items,\n            metadata={\"mock\": True, \"reason\": \"tools_not_available\"},\n            data_type=data_type,\n            total_items=len(mock_items),\n        )\n</code></pre>"},{"location":"data_agent/#geoagent.core.data_agent.DataAgent.__init__","title":"<code>__init__(self, llm, tools=None)</code>  <code>special</code>","text":"<p>Initialize the Data Agent.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>Any</code> <p>Language model instance for decision making</p> required <code>tools</code> <code>Optional[Dict[str, Any]]</code> <p>Dictionary of available data tools (stac, duckdb, etc.)</p> <code>None</code> Source code in <code>geoagent/core/data_agent.py</code> <pre><code>def __init__(self, llm: Any, tools: Optional[Dict[str, Any]] = None):\n    \"\"\"Initialize the Data Agent.\n\n    Args:\n        llm: Language model instance for decision making\n        tools: Dictionary of available data tools (stac, duckdb, etc.)\n    \"\"\"\n    self.llm = llm\n    self.tools = tools or {}\n    self._setup_tools()\n</code></pre>"},{"location":"data_agent/#geoagent.core.data_agent.DataAgent.search_data","title":"<code>search_data(self, plan)</code>","text":"<p>Search for geospatial data based on the query plan.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>PlannerOutput</code> <p>Structured query parameters from Planner Agent</p> required <p>Returns:</p> Type Description <code>DataResult</code> <p>DataResult containing found data items and metadata</p> Source code in <code>geoagent/core/data_agent.py</code> <pre><code>def search_data(self, plan: PlannerOutput) -&gt; DataResult:\n    \"\"\"Search for geospatial data based on the query plan.\n\n    Args:\n        plan: Structured query parameters from Planner Agent\n\n    Returns:\n        DataResult containing found data items and metadata\n    \"\"\"\n    logger.info(f\"Searching data for intent: {plan.intent}\")\n\n    try:\n        # Determine data type based on intent and dataset\n        data_type = self._determine_data_type(plan)\n\n        if data_type == \"raster\":\n            return self._search_raster_data(plan)\n        elif data_type == \"vector\":\n            return self._search_vector_data(plan)\n        elif data_type == \"tabular\":\n            return self._search_tabular_data(plan)\n        else:\n            # Fallback: try multiple sources\n            return self._search_multi_source(plan)\n\n    except Exception as e:\n        logger.error(f\"Error searching data: {e}\")\n        return DataResult(\n            items=[], metadata={\"error\": str(e)}, data_type=\"unknown\", total_items=0\n        )\n</code></pre>"},{"location":"data_agent/#geoagent.core.data_agent.STACSearchWrapper","title":"<code> STACSearchWrapper        </code>","text":"<p>Wrapper around pystac_client for STAC searches.</p> Source code in <code>geoagent/core/data_agent.py</code> <pre><code>class STACSearchWrapper:\n    \"\"\"Wrapper around pystac_client for STAC searches.\"\"\"\n\n    def __init__(self, catalog_url: str = None):\n        self.catalog_url = (\n            catalog_url or \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        )\n        self._client = None\n\n    @property\n    def client(self):\n        if self._client is None:\n            from pystac_client import Client\n\n            # Use planetary_computer modifier for signed URLs if available\n            modifier = None\n            if \"planetarycomputer\" in self.catalog_url:\n                try:\n                    import planetary_computer\n\n                    modifier = planetary_computer.sign_inplace\n                except ImportError:\n                    logger.warning(\n                        \"planetary_computer not installed. \"\n                        \"Run: pip install planetary-computer\"\n                    )\n\n            self._client = Client.open(self.catalog_url, modifier=modifier)\n        return self._client\n\n    def search(\n        self,\n        bbox=None,\n        datetime=None,\n        collections=None,\n        max_items=10,\n        **kwargs,\n    ):\n        \"\"\"Search STAC catalog and return list of item dicts.\"\"\"\n        search_params = {}\n        if bbox:\n            search_params[\"bbox\"] = bbox\n        if datetime:\n            search_params[\"datetime\"] = datetime\n        if collections:\n            search_params[\"collections\"] = collections\n        if \"query\" in kwargs:\n            search_params[\"query\"] = kwargs.pop(\"query\")\n        search_params[\"limit\"] = max_items\n\n        search = self.client.search(**search_params)\n\n        results = []\n        for item in search.items():\n            if len(results) &gt;= max_items:\n                break\n\n            item_data = {\n                \"id\": item.id,\n                \"collection\": item.collection_id,\n                \"geometry\": item.geometry,\n                \"bbox\": list(item.bbox) if item.bbox else None,\n                \"properties\": item.properties,\n                \"assets\": {},\n            }\n\n            for asset_key, asset in item.assets.items():\n                if asset_key == \"rendered_preview\":\n                    continue\n                item_data[\"assets\"][asset_key] = {\n                    \"href\": asset.href,\n                    \"type\": asset.media_type,\n                    \"title\": asset.title,\n                    \"roles\": asset.roles if asset.roles else [],\n                }\n\n            results.append(item_data)\n\n        return results\n</code></pre>"},{"location":"data_agent/#geoagent.core.data_agent.STACSearchWrapper.search","title":"<code>search(self, bbox=None, datetime=None, collections=None, max_items=10, **kwargs)</code>","text":"<p>Search STAC catalog and return list of item dicts.</p> Source code in <code>geoagent/core/data_agent.py</code> <pre><code>def search(\n    self,\n    bbox=None,\n    datetime=None,\n    collections=None,\n    max_items=10,\n    **kwargs,\n):\n    \"\"\"Search STAC catalog and return list of item dicts.\"\"\"\n    search_params = {}\n    if bbox:\n        search_params[\"bbox\"] = bbox\n    if datetime:\n        search_params[\"datetime\"] = datetime\n    if collections:\n        search_params[\"collections\"] = collections\n    if \"query\" in kwargs:\n        search_params[\"query\"] = kwargs.pop(\"query\")\n    search_params[\"limit\"] = max_items\n\n    search = self.client.search(**search_params)\n\n    results = []\n    for item in search.items():\n        if len(results) &gt;= max_items:\n            break\n\n        item_data = {\n            \"id\": item.id,\n            \"collection\": item.collection_id,\n            \"geometry\": item.geometry,\n            \"bbox\": list(item.bbox) if item.bbox else None,\n            \"properties\": item.properties,\n            \"assets\": {},\n        }\n\n        for asset_key, asset in item.assets.items():\n            if asset_key == \"rendered_preview\":\n                continue\n            item_data[\"assets\"][asset_key] = {\n                \"href\": asset.href,\n                \"type\": asset.media_type,\n                \"title\": asset.title,\n                \"roles\": asset.roles if asset.roles else [],\n            }\n\n        results.append(item_data)\n\n    return results\n</code></pre>"},{"location":"geoagent/","title":"GeoAgent","text":"<p>The main <code>GeoAgent</code> class orchestrates the 4-agent pipeline.</p>"},{"location":"geoagent/#geoagent.core.agent","title":"<code>geoagent.core.agent</code>","text":"<p>Main GeoAgent orchestrator using LangGraph for agent coordination.</p> <p>This module contains the main GeoAgent class that orchestrates the entire geospatial analysis pipeline using multiple specialized agents.</p>"},{"location":"geoagent/#geoagent.core.agent.AgentState","title":"<code> AgentState            (dict)         </code>","text":"<p>State passed between agents in the LangGraph workflow.</p> Source code in <code>geoagent/core/agent.py</code> <pre><code>class AgentState(TypedDict):\n    \"\"\"State passed between agents in the LangGraph workflow.\"\"\"\n\n    query: str\n    plan: Optional[PlannerOutput]\n    data: Optional[DataResult]\n    analysis: Optional[AnalysisResult]\n    map: Optional[Any]\n    code: str\n    error: Optional[str]\n    should_analyze: bool\n    should_visualize: bool\n</code></pre>"},{"location":"geoagent/#geoagent.core.agent.GeoAgent","title":"<code> GeoAgent        </code>","text":"<p>Main GeoAgent orchestrator for geospatial analysis workflows.</p> <p>GeoAgent coordinates multiple specialized agents to perform end-to-end geospatial data analysis from natural language queries.</p> Source code in <code>geoagent/core/agent.py</code> <pre><code>class GeoAgent:\n    \"\"\"Main GeoAgent orchestrator for geospatial analysis workflows.\n\n    GeoAgent coordinates multiple specialized agents to perform end-to-end\n    geospatial data analysis from natural language queries.\n    \"\"\"\n\n    def __init__(\n        self,\n        llm: Optional[Any] = None,\n        provider: Optional[str] = None,\n        model: Optional[str] = None,\n        catalogs: Optional[List[str]] = None,\n    ):\n        \"\"\"Initialize GeoAgent with LLM and configuration.\n\n        Args:\n            llm: Language model instance. If None, uses get_default_llm()\n            provider: LLM provider name (e.g., 'openai', 'anthropic')\n            model: Specific model name\n            catalogs: List of STAC catalog URLs to search\n        \"\"\"\n        self.llm = llm or get_default_llm()\n        self.provider = provider\n        self.model = model\n        self.catalogs = catalogs or []\n\n        # Fetch available collections from the Planetary Computer STAC (with fallback)\n        try:\n            self.collection_index = get_collection_index()\n        except Exception as e:\n            logger.warning(\n                f\"Failed to fetch collection index: {e}. Proceeding without it.\"\n            )\n            self.collection_index = []\n\n        # Initialize specialized agents\n        self.planner = Planner(self.llm, collections=self.collection_index)\n        self.data_agent = DataAgent(self.llm)\n        self.analysis_agent = AnalysisAgent(self.llm)\n        self.viz_agent = VizAgent(self.llm)\n\n        # Initialize workflow graph\n        self.workflow = self._create_workflow()\n\n        logger.info(\"GeoAgent initialized successfully\")\n\n    def chat(\n        self,\n        query: str,\n        target_map: Any = None,\n        status_callback: Optional[Callable[[str], None]] = None,\n    ) -&gt; GeoAgentResponse:\n        \"\"\"Main method to process a natural language query.\n\n        Args:\n            query: Natural language geospatial analysis query\n            target_map: Optional existing map widget to render results on.\n                When provided, layers are added directly to this map\n                instead of creating a new one.\n\n        Returns:\n            GeoAgentResponse with complete pipeline results\n        \"\"\"\n        logger.info(f\"Processing query: {query}\")\n        self._target_map = target_map\n        self._status_callback = status_callback\n        start_time = time.time()\n\n        try:\n            # Initialize state\n            initial_state = AgentState(\n                query=query,\n                plan=None,\n                data=None,\n                analysis=None,\n                map=None,\n                code=\"\",\n                error=None,\n                should_analyze=True,\n                should_visualize=True,\n            )\n\n            # Execute workflow\n            if LANGGRAPH_AVAILABLE and self.workflow:\n                final_state = self.workflow.invoke(initial_state)\n            else:\n                # Fallback to sequential execution\n                final_state = self._sequential_execution(initial_state)\n\n            # Create response\n            execution_time = time.time() - start_time\n\n            response = GeoAgentResponse(\n                plan=final_state[\"plan\"],\n                data=final_state[\"data\"],\n                analysis=final_state[\"analysis\"],\n                map=final_state[\"map\"],\n                code=final_state[\"code\"],\n                success=final_state[\"error\"] is None,\n                error_message=final_state[\"error\"],\n                execution_time=execution_time,\n            )\n\n            logger.info(f\"Query processed successfully in {execution_time:.2f}s\")\n            return response\n\n        except Exception as e:\n            execution_time = time.time() - start_time\n            logger.error(f\"Query processing failed: {e}\")\n\n            return GeoAgentResponse(\n                plan=PlannerOutput(intent=query, confidence=0.0),\n                success=False,\n                error_message=str(e),\n                execution_time=execution_time,\n            )\n        finally:\n            self._status_callback = None\n\n    def _emit_status(self, stage: str) -&gt; None:\n        self._emit_status_detail(stage, None)\n\n    def _emit_status_detail(self, stage: str, detail: Optional[str]) -&gt; None:\n        callback = getattr(self, \"_status_callback\", None)\n        if callback is None:\n            return\n        payload = {\"stage\": stage}\n        if detail:\n            payload[\"detail\"] = detail\n        try:\n            callback(payload)\n            return\n        except TypeError:\n            pass\n        try:\n            if detail:\n                callback(f\"{stage} \u2022 {detail}\")\n            else:\n                callback(stage)\n        except Exception as e:\n            logger.debug(f\"Status callback failed: {e}\")\n\n    @staticmethod\n    def _format_plan_detail(plan: PlannerOutput) -&gt; str:\n        parts: List[str] = []\n        if plan.dataset:\n            parts.append(plan.dataset)\n        if plan.location:\n            name = plan.location.get(\"name\")\n            if name:\n                parts.append(name)\n        if plan.time_range:\n            start = plan.time_range.get(\"start_date\") or \"\"\n            end = plan.time_range.get(\"end_date\") or \"\"\n            if start or end:\n                if start and end:\n                    parts.append(f\"{start} \u2192 {end}\")\n                else:\n                    parts.append(start or end)\n        return \" \u2022 \".join([p for p in parts if p])\n\n    def search(self, query: str) -&gt; DataResult:\n        \"\"\"Shortcut method to just search for data without analysis.\n\n        Args:\n            query: Natural language data search query\n\n        Returns:\n            DataResult with found data\n        \"\"\"\n        logger.info(f\"Data search for: {query}\")\n\n        try:\n            # Parse query into plan\n            plan = self._parse_query(query)\n\n            # Search for data\n            data_result = self.data_agent.search_data(plan)\n\n            logger.info(f\"Found {data_result.total_items} data items\")\n            return data_result\n\n        except Exception as e:\n            logger.error(f\"Data search failed: {e}\")\n            return DataResult(\n                items=[], metadata={\"error\": str(e)}, data_type=\"unknown\", total_items=0\n            )\n\n    def analyze(self, query: str) -&gt; GeoAgentResponse:\n        \"\"\"Shortcut method for search + analysis without visualization.\n\n        Args:\n            query: Natural language analysis query\n\n        Returns:\n            GeoAgentResponse with data and analysis results\n        \"\"\"\n        logger.info(f\"Analysis for: {query}\")\n\n        try:\n            # Parse query\n            plan = self._parse_query(query)\n\n            # Search data\n            data = self.data_agent.search_data(plan)\n\n            # Perform analysis\n            analysis = self.analysis_agent.analyze(plan, data)\n\n            response = GeoAgentResponse(\n                plan=plan,\n                data=data,\n                analysis=analysis,\n                code=analysis.code_generated,\n                success=analysis.success,\n                error_message=analysis.error_message,\n            )\n\n            logger.info(\"Analysis completed\")\n            return response\n\n        except Exception as e:\n            logger.error(f\"Analysis failed: {e}\")\n            return GeoAgentResponse(\n                plan=PlannerOutput(intent=query, confidence=0.0),\n                success=False,\n                error_message=str(e),\n            )\n\n    def visualize(self, query: str) -&gt; GeoAgentResponse:\n        \"\"\"Run full pipeline including MapLibre GL visualization.\n\n        Args:\n            query: Natural language query for complete analysis\n\n        Returns:\n            GeoAgentResponse with MapLibre map visualization\n        \"\"\"\n        return self.chat(query)  # Full pipeline is the same as chat\n\n    def _create_workflow(self) -&gt; Optional[Any]:\n        \"\"\"Create LangGraph workflow for agent coordination.\n\n        Returns:\n            Compiled LangGraph workflow or None if LangGraph unavailable\n        \"\"\"\n        if not LANGGRAPH_AVAILABLE:\n            return None\n\n        try:\n            # Create state graph\n            workflow = StateGraph(AgentState)\n\n            # Add nodes\n            workflow.add_node(\"plan\", self._plan_node)\n            workflow.add_node(\"fetch_data\", self._fetch_data_node)\n            workflow.add_node(\"analyze\", self._analyze_node)\n            workflow.add_node(\"visualize\", self._visualize_node)\n\n            # Define edges\n            workflow.set_entry_point(\"plan\")\n            workflow.add_edge(\"plan\", \"fetch_data\")\n            workflow.add_conditional_edges(\n                \"fetch_data\",\n                self._should_analyze,\n                {True: \"analyze\", False: \"visualize\"},\n            )\n            workflow.add_conditional_edges(\n                \"analyze\", self._should_visualize, {True: \"visualize\", False: END}\n            )\n            workflow.add_edge(\"visualize\", END)\n\n            return workflow.compile()\n\n        except Exception as e:\n            logger.warning(f\"Could not create LangGraph workflow: {e}\")\n            return None\n\n    def _sequential_execution(self, state: AgentState) -&gt; AgentState:\n        \"\"\"Fallback sequential execution when LangGraph is not available.\n\n        Args:\n            state: Initial agent state\n\n        Returns:\n            Final agent state\n        \"\"\"\n        logger.info(\"Using sequential execution (LangGraph not available)\")\n\n        try:\n            # Step 1: Plan\n            state = self._plan_node(state)\n\n            # Step 2: Fetch data\n            state = self._fetch_data_node(state)\n\n            # Step 3: Analyze (if needed)\n            if (\n                state[\"should_analyze\"]\n                and state[\"data\"]\n                and state[\"data\"].total_items &gt; 0\n            ):\n                state = self._analyze_node(state)\n\n            # Step 4: Visualize (if needed)\n            if state[\"should_visualize\"]:\n                state = self._visualize_node(state)\n\n            return state\n\n        except Exception as e:\n            state[\"error\"] = str(e)\n            logger.error(f\"Sequential execution failed: {e}\")\n            return state\n\n    def _plan_node(self, state: AgentState) -&gt; AgentState:\n        \"\"\"Planning node - parse natural language query into structured parameters.\n\n        Args:\n            state: Current agent state\n\n        Returns:\n            Updated state with plan\n        \"\"\"\n        logger.debug(\"Executing planning node\")\n        self._emit_status_detail(\"planning\", \"Parsing intent, location, and time range\")\n\n        try:\n            plan = self._parse_query(state[\"query\"])\n            state[\"plan\"] = plan\n\n            # Determine if we need analysis and visualization\n            intent_lower = plan.intent.lower()\n\n            # Analysis is needed for computational tasks\n            analysis_keywords = [\n                \"calculate\",\n                \"compute\",\n                \"analyze\",\n                \"ndvi\",\n                \"evi\",\n                \"index\",\n                \"statistics\",\n                \"mean\",\n                \"median\",\n                \"change\",\n                \"trend\",\n                \"zonal\",\n            ]\n            needs_analysis = any(kw in intent_lower for kw in analysis_keywords)\n            # Land cover and elevation need analysis routing for proper viz hints\n            analysis_type_hint = (plan.analysis_type or \"\").lower()\n            if analysis_type_hint in (\n                \"land_cover\",\n                \"classification\",\n                \"lulc\",\n                \"elevation\",\n                \"dem\",\n                \"terrain\",\n            ):\n                needs_analysis = True\n            state[\"should_analyze\"] = needs_analysis\n\n            # Visualization is usually desired unless explicitly asking for just data\n            viz_skip_keywords = [\"download\", \"list\", \"count\", \"metadata\"]\n            state[\"should_visualize\"] = not any(\n                kw in intent_lower for kw in viz_skip_keywords\n            )\n\n            logger.debug(\n                f\"Plan created: analyze={state['should_analyze']}, visualize={state['should_visualize']}\"\n            )\n            plan_detail = self._format_plan_detail(plan)\n            if plan_detail:\n                self._emit_status_detail(\"planning\", f\"Plan ready \u2022 {plan_detail}\")\n\n        except Exception as e:\n            state[\"error\"] = f\"Planning failed: {e}\"\n            logger.error(state[\"error\"])\n\n        return state\n\n    def _fetch_data_node(self, state: AgentState) -&gt; AgentState:\n        \"\"\"Data fetching node - search and retrieve geospatial data.\n\n        Args:\n            state: Current agent state\n\n        Returns:\n            Updated state with data\n        \"\"\"\n        logger.debug(\"Executing data fetching node\")\n        if state[\"plan\"]:\n            detail = self._format_plan_detail(state[\"plan\"])\n        else:\n            detail = None\n        self._emit_status_detail(\"fetch_data\", detail or \"Searching catalogs\")\n\n        try:\n            if state[\"plan\"]:\n                data = self.data_agent.search_data(state[\"plan\"])\n                state[\"data\"] = data\n\n                # Generate reproducible search code\n                state[\"code\"] += self._generate_search_code(state[\"plan\"], data)\n\n                logger.debug(\n                    f\"Data fetched: {data.total_items} items of type {data.data_type}\"\n                )\n                self._emit_status_detail(\n                    \"fetch_data\", f\"Found {data.total_items} items\"\n                )\n            else:\n                state[\"error\"] = \"No plan available for data fetching\"\n\n        except Exception as e:\n            state[\"error\"] = f\"Data fetching failed: {e}\"\n            logger.error(state[\"error\"])\n\n        return state\n\n    def _generate_search_code(self, plan: PlannerOutput, data: Any) -&gt; str:\n        \"\"\"Generate reproducible Python code for the STAC search.\n\n        Args:\n            plan: Query plan used for the search\n            data: Search results\n\n        Returns:\n            Python code string\n        \"\"\"\n        bbox = plan.location.get(\"bbox\") if plan.location else None\n        location_name = plan.location.get(\"name\", \"\") if plan.location else \"\"\n        time_range = plan.time_range\n        datetime_str = \"\"\n        if time_range:\n            datetime_str = (\n                f\"{time_range.get('start_date', '')}/{time_range.get('end_date', '')}\"\n            )\n\n        # Build collection: use planner output directly; fallback to Sentinel-2 if absent\n        dataset = plan.dataset\n        collection = dataset if dataset else \"sentinel-2-l2a\"\n\n        # Cloud cover filter only for imagery collections\n        cloud_filter = \"\"\n        imagery_collections = {\n            \"sentinel-2-l2a\",\n            \"landsat-c2-l2\",\n            \"naip\",\n            \"sentinel-1-grd\",\n        }\n        max_cc = plan.parameters.get(\"max_cloud_cover\")\n        if max_cc is not None and collection in imagery_collections:\n            cloud_filter = f'\\n    query={{\"eo:cloud_cover\": {{\"lt\": {max_cc}}}}},'\n\n        code = f'''import planetary_computer\nfrom pystac_client import Client\n\n# Search Planetary Computer STAC catalog{f\" - {location_name}\" if location_name else \"\"}\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\nsearch = catalog.search(\n    collections=[\"{collection}\"],\n    bbox={bbox},{f\"\"\"\n    datetime=\"{datetime_str}\",\"\"\" if datetime_str else \"\"}{cloud_filter}\n    max_items=10,\n)\n\nitems = list(search.items())\nprint(f\"Found {{len(items)}} items\")\nfor item in items:\n    cc = item.properties.get(\"eo:cloud_cover\", \"N/A\")\n    print(f\"  {{item.id}} - cloud cover: {{cc}}%\")\n'''\n        return code\n\n    def _analyze_node(self, state: AgentState) -&gt; AgentState:\n        \"\"\"Analysis node - perform geospatial analysis on data.\n\n        Args:\n            state: Current agent state\n\n        Returns:\n            Updated state with analysis results\n        \"\"\"\n        logger.debug(\"Executing analysis node\")\n        detail = None\n        if state[\"plan\"] and state[\"plan\"].analysis_type:\n            detail = state[\"plan\"].analysis_type.replace(\"_\", \" \")\n        self._emit_status_detail(\"analysis\", detail or \"Running analysis\")\n\n        try:\n            if state[\"plan\"] and state[\"data\"]:\n                analysis = self.analysis_agent.analyze(state[\"plan\"], state[\"data\"])\n                state[\"analysis\"] = analysis\n                state[\"code\"] += analysis.code_generated + \"\\n\"\n\n                if not analysis.success:\n                    state[\"error\"] = analysis.error_message\n\n                logger.debug(f\"Analysis completed: success={analysis.success}\")\n            else:\n                state[\"error\"] = \"Missing plan or data for analysis\"\n\n        except Exception as e:\n            state[\"error\"] = f\"Analysis failed: {e}\"\n            logger.error(state[\"error\"])\n\n        return state\n\n    def _visualize_node(self, state: AgentState) -&gt; AgentState:\n        \"\"\"Visualization node - create map visualization.\n\n        Args:\n            state: Current agent state\n\n        Returns:\n            Updated state with map\n        \"\"\"\n        logger.debug(\"Executing visualization node\")\n        detail = None\n        if state[\"plan\"]:\n            detail = self._format_plan_detail(state[\"plan\"])\n        self._emit_status_detail(\"visualize\", detail or \"Rendering map layers\")\n\n        try:\n            if state[\"plan\"]:\n                viz_map = self.viz_agent.create_visualization(\n                    state[\"plan\"],\n                    state[\"data\"],\n                    state[\"analysis\"],\n                    target_map=getattr(self, \"_target_map\", None),\n                )\n                state[\"map\"] = viz_map\n\n                # Add visualization code\n                state[\"code\"] += self._generate_viz_code(state[\"plan\"], state[\"data\"])\n\n                logger.debug(\"Map visualization created\")\n            else:\n                state[\"error\"] = \"Missing plan for visualization\"\n\n        except Exception as e:\n            state[\"error\"] = f\"Visualization failed: {e}\"\n            logger.error(state[\"error\"])\n\n        return state\n\n    def _generate_viz_code(self, plan: PlannerOutput, data: Any) -&gt; str:\n        \"\"\"Generate reproducible visualization code.\n\n        Args:\n            plan: Query plan\n            data: Data result\n\n        Returns:\n            Python code string for visualization\n        \"\"\"\n        if not data or not data.items:\n            return \"\"\n\n        item = data.items[0]\n        item_id = item.get(\"id\", \"\")\n        collection = item.get(\"collection\", \"\")\n\n        if not collection:\n            return \"\"\n\n        # Determine assets\n        assets = item.get(\"assets\", {})\n        if \"visual\" in assets:\n            assets_str = '\"visual\"'\n        elif \"B04\" in assets and \"B03\" in assets and \"B02\" in assets:\n            assets_str = '[\"B04\", \"B03\", \"B02\"]'\n        elif \"red\" in assets and \"green\" in assets and \"blue\" in assets:\n            assets_str = '[\"red\", \"green\", \"blue\"]'\n        else:\n            assets_str = '\"visual\"'\n\n        code = f\"\"\"\n# Visualize on an interactive map\nimport leafmap.maplibregl as leafmap\n\nm = leafmap.Map()\nm.add_stac_layer(\n    collection=\"{collection}\",\n    item=\"{item_id}\",\n    assets={assets_str},\n    titiler_endpoint=\"planetary-computer\",\n    name=\"{item_id}\",\n    fit_bounds=True,\n)\nm\n\"\"\"\n        return code\n\n    def _should_analyze(self, state: AgentState) -&gt; bool:\n        \"\"\"Conditional edge function to determine if analysis is needed.\n\n        Args:\n            state: Current agent state\n\n        Returns:\n            True if analysis should be performed\n        \"\"\"\n        return (\n            state[\"should_analyze\"]\n            and state[\"data\"] is not None\n            and state[\"data\"].total_items &gt; 0\n            and state[\"error\"] is None\n        )\n\n    def _should_visualize(self, state: AgentState) -&gt; bool:\n        \"\"\"Conditional edge function to determine if visualization is needed.\n\n        Args:\n            state: Current agent state\n\n        Returns:\n            True if visualization should be performed\n        \"\"\"\n        return state[\"should_visualize\"] and state[\"error\"] is None\n\n    def _parse_query(self, query: str) -&gt; PlannerOutput:\n        \"\"\"Parse natural language query into structured plan.\n\n        Uses LLM for intent/parameter extraction, then geocodes the location.\n        Falls back to regex-based parsing if LLM fails.\n\n        Args:\n            query: Natural language query\n\n        Returns:\n            PlannerOutput with parsed parameters\n        \"\"\"\n        logger.debug(f\"Parsing query: {query}\")\n\n        try:\n            # Use LLM-based planner for robust parsing\n            plan = self.planner.parse_query(query)\n            logger.info(\n                f\"LLM parsed: location={plan.location}, time={plan.time_range}, \"\n                f\"dataset={plan.dataset}, params={plan.parameters}\"\n            )\n\n            # Geocode location name to bbox if needed\n            if (\n                plan.location\n                and \"name\" in plan.location\n                and \"bbox\" not in plan.location\n            ):\n                geocoded = self._geocode_location(plan.location[\"name\"])\n                if geocoded:\n                    plan.location = geocoded\n                else:\n                    logger.warning(f\"Could not geocode: {plan.location['name']}\")\n\n            # Post-process: LLM sometimes puts time_range in parameters\n            if plan.time_range is None and \"time_range\" in plan.parameters:\n                tr = plan.parameters.pop(\"time_range\")\n                if isinstance(tr, (list, tuple)) and len(tr) == 2:\n                    plan.time_range = {\n                        \"start_date\": tr[0],\n                        \"end_date\": tr[1],\n                    }\n\n            # Post-process: normalize cloud cover thresholds\n            cc = plan.parameters.get(\"cloud_cover\")\n            if cc is not None:\n                # \"cloud-free\" (0) is unrealistic; use 10% threshold\n                if cc &lt;= 0:\n                    plan.parameters[\"cloud_cover\"] = 10\n                plan.parameters[\"max_cloud_cover\"] = plan.parameters.pop(\"cloud_cover\")\n\n            return plan\n\n        except Exception as e:\n            logger.warning(f\"LLM planner failed ({e}), falling back to regex parser\")\n            return self._parse_query_fallback(query)\n\n    def _parse_query_fallback(self, query: str) -&gt; PlannerOutput:\n        \"\"\"Fallback regex-based query parser when LLM is unavailable.\n\n        Args:\n            query: Natural language query\n\n        Returns:\n            PlannerOutput with parsed parameters\n        \"\"\"\n        query_lower = query.lower()\n        intent = query.strip()\n\n        location = self._extract_location(query)\n        time_range = self._extract_time_range(query_lower)\n\n        dataset = None\n        analysis_type = None\n        if \"sentinel-1\" in query_lower:\n            dataset = \"sentinel-1-grd\"\n        elif \"sentinel\" in query_lower or \"sentinel-2\" in query_lower:\n            dataset = \"sentinel-2-l2a\"\n        elif \"landsat\" in query_lower:\n            dataset = \"landsat-c2-l2\"\n        elif \"naip\" in query_lower:\n            dataset = \"naip\"\n        elif \"modis\" in query_lower:\n            dataset = \"modis-09A1-061\"\n        elif any(\n            kw in query_lower for kw in [\"land cover\", \"landcover\", \"lulc\", \"land use\"]\n        ):\n            dataset = \"io-lulc-9-class\"\n            analysis_type = \"land_cover\"\n        elif any(kw in query_lower for kw in [\"dem\", \"elevation\", \"terrain\"]):\n            dataset = \"cop-dem-glo-30\"\n            analysis_type = \"elevation\"\n\n        parameters = {}\n        if \"cloud-free\" in query_lower or \"cloud free\" in query_lower:\n            parameters[\"max_cloud_cover\"] = 10\n        elif \"low cloud\" in query_lower or \"low-cloud\" in query_lower:\n            parameters[\"max_cloud_cover\"] = 20\n        elif \"cloud cover\" in query_lower or \"cloudy\" in query_lower:\n            parameters[\"max_cloud_cover\"] = 20\n\n        return PlannerOutput(\n            intent=intent,\n            location=location,\n            time_range=time_range,\n            dataset=dataset,\n            analysis_type=analysis_type,\n            parameters=parameters,\n            confidence=0.5,\n        )\n\n    def _geocode_location(self, place_name: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Geocode a place name to a bbox.\n\n        Args:\n            place_name: Place name string (e.g., \"Knoxville\", \"San Francisco\")\n\n        Returns:\n            Location dict with bbox and name, or None\n        \"\"\"\n        try:\n            from geopy.geocoders import Nominatim\n\n            geolocator = Nominatim(user_agent=\"geoagent\")\n            result = geolocator.geocode(place_name, exactly_one=True, timeout=5)\n\n            if result:\n                lat, lon = result.latitude, result.longitude\n                bbox = [lon - 0.1, lat - 0.1, lon + 0.1, lat + 0.1]\n                name = result.address.split(\",\")[0]\n                logger.info(f\"Geocoded '{place_name}' -&gt; {name} ({lat:.4f}, {lon:.4f})\")\n                return {\"bbox\": bbox, \"name\": name}\n        except ImportError:\n            logger.warning(\"geopy not installed\")\n        except Exception as e:\n            logger.warning(f\"Geocoding failed for '{place_name}': {e}\")\n\n        # Try fallback city lookup\n        return self._extract_location_fallback(place_name.lower())\n\n    def _extract_location(self, query: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Extract location from query using geocoding (for regex fallback parser).\n\n        Tries to find a place name in the query and geocode it to a bbox.\n\n        Args:\n            query: Natural language query\n\n        Returns:\n            Location dict with bbox and name, or None\n        \"\"\"\n        try:\n            from geopy.geocoders import Nominatim\n\n            geolocator = Nominatim(user_agent=\"geoagent\")\n\n            # Try to extract place name - remove common non-location words\n            import re\n\n            # Remove analysis terms to isolate location\n            cleaned = re.sub(\n                r\"\\b(show|display|compute|calculate|analyze|find|get|plot|map|\"\n                r\"ndvi|evi|savi|imagery|image|images|satellite|sentinel-?\\d*|landsat|\"\n                r\"modis|for|in|of|the|from|during|between|and|with|using|\"\n                r\"cloud[- ]?free|low[- ]?cloud|cloud\\s*cover|cloudy|\"\n                r\"recent|latest|best|high[- ]?resolution|\"\n                r\"january|february|march|april|may|june|july|august|\"\n                r\"september|october|november|december|\"\n                r\"jan|feb|mar|apr|jun|jul|aug|sep|oct|nov|dec|\"\n                r\"\\d{4})\\b\",\n                \"\",\n                query,\n                flags=re.IGNORECASE,\n            ).strip()\n\n            # Clean up extra whitespace\n            cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip(\" ,.-\")\n\n            if not cleaned or len(cleaned) &lt; 2:\n                logger.debug(\"No location found in query\")\n                return None\n\n            logger.debug(f\"Geocoding: '{cleaned}'\")\n            result = geolocator.geocode(cleaned, exactly_one=True, timeout=5)\n\n            if result:\n                lat, lon = result.latitude, result.longitude\n                # Create bbox around the point (~0.1 degrees \u2248 10km)\n                bbox = [lon - 0.1, lat - 0.1, lon + 0.1, lat + 0.1]\n                name = result.address.split(\",\")[0]\n                logger.info(f\"Geocoded '{cleaned}' -&gt; {name} ({lat:.4f}, {lon:.4f})\")\n                return {\"bbox\": bbox, \"name\": name}\n            else:\n                logger.warning(f\"Could not geocode: '{cleaned}'\")\n                return None\n\n        except ImportError:\n            logger.warning(\"geopy not installed, using fallback location parsing\")\n            return self._extract_location_fallback(query.lower())\n        except Exception as e:\n            logger.warning(f\"Geocoding failed: {e}\")\n            return self._extract_location_fallback(query.lower())\n\n    def _extract_location_fallback(self, query_lower: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Fallback location extraction using hardcoded city lookups.\n\n        Args:\n            query_lower: Lowercased query string\n\n        Returns:\n            Location dict or None\n        \"\"\"\n        cities = {\n            \"san francisco\": {\n                \"bbox\": [-122.5, 37.7, -122.3, 37.8],\n                \"name\": \"San Francisco\",\n            },\n            \"new york\": {\"bbox\": [-74.1, 40.6, -73.9, 40.8], \"name\": \"New York\"},\n            \"los angeles\": {\n                \"bbox\": [-118.4, 33.9, -118.1, 34.1],\n                \"name\": \"Los Angeles\",\n            },\n            \"chicago\": {\"bbox\": [-87.8, 41.7, -87.5, 42.0], \"name\": \"Chicago\"},\n            \"seattle\": {\"bbox\": [-122.4, 47.5, -122.2, 47.7], \"name\": \"Seattle\"},\n            \"denver\": {\"bbox\": [-105.1, 39.6, -104.8, 39.8], \"name\": \"Denver\"},\n            \"houston\": {\"bbox\": [-95.5, 29.6, -95.2, 29.9], \"name\": \"Houston\"},\n            \"miami\": {\"bbox\": [-80.3, 25.7, -80.1, 25.9], \"name\": \"Miami\"},\n            \"california\": {\"bbox\": [-124.4, 32.5, -114.1, 42.0], \"name\": \"California\"},\n        }\n        for city, loc in cities.items():\n            if city in query_lower:\n                return loc\n        return None\n\n    def _extract_time_range(self, query_lower: str) -&gt; Optional[Dict[str, str]]:\n        \"\"\"Extract time range from query text.\n\n        Handles patterns like 'July 2024', 'in 2025', 'June 2023', etc.\n\n        Args:\n            query_lower: Lowercased query string\n\n        Returns:\n            Dict with start_date and end_date, or None\n        \"\"\"\n        import re\n\n        months = {\n            \"january\": (\"01\", \"31\"),\n            \"jan\": (\"01\", \"31\"),\n            \"february\": (\"02\", \"28\"),\n            \"feb\": (\"02\", \"28\"),\n            \"march\": (\"03\", \"31\"),\n            \"mar\": (\"03\", \"31\"),\n            \"april\": (\"04\", \"30\"),\n            \"apr\": (\"04\", \"30\"),\n            \"may\": (\"05\", \"31\"),\n            \"june\": (\"06\", \"30\"),\n            \"jun\": (\"06\", \"30\"),\n            \"july\": (\"07\", \"31\"),\n            \"jul\": (\"07\", \"31\"),\n            \"august\": (\"08\", \"31\"),\n            \"aug\": (\"08\", \"31\"),\n            \"september\": (\"09\", \"30\"),\n            \"sep\": (\"09\", \"30\"),\n            \"october\": (\"10\", \"31\"),\n            \"oct\": (\"10\", \"31\"),\n            \"november\": (\"11\", \"30\"),\n            \"nov\": (\"11\", \"30\"),\n            \"december\": (\"12\", \"31\"),\n            \"dec\": (\"12\", \"31\"),\n        }\n\n        # Match \"Month YYYY\" or \"YYYY\" patterns\n        for month_name, (month_num, last_day) in months.items():\n            pattern = rf\"\\b{month_name}\\s+(\\d{{4}})\\b\"\n            match = re.search(pattern, query_lower)\n            if match:\n                year = match.group(1)\n                return {\n                    \"start_date\": f\"{year}-{month_num}-01\",\n                    \"end_date\": f\"{year}-{month_num}-{last_day}\",\n                }\n\n        # Match bare year\n        year_match = re.search(r\"\\b(20\\d{2})\\b\", query_lower)\n        if year_match:\n            year = year_match.group(1)\n            return {\"start_date\": f\"{year}-01-01\", \"end_date\": f\"{year}-12-31\"}\n\n        return None\n</code></pre>"},{"location":"geoagent/#geoagent.core.agent.GeoAgent.__init__","title":"<code>__init__(self, llm=None, provider=None, model=None, catalogs=None)</code>  <code>special</code>","text":"<p>Initialize GeoAgent with LLM and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>Optional[Any]</code> <p>Language model instance. If None, uses get_default_llm()</p> <code>None</code> <code>provider</code> <code>Optional[str]</code> <p>LLM provider name (e.g., 'openai', 'anthropic')</p> <code>None</code> <code>model</code> <code>Optional[str]</code> <p>Specific model name</p> <code>None</code> <code>catalogs</code> <code>Optional[List[str]]</code> <p>List of STAC catalog URLs to search</p> <code>None</code> Source code in <code>geoagent/core/agent.py</code> <pre><code>def __init__(\n    self,\n    llm: Optional[Any] = None,\n    provider: Optional[str] = None,\n    model: Optional[str] = None,\n    catalogs: Optional[List[str]] = None,\n):\n    \"\"\"Initialize GeoAgent with LLM and configuration.\n\n    Args:\n        llm: Language model instance. If None, uses get_default_llm()\n        provider: LLM provider name (e.g., 'openai', 'anthropic')\n        model: Specific model name\n        catalogs: List of STAC catalog URLs to search\n    \"\"\"\n    self.llm = llm or get_default_llm()\n    self.provider = provider\n    self.model = model\n    self.catalogs = catalogs or []\n\n    # Fetch available collections from the Planetary Computer STAC (with fallback)\n    try:\n        self.collection_index = get_collection_index()\n    except Exception as e:\n        logger.warning(\n            f\"Failed to fetch collection index: {e}. Proceeding without it.\"\n        )\n        self.collection_index = []\n\n    # Initialize specialized agents\n    self.planner = Planner(self.llm, collections=self.collection_index)\n    self.data_agent = DataAgent(self.llm)\n    self.analysis_agent = AnalysisAgent(self.llm)\n    self.viz_agent = VizAgent(self.llm)\n\n    # Initialize workflow graph\n    self.workflow = self._create_workflow()\n\n    logger.info(\"GeoAgent initialized successfully\")\n</code></pre>"},{"location":"geoagent/#geoagent.core.agent.GeoAgent.analyze","title":"<code>analyze(self, query)</code>","text":"<p>Shortcut method for search + analysis without visualization.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Natural language analysis query</p> required <p>Returns:</p> Type Description <code>GeoAgentResponse</code> <p>GeoAgentResponse with data and analysis results</p> Source code in <code>geoagent/core/agent.py</code> <pre><code>def analyze(self, query: str) -&gt; GeoAgentResponse:\n    \"\"\"Shortcut method for search + analysis without visualization.\n\n    Args:\n        query: Natural language analysis query\n\n    Returns:\n        GeoAgentResponse with data and analysis results\n    \"\"\"\n    logger.info(f\"Analysis for: {query}\")\n\n    try:\n        # Parse query\n        plan = self._parse_query(query)\n\n        # Search data\n        data = self.data_agent.search_data(plan)\n\n        # Perform analysis\n        analysis = self.analysis_agent.analyze(plan, data)\n\n        response = GeoAgentResponse(\n            plan=plan,\n            data=data,\n            analysis=analysis,\n            code=analysis.code_generated,\n            success=analysis.success,\n            error_message=analysis.error_message,\n        )\n\n        logger.info(\"Analysis completed\")\n        return response\n\n    except Exception as e:\n        logger.error(f\"Analysis failed: {e}\")\n        return GeoAgentResponse(\n            plan=PlannerOutput(intent=query, confidence=0.0),\n            success=False,\n            error_message=str(e),\n        )\n</code></pre>"},{"location":"geoagent/#geoagent.core.agent.GeoAgent.chat","title":"<code>chat(self, query, target_map=None, status_callback=None)</code>","text":"<p>Main method to process a natural language query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Natural language geospatial analysis query</p> required <code>target_map</code> <code>Any</code> <p>Optional existing map widget to render results on. When provided, layers are added directly to this map instead of creating a new one.</p> <code>None</code> <p>Returns:</p> Type Description <code>GeoAgentResponse</code> <p>GeoAgentResponse with complete pipeline results</p> Source code in <code>geoagent/core/agent.py</code> <pre><code>def chat(\n    self,\n    query: str,\n    target_map: Any = None,\n    status_callback: Optional[Callable[[str], None]] = None,\n) -&gt; GeoAgentResponse:\n    \"\"\"Main method to process a natural language query.\n\n    Args:\n        query: Natural language geospatial analysis query\n        target_map: Optional existing map widget to render results on.\n            When provided, layers are added directly to this map\n            instead of creating a new one.\n\n    Returns:\n        GeoAgentResponse with complete pipeline results\n    \"\"\"\n    logger.info(f\"Processing query: {query}\")\n    self._target_map = target_map\n    self._status_callback = status_callback\n    start_time = time.time()\n\n    try:\n        # Initialize state\n        initial_state = AgentState(\n            query=query,\n            plan=None,\n            data=None,\n            analysis=None,\n            map=None,\n            code=\"\",\n            error=None,\n            should_analyze=True,\n            should_visualize=True,\n        )\n\n        # Execute workflow\n        if LANGGRAPH_AVAILABLE and self.workflow:\n            final_state = self.workflow.invoke(initial_state)\n        else:\n            # Fallback to sequential execution\n            final_state = self._sequential_execution(initial_state)\n\n        # Create response\n        execution_time = time.time() - start_time\n\n        response = GeoAgentResponse(\n            plan=final_state[\"plan\"],\n            data=final_state[\"data\"],\n            analysis=final_state[\"analysis\"],\n            map=final_state[\"map\"],\n            code=final_state[\"code\"],\n            success=final_state[\"error\"] is None,\n            error_message=final_state[\"error\"],\n            execution_time=execution_time,\n        )\n\n        logger.info(f\"Query processed successfully in {execution_time:.2f}s\")\n        return response\n\n    except Exception as e:\n        execution_time = time.time() - start_time\n        logger.error(f\"Query processing failed: {e}\")\n\n        return GeoAgentResponse(\n            plan=PlannerOutput(intent=query, confidence=0.0),\n            success=False,\n            error_message=str(e),\n            execution_time=execution_time,\n        )\n    finally:\n        self._status_callback = None\n</code></pre>"},{"location":"geoagent/#geoagent.core.agent.GeoAgent.search","title":"<code>search(self, query)</code>","text":"<p>Shortcut method to just search for data without analysis.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Natural language data search query</p> required <p>Returns:</p> Type Description <code>DataResult</code> <p>DataResult with found data</p> Source code in <code>geoagent/core/agent.py</code> <pre><code>def search(self, query: str) -&gt; DataResult:\n    \"\"\"Shortcut method to just search for data without analysis.\n\n    Args:\n        query: Natural language data search query\n\n    Returns:\n        DataResult with found data\n    \"\"\"\n    logger.info(f\"Data search for: {query}\")\n\n    try:\n        # Parse query into plan\n        plan = self._parse_query(query)\n\n        # Search for data\n        data_result = self.data_agent.search_data(plan)\n\n        logger.info(f\"Found {data_result.total_items} data items\")\n        return data_result\n\n    except Exception as e:\n        logger.error(f\"Data search failed: {e}\")\n        return DataResult(\n            items=[], metadata={\"error\": str(e)}, data_type=\"unknown\", total_items=0\n        )\n</code></pre>"},{"location":"geoagent/#geoagent.core.agent.GeoAgent.visualize","title":"<code>visualize(self, query)</code>","text":"<p>Run full pipeline including MapLibre GL visualization.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Natural language query for complete analysis</p> required <p>Returns:</p> Type Description <code>GeoAgentResponse</code> <p>GeoAgentResponse with MapLibre map visualization</p> Source code in <code>geoagent/core/agent.py</code> <pre><code>def visualize(self, query: str) -&gt; GeoAgentResponse:\n    \"\"\"Run full pipeline including MapLibre GL visualization.\n\n    Args:\n        query: Natural language query for complete analysis\n\n    Returns:\n        GeoAgentResponse with MapLibre map visualization\n    \"\"\"\n    return self.chat(query)  # Full pipeline is the same as chat\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable Release","text":"<p>To install GeoAgent, run this command in your terminal:</p> <pre><code>pip install geoagent\n</code></pre> <p>Or install from conda-forge:</p> <pre><code>conda install -c conda-forge geoagent\n</code></pre> <p>This installs the core package with OpenAI support.</p>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"installation/#additional-llm-providers","title":"Additional LLM Providers","text":"<p>To use Anthropic Claude or Google Gemini:</p> <pre><code>pip install \"geoagent[llm]\"\n</code></pre>"},{"location":"installation/#local-llm-with-ollama","title":"Local LLM with Ollama","text":"<p>For offline or air-gapped environments:</p> <pre><code>pip install \"geoagent[ollama]\"\n</code></pre> <p>Make sure Ollama is installed and running locally.</p>"},{"location":"installation/#web-ui","title":"Web UI","text":"<p>For the Solara-based web interface:</p> <pre><code>pip install \"geoagent[ui]\"\n</code></pre>"},{"location":"installation/#everything","title":"Everything","text":"<p>To install all optional dependencies:</p> <pre><code>pip install \"geoagent[all]\"\n</code></pre>"},{"location":"installation/#from-source","title":"From Source","text":"<p>To install the latest development version:</p> <pre><code>pip install git+https://github.com/opengeos/GeoAgent\n</code></pre> <p>Or clone and install in editable mode:</p> <pre><code>git clone https://github.com/opengeos/GeoAgent.git\ncd GeoAgent\npip install -e \".[all]\"\n</code></pre>"},{"location":"installation/#llm-configuration","title":"LLM Configuration","text":"<p>GeoAgent needs an LLM provider to function. Set one of these environment variables:</p> <pre><code># OpenAI (default)\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Anthropic Claude\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n\n# Google Gemini\nexport GOOGLE_API_KEY=\"AI...\"\n</code></pre> <p>For Ollama, no API key is needed. Just make sure the Ollama server is running:</p> <pre><code>ollama serve\nollama pull llama3.1\n</code></pre> <p>GeoAgent automatically detects available providers and uses the first one found (in order: OpenAI, Anthropic, Google, Ollama).</p>"},{"location":"llm/","title":"LLM Provider","text":"<p>Multi-provider LLM abstraction supporting OpenAI, Anthropic, Google Gemini, and Ollama.</p>"},{"location":"llm/#geoagent.core.llm","title":"<code>geoagent.core.llm</code>","text":"<p>LLM provider abstraction for GeoAgent.</p> <p>Provides a unified interface for multiple LLM providers including OpenAI, Anthropic, Google Gemini, and Ollama (local).</p>"},{"location":"llm/#geoagent.core.llm.MockLLM","title":"<code> MockLLM        </code>","text":"<p>Mock LLM for testing and development when no real LLM is available.</p> Source code in <code>geoagent/core/llm.py</code> <pre><code>class MockLLM:\n    \"\"\"Mock LLM for testing and development when no real LLM is available.\"\"\"\n\n    def __init__(self, name: str = \"MockLLM\"):\n        self.name = name\n\n    def invoke(self, prompt: str) -&gt; str:\n        \"\"\"Mock LLM invocation.\n\n        Args:\n            prompt: Input prompt\n\n        Returns:\n            Mock response\n        \"\"\"\n        return f\"Mock response to: {prompt[:100]}...\"\n\n    def __str__(self) -&gt; str:\n        return self.name\n</code></pre>"},{"location":"llm/#geoagent.core.llm.MockLLM.invoke","title":"<code>invoke(self, prompt)</code>","text":"<p>Mock LLM invocation.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>Input prompt</p> required <p>Returns:</p> Type Description <code>str</code> <p>Mock response</p> Source code in <code>geoagent/core/llm.py</code> <pre><code>def invoke(self, prompt: str) -&gt; str:\n    \"\"\"Mock LLM invocation.\n\n    Args:\n        prompt: Input prompt\n\n    Returns:\n        Mock response\n    \"\"\"\n    return f\"Mock response to: {prompt[:100]}...\"\n</code></pre>"},{"location":"llm/#geoagent.core.llm.check_api_keys","title":"<code>check_api_keys()</code>","text":"<p>Check which LLM API keys are available in the environment.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping provider names to whether their API key is set.</p> Source code in <code>geoagent/core/llm.py</code> <pre><code>def check_api_keys() -&gt; Dict[str, bool]:\n    \"\"\"Check which LLM API keys are available in the environment.\n\n    Returns:\n        Dictionary mapping provider names to whether their API key is set.\n    \"\"\"\n    return {\n        name: config[\"env_var\"] is None or bool(os.getenv(config[\"env_var\"]))\n        for name, config in PROVIDERS.items()\n    }\n</code></pre>"},{"location":"llm/#geoagent.core.llm.get_available_providers","title":"<code>get_available_providers()</code>","text":"<p>Get list of available LLM providers based on installed packages and API keys.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available provider names.</p> Source code in <code>geoagent/core/llm.py</code> <pre><code>def get_available_providers() -&gt; List[str]:\n    \"\"\"Get list of available LLM providers based on installed packages and API keys.\n\n    Returns:\n        List of available provider names.\n    \"\"\"\n    available = []\n    for name, config in PROVIDERS.items():\n        env_var = config[\"env_var\"]\n        has_key = env_var is None or bool(os.getenv(env_var))\n\n        if not has_key:\n            continue\n\n        try:\n            if name == \"openai\":\n                import langchain_openai  # noqa: F401\n            elif name == \"anthropic\":\n                import langchain_anthropic  # noqa: F401\n            elif name == \"google\":\n                import langchain_google_genai  # noqa: F401\n            elif name == \"ollama\":\n                import langchain_ollama  # noqa: F401\n            available.append(name)\n        except ImportError:\n            pass\n\n    return available\n</code></pre>"},{"location":"llm/#geoagent.core.llm.get_default_llm","title":"<code>get_default_llm(temperature=0.1, **kwargs)</code>","text":"<p>Get a default LLM by checking available API keys.</p> <p>Checks environment variables in order: OpenAI, Anthropic, Google, Ollama. Returns the first available provider.</p> <p>Parameters:</p> Name Type Description Default <code>temperature</code> <code>float</code> <p>Sampling temperature.</p> <code>0.1</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the LLM constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>A LangChain BaseChatModel instance.</p> <p>Exceptions:</p> Type Description <code>RuntimeError</code> <p>If no LLM provider is available.</p> Source code in <code>geoagent/core/llm.py</code> <pre><code>def get_default_llm(temperature: float = 0.1, **kwargs) -&gt; Any:\n    \"\"\"Get a default LLM by checking available API keys.\n\n    Checks environment variables in order: OpenAI, Anthropic, Google, Ollama.\n    Returns the first available provider.\n\n    Args:\n        temperature: Sampling temperature.\n        **kwargs: Additional keyword arguments passed to the LLM constructor.\n\n    Returns:\n        A LangChain BaseChatModel instance.\n\n    Raises:\n        RuntimeError: If no LLM provider is available.\n    \"\"\"\n    # Try providers in priority order\n    for provider_name, config in PROVIDERS.items():\n        env_var = config[\"env_var\"]\n\n        # Ollama has no API key requirement\n        if env_var is None:\n            try:\n                return get_llm(\n                    provider=provider_name, temperature=temperature, **kwargs\n                )\n            except ImportError:\n                continue\n\n        # Check if API key is set\n        if os.getenv(env_var):\n            try:\n                return get_llm(\n                    provider=provider_name, temperature=temperature, **kwargs\n                )\n            except ImportError:\n                logger.warning(\n                    f\"{config['package']} not installed, skipping {provider_name}\"\n                )\n                continue\n\n    # Return MockLLM when no providers are available\n    logger.warning(\"No LLM provider available, using MockLLM\")\n    return MockLLM()\n</code></pre>"},{"location":"llm/#geoagent.core.llm.get_llm","title":"<code>get_llm(provider='openai', model=None, temperature=0.1, max_tokens=4096, **kwargs)</code>","text":"<p>Create an LLM instance for the specified provider.</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>str</code> <p>LLM provider name (\"openai\", \"anthropic\", \"google\", \"ollama\").</p> <code>'openai'</code> <code>model</code> <code>Optional[str]</code> <p>Model name. Uses provider default if None.</p> <code>None</code> <code>temperature</code> <code>float</code> <p>Sampling temperature (0.0 to 1.0).</p> <code>0.1</code> <code>max_tokens</code> <code>int</code> <p>Maximum tokens in the response.</p> <code>4096</code> <code>**kwargs</code> <p>Additional provider-specific keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>A LangChain BaseChatModel instance.</p> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If the provider is not supported.</p> <code>ImportError</code> <p>If the required package is not installed.</p> <code>RuntimeError</code> <p>If the API key is missing.</p> Source code in <code>geoagent/core/llm.py</code> <pre><code>def get_llm(\n    provider: str = \"openai\",\n    model: Optional[str] = None,\n    temperature: float = 0.1,\n    max_tokens: int = 4096,\n    **kwargs,\n) -&gt; Any:\n    \"\"\"Create an LLM instance for the specified provider.\n\n    Args:\n        provider: LLM provider name (\"openai\", \"anthropic\", \"google\", \"ollama\").\n        model: Model name. Uses provider default if None.\n        temperature: Sampling temperature (0.0 to 1.0).\n        max_tokens: Maximum tokens in the response.\n        **kwargs: Additional provider-specific keyword arguments.\n\n    Returns:\n        A LangChain BaseChatModel instance.\n\n    Raises:\n        ValueError: If the provider is not supported.\n        ImportError: If the required package is not installed.\n        RuntimeError: If the API key is missing.\n    \"\"\"\n    provider = provider.lower()\n    if provider not in PROVIDERS:\n        supported = \", \".join(PROVIDERS.keys())\n        raise ValueError(f\"Unsupported provider '{provider}'. Supported: {supported}\")\n\n    config = PROVIDERS[provider]\n    resolved_model = model or config[\"default_model\"]\n\n    # Check API key (not needed for Ollama)\n    if config[\"env_var\"] and not os.getenv(config[\"env_var\"]):\n        raise RuntimeError(\n            f\"API key not found. Set the {config['env_var']} environment variable.\"\n        )\n\n    if provider == \"openai\":\n        try:\n            from langchain_openai import ChatOpenAI\n        except ImportError:\n            raise ImportError(\n                \"langchain-openai is not installed. Run: pip install langchain-openai\"\n            )\n        return ChatOpenAI(\n            model=resolved_model,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            **kwargs,\n        )\n\n    elif provider == \"anthropic\":\n        try:\n            from langchain_anthropic import ChatAnthropic\n        except ImportError:\n            raise ImportError(\n                \"langchain-anthropic is not installed. Run: pip install langchain-anthropic\"\n            )\n        return ChatAnthropic(\n            model=resolved_model,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            **kwargs,\n        )\n\n    elif provider == \"google\":\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError:\n            raise ImportError(\n                \"langchain-google-genai is not installed. Run: pip install langchain-google-genai\"\n            )\n        return ChatGoogleGenerativeAI(\n            model=resolved_model,\n            temperature=temperature,\n            max_output_tokens=max_tokens,\n            **kwargs,\n        )\n\n    elif provider == \"ollama\":\n        try:\n            from langchain_ollama import ChatOllama\n        except ImportError:\n            raise ImportError(\n                \"langchain-ollama is not installed. Run: pip install langchain-ollama\"\n            )\n        return ChatOllama(\n            model=resolved_model,\n            temperature=temperature,\n            **kwargs,\n        )\n</code></pre>"},{"location":"models/","title":"Data Models","text":"<p>Core data models used throughout GeoAgent for structured data exchange between agents.</p>"},{"location":"models/#geoagent.core.models","title":"<code>geoagent.core.models</code>","text":"<p>Shared Pydantic models for GeoAgent components.</p> <p>This module contains all shared data models used across the GeoAgent pipeline to avoid circular dependencies between modules.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult","title":"<code> AnalysisResult            (BaseModel)         </code>","text":"<p>Result from the Analysis Agent containing computed analysis.</p> Source code in <code>geoagent/core/models.py</code> <pre><code>class AnalysisResult(BaseModel):\n    \"\"\"Result from the Analysis Agent containing computed analysis.\"\"\"\n\n    result_data: Union[Dict[str, Any], List[Any]] = Field(\n        description=\"The computed analysis results (summary statistics, arrays, etc.)\"\n    )\n    code_generated: str = Field(\n        description=\"Python code that was generated and executed for transparency\"\n    )\n    visualization_hints: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Suggested visualization parameters (colormap, ranges, etc.)\",\n    )\n    success: bool = Field(\n        default=True, description=\"Whether the analysis completed successfully\"\n    )\n    error_message: Optional[str] = Field(\n        default=None, description=\"Error message if analysis failed\"\n    )\n</code></pre>"},{"location":"models/#geoagent.core.models.AnalysisResult.__class_vars__","title":"<code>__class_vars__</code>  <code>special</code>","text":"<p>The names of the class variables defined on the model.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__private_attributes__","title":"<code>__private_attributes__</code>  <code>special</code>","text":"<p>Metadata about the private attributes of the model.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_complete__","title":"<code>__pydantic_complete__</code>  <code>special</code>","text":"<p>Whether model building is completed, or if there are still undefined fields.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_computed_fields__","title":"<code>__pydantic_computed_fields__</code>  <code>special</code>","text":"<p>A dictionary of computed field names and their corresponding [<code>ComputedFieldInfo</code>][pydantic.fields.ComputedFieldInfo] objects.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_custom_init__","title":"<code>__pydantic_custom_init__</code>  <code>special</code>","text":"<p>Whether the model has a custom <code>__init__</code> method.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_decorators__","title":"<code>__pydantic_decorators__</code>  <code>special</code>","text":"<p>Metadata containing the decorators defined on the model. This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_fields__","title":"<code>__pydantic_fields__</code>  <code>special</code>","text":"<p>A dictionary of field names and their corresponding [<code>FieldInfo</code>][pydantic.fields.FieldInfo] objects. This replaces <code>Model.__fields__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_generic_metadata__","title":"<code>__pydantic_generic_metadata__</code>  <code>special</code>","text":"<p>Metadata for generic models; contains data used for a similar purpose to args, origin, parameters in typing-module generics. May eventually be replaced by these.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_parent_namespace__","title":"<code>__pydantic_parent_namespace__</code>  <code>special</code>","text":"<p>Parent namespace of the model, used for automatic rebuilding of models.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_post_init__","title":"<code>__pydantic_post_init__</code>  <code>special</code>","text":"<p>The name of the post-init method for the model, if defined.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__pydantic_setattr_handlers__","title":"<code>__pydantic_setattr_handlers__</code>  <code>special</code>","text":"<p><code>__setattr__</code> handlers. Memoizing the handlers leads to a dramatic performance improvement in <code>__setattr__</code></p>"},{"location":"models/#geoagent.core.models.AnalysisResult.__signature__","title":"<code>__signature__</code>  <code>special</code>","text":"<p>The synthesized <code>__init__</code> [<code>Signature</code>][inspect.Signature] of the model.</p>"},{"location":"models/#geoagent.core.models.AnalysisResult.model_config","title":"<code>model_config</code>","text":"<p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>"},{"location":"models/#geoagent.core.models.DataResult","title":"<code> DataResult            (BaseModel)         </code>","text":"<p>Result from the Data Agent containing retrieved geospatial data.</p> Source code in <code>geoagent/core/models.py</code> <pre><code>class DataResult(BaseModel):\n    \"\"\"Result from the Data Agent containing retrieved geospatial data.\"\"\"\n\n    items: List[Dict[str, Any]] = Field(\n        description=\"List of STAC items or data references\"\n    )\n    metadata: Dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional metadata about the data search\"\n    )\n    data_type: str = Field(\n        description=\"Type of data retrieved: 'raster', 'vector', or 'tabular'\"\n    )\n    total_items: int = Field(description=\"Total number of items found\")\n    search_query: Optional[Dict[str, Any]] = Field(\n        default=None, description=\"The search query that was executed\"\n    )\n</code></pre>"},{"location":"models/#geoagent.core.models.DataResult.__class_vars__","title":"<code>__class_vars__</code>  <code>special</code>","text":"<p>The names of the class variables defined on the model.</p>"},{"location":"models/#geoagent.core.models.DataResult.__private_attributes__","title":"<code>__private_attributes__</code>  <code>special</code>","text":"<p>Metadata about the private attributes of the model.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_complete__","title":"<code>__pydantic_complete__</code>  <code>special</code>","text":"<p>Whether model building is completed, or if there are still undefined fields.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_computed_fields__","title":"<code>__pydantic_computed_fields__</code>  <code>special</code>","text":"<p>A dictionary of computed field names and their corresponding [<code>ComputedFieldInfo</code>][pydantic.fields.ComputedFieldInfo] objects.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_custom_init__","title":"<code>__pydantic_custom_init__</code>  <code>special</code>","text":"<p>Whether the model has a custom <code>__init__</code> method.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_decorators__","title":"<code>__pydantic_decorators__</code>  <code>special</code>","text":"<p>Metadata containing the decorators defined on the model. This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_fields__","title":"<code>__pydantic_fields__</code>  <code>special</code>","text":"<p>A dictionary of field names and their corresponding [<code>FieldInfo</code>][pydantic.fields.FieldInfo] objects. This replaces <code>Model.__fields__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_generic_metadata__","title":"<code>__pydantic_generic_metadata__</code>  <code>special</code>","text":"<p>Metadata for generic models; contains data used for a similar purpose to args, origin, parameters in typing-module generics. May eventually be replaced by these.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_parent_namespace__","title":"<code>__pydantic_parent_namespace__</code>  <code>special</code>","text":"<p>Parent namespace of the model, used for automatic rebuilding of models.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_post_init__","title":"<code>__pydantic_post_init__</code>  <code>special</code>","text":"<p>The name of the post-init method for the model, if defined.</p>"},{"location":"models/#geoagent.core.models.DataResult.__pydantic_setattr_handlers__","title":"<code>__pydantic_setattr_handlers__</code>  <code>special</code>","text":"<p><code>__setattr__</code> handlers. Memoizing the handlers leads to a dramatic performance improvement in <code>__setattr__</code></p>"},{"location":"models/#geoagent.core.models.DataResult.__signature__","title":"<code>__signature__</code>  <code>special</code>","text":"<p>The synthesized <code>__init__</code> [<code>Signature</code>][inspect.Signature] of the model.</p>"},{"location":"models/#geoagent.core.models.DataResult.model_config","title":"<code>model_config</code>","text":"<p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse","title":"<code> GeoAgentResponse            (BaseModel)         </code>","text":"<p>Complete response from GeoAgent containing all pipeline results.</p> Source code in <code>geoagent/core/models.py</code> <pre><code>class GeoAgentResponse(BaseModel):\n    \"\"\"Complete response from GeoAgent containing all pipeline results.\"\"\"\n\n    plan: PlannerOutput = Field(description=\"The parsed query plan\")\n    data: Optional[DataResult] = Field(\n        default=None, description=\"Data retrieval results\"\n    )\n    analysis: Optional[AnalysisResult] = Field(\n        default=None, description=\"Analysis results if analysis was performed\"\n    )\n    map: Optional[Any] = Field(  # leafmap.Map - using Any to avoid import issues\n        default=None, description=\"Generated leafmap visualization\"\n    )\n    code: str = Field(\n        default=\"\", description=\"All generated Python code from the pipeline\"\n    )\n    success: bool = Field(\n        default=True, description=\"Whether the overall pipeline succeeded\"\n    )\n    error_message: Optional[str] = Field(\n        default=None, description=\"Error message if pipeline failed\"\n    )\n    execution_time: Optional[float] = Field(\n        default=None, description=\"Total execution time in seconds\"\n    )\n</code></pre>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__class_vars__","title":"<code>__class_vars__</code>  <code>special</code>","text":"<p>The names of the class variables defined on the model.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__private_attributes__","title":"<code>__private_attributes__</code>  <code>special</code>","text":"<p>Metadata about the private attributes of the model.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_complete__","title":"<code>__pydantic_complete__</code>  <code>special</code>","text":"<p>Whether model building is completed, or if there are still undefined fields.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_computed_fields__","title":"<code>__pydantic_computed_fields__</code>  <code>special</code>","text":"<p>A dictionary of computed field names and their corresponding [<code>ComputedFieldInfo</code>][pydantic.fields.ComputedFieldInfo] objects.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_custom_init__","title":"<code>__pydantic_custom_init__</code>  <code>special</code>","text":"<p>Whether the model has a custom <code>__init__</code> method.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_decorators__","title":"<code>__pydantic_decorators__</code>  <code>special</code>","text":"<p>Metadata containing the decorators defined on the model. This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_fields__","title":"<code>__pydantic_fields__</code>  <code>special</code>","text":"<p>A dictionary of field names and their corresponding [<code>FieldInfo</code>][pydantic.fields.FieldInfo] objects. This replaces <code>Model.__fields__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_generic_metadata__","title":"<code>__pydantic_generic_metadata__</code>  <code>special</code>","text":"<p>Metadata for generic models; contains data used for a similar purpose to args, origin, parameters in typing-module generics. May eventually be replaced by these.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_parent_namespace__","title":"<code>__pydantic_parent_namespace__</code>  <code>special</code>","text":"<p>Parent namespace of the model, used for automatic rebuilding of models.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_post_init__","title":"<code>__pydantic_post_init__</code>  <code>special</code>","text":"<p>The name of the post-init method for the model, if defined.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__pydantic_setattr_handlers__","title":"<code>__pydantic_setattr_handlers__</code>  <code>special</code>","text":"<p><code>__setattr__</code> handlers. Memoizing the handlers leads to a dramatic performance improvement in <code>__setattr__</code></p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.__signature__","title":"<code>__signature__</code>  <code>special</code>","text":"<p>The synthesized <code>__init__</code> [<code>Signature</code>][inspect.Signature] of the model.</p>"},{"location":"models/#geoagent.core.models.GeoAgentResponse.model_config","title":"<code>model_config</code>","text":"<p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>"},{"location":"models/#geoagent.core.models.Intent","title":"<code> Intent            (str, Enum)         </code>","text":"<p>Supported query intents.</p> Source code in <code>geoagent/core/models.py</code> <pre><code>class Intent(str, Enum):\n    \"\"\"Supported query intents.\"\"\"\n\n    SEARCH = \"search\"\n    ANALYZE = \"analyze\"\n    VISUALIZE = \"visualize\"\n    COMPARE = \"compare\"\n</code></pre>"},{"location":"models/#geoagent.core.models.Intent.__format__","title":"<code>__format__(self, format_spec)</code>  <code>special</code>","text":"<p>Default object formatter.</p> <p>Return str(self) if format_spec is empty. Raise TypeError otherwise.</p> Source code in <code>geoagent/core/models.py</code> <pre><code>def __format__(self, format_spec):\n    return str.__format__(str(self), format_spec)\n</code></pre>"},{"location":"models/#geoagent.core.models.PlannerOutput","title":"<code> PlannerOutput            (BaseModel)         </code>","text":"<p>Output from the Planner Agent containing structured query parameters.</p> Source code in <code>geoagent/core/models.py</code> <pre><code>class PlannerOutput(BaseModel):\n    \"\"\"Output from the Planner Agent containing structured query parameters.\"\"\"\n\n    intent: str = Field(\n        description=\"The analysis intent (e.g., 'compute_ndvi', 'find_deforestation')\"\n    )\n    location: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=\"Location information (bounding box, geometry, place name)\",\n    )\n    time_range: Optional[Dict[str, Union[str, datetime]]] = Field(\n        default=None, description=\"Temporal range with start_date and end_date\"\n    )\n    dataset: Optional[str] = Field(\n        default=None,\n        description=\"Preferred dataset or catalog (e.g., 'sentinel-2', 'landsat')\",\n    )\n    analysis_type: Optional[str] = Field(\n        default=None,\n        description=\"Type of analysis requested (e.g., 'ndvi', 'change_detection')\",\n    )\n    parameters: Dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional analysis parameters\"\n    )\n    confidence: float = Field(\n        default=1.0, description=\"Confidence score of the parsing (0-1)\"\n    )\n</code></pre>"},{"location":"models/#geoagent.core.models.PlannerOutput.__class_vars__","title":"<code>__class_vars__</code>  <code>special</code>","text":"<p>The names of the class variables defined on the model.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__private_attributes__","title":"<code>__private_attributes__</code>  <code>special</code>","text":"<p>Metadata about the private attributes of the model.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_complete__","title":"<code>__pydantic_complete__</code>  <code>special</code>","text":"<p>Whether model building is completed, or if there are still undefined fields.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_computed_fields__","title":"<code>__pydantic_computed_fields__</code>  <code>special</code>","text":"<p>A dictionary of computed field names and their corresponding [<code>ComputedFieldInfo</code>][pydantic.fields.ComputedFieldInfo] objects.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_custom_init__","title":"<code>__pydantic_custom_init__</code>  <code>special</code>","text":"<p>Whether the model has a custom <code>__init__</code> method.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_decorators__","title":"<code>__pydantic_decorators__</code>  <code>special</code>","text":"<p>Metadata containing the decorators defined on the model. This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_fields__","title":"<code>__pydantic_fields__</code>  <code>special</code>","text":"<p>A dictionary of field names and their corresponding [<code>FieldInfo</code>][pydantic.fields.FieldInfo] objects. This replaces <code>Model.__fields__</code> from Pydantic V1.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_generic_metadata__","title":"<code>__pydantic_generic_metadata__</code>  <code>special</code>","text":"<p>Metadata for generic models; contains data used for a similar purpose to args, origin, parameters in typing-module generics. May eventually be replaced by these.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_parent_namespace__","title":"<code>__pydantic_parent_namespace__</code>  <code>special</code>","text":"<p>Parent namespace of the model, used for automatic rebuilding of models.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_post_init__","title":"<code>__pydantic_post_init__</code>  <code>special</code>","text":"<p>The name of the post-init method for the model, if defined.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__pydantic_setattr_handlers__","title":"<code>__pydantic_setattr_handlers__</code>  <code>special</code>","text":"<p><code>__setattr__</code> handlers. Memoizing the handlers leads to a dramatic performance improvement in <code>__setattr__</code></p>"},{"location":"models/#geoagent.core.models.PlannerOutput.__signature__","title":"<code>__signature__</code>  <code>special</code>","text":"<p>The synthesized <code>__init__</code> [<code>Signature</code>][inspect.Signature] of the model.</p>"},{"location":"models/#geoagent.core.models.PlannerOutput.model_config","title":"<code>model_config</code>","text":"<p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>"},{"location":"planner/","title":"Planner","text":"<p>The Planner agent parses natural language queries into structured parameters (intent, location, time range, dataset).</p>"},{"location":"planner/#geoagent.core.planner","title":"<code>geoagent.core.planner</code>","text":"<p>Planner agent for parsing natural language queries into structured parameters.</p>"},{"location":"planner/#geoagent.core.planner.Planner","title":"<code> Planner        </code>","text":"<p>Agent for parsing natural language queries into structured parameters.</p> Source code in <code>geoagent/core/planner.py</code> <pre><code>class Planner:\n    \"\"\"Agent for parsing natural language queries into structured parameters.\"\"\"\n\n    def __init__(\n        self,\n        llm: Optional[BaseChatModel] = None,\n        collections: Optional[List[Dict[str, str]]] = None,\n    ):\n        \"\"\"\n        Initialize the planner agent.\n\n        Args:\n            llm: Language model to use. Uses default if None.\n        \"\"\"\n        self.llm = llm or get_default_llm(temperature=0.0)\n\n        # Format collections into a readable list for the system prompt\n        collections_text = \"\"\n        if collections:\n            lines = [\"Available collections in the STAC catalog:\"]\n            for c in collections:\n                cid = c.get(\"id\", \"\")\n                title = c.get(\"title\", \"\")\n                if title and title != cid:\n                    lines.append(f\"- {cid}: {title}\")\n                else:\n                    lines.append(f\"- {cid}\")\n            collections_text = \"\\n\".join(lines)\n\n        # Use replace instead of format to avoid conflicts with {{ }} in examples\n        system_prompt = SYSTEM_PROMPT.replace(\"{collections}\", collections_text)\n        self.prompt = ChatPromptTemplate.from_messages(\n            [(\"system\", system_prompt), (\"human\", \"{query}\")]\n        )\n\n        # Build structured output chains \u2014 try strict first, json_mode as fallback\n        self._chain_strict = None\n        self._chain_json = None\n        try:\n            self._chain_strict = self.prompt | self.llm.with_structured_output(\n                _PlannerLLMSchema\n            )\n        except Exception:\n            pass\n        try:\n            self._chain_json = self.prompt | self.llm.with_structured_output(\n                _PlannerLLMSchema, method=\"json_mode\"\n            )\n        except Exception:\n            pass\n\n    @staticmethod\n    def _convert_to_planner_output(result: _PlannerLLMSchema) -&gt; PlannerOutput:\n        \"\"\"Convert LLM schema output to the canonical PlannerOutput model.\"\"\"\n        location = None\n        if result.location:\n            try:\n                parts = [float(x) for x in result.location.split(\",\")]\n                if len(parts) == 4:\n                    location = {\"bbox\": parts}\n                else:\n                    location = {\"name\": result.location}\n            except ValueError:\n                location = {\"name\": result.location}\n\n        time_range = None\n        if result.time_range:\n            time_range = {\n                \"start_date\": result.time_range[0],\n                \"end_date\": result.time_range[1],\n            }\n\n        # Build parameters dict from explicit fields\n        parameters: Dict[str, Any] = {}\n        if result.max_cloud_cover is not None:\n            parameters[\"max_cloud_cover\"] = result.max_cloud_cover\n        if result.max_items is not None:\n            parameters[\"max_items\"] = result.max_items\n\n        return PlannerOutput(\n            intent=result.intent.value,\n            location=location,\n            time_range=time_range,\n            dataset=result.dataset,\n            analysis_type=result.analysis_type,\n            parameters=parameters,\n            confidence=1.0,\n        )\n\n    def parse_query(self, query: str) -&gt; PlannerOutput:\n        \"\"\"\n        Parse a natural language query into structured parameters.\n\n        Args:\n            query: Natural language query about Earth observation data\n\n        Returns:\n            PlannerOutput with extracted structured information\n\n        Raises:\n            Exception: If LLM fails to parse the query\n        \"\"\"\n        last_err = None\n        for chain in (self._chain_strict, self._chain_json):\n            if chain is None:\n                continue\n            try:\n                result = chain.invoke({\"query\": query})\n                if isinstance(result, _PlannerLLMSchema):\n                    return self._convert_to_planner_output(result)\n            except Exception as e:\n                last_err = e\n                logger.debug(f\"Structured output attempt failed: {e}\")\n                continue\n\n        raise Exception(\n            f\"Failed to parse query: {last_err or 'no structured output chain available'}\"\n        )\n\n    def parse_batch(self, queries: List[str]) -&gt; List[PlannerOutput]:\n        \"\"\"\n        Parse multiple queries in batch.\n\n        Args:\n            queries: List of natural language queries\n\n        Returns:\n            List of PlannerOutput objects\n        \"\"\"\n        results = []\n        for query in queries:\n            try:\n                result = self.parse_query(query)\n                results.append(result)\n            except Exception as e:\n                # Create a minimal output for failed queries\n                fallback = PlannerOutput(\n                    intent=Intent.SEARCH.value,\n                    parameters={\"error\": str(e), \"original_query\": query},\n                )\n                results.append(fallback)\n\n        return results\n</code></pre>"},{"location":"planner/#geoagent.core.planner.Planner.__init__","title":"<code>__init__(self, llm=None, collections=None)</code>  <code>special</code>","text":"<p>Initialize the planner agent.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>Optional[langchain_core.language_models.chat_models.BaseChatModel]</code> <p>Language model to use. Uses default if None.</p> <code>None</code> Source code in <code>geoagent/core/planner.py</code> <pre><code>def __init__(\n    self,\n    llm: Optional[BaseChatModel] = None,\n    collections: Optional[List[Dict[str, str]]] = None,\n):\n    \"\"\"\n    Initialize the planner agent.\n\n    Args:\n        llm: Language model to use. Uses default if None.\n    \"\"\"\n    self.llm = llm or get_default_llm(temperature=0.0)\n\n    # Format collections into a readable list for the system prompt\n    collections_text = \"\"\n    if collections:\n        lines = [\"Available collections in the STAC catalog:\"]\n        for c in collections:\n            cid = c.get(\"id\", \"\")\n            title = c.get(\"title\", \"\")\n            if title and title != cid:\n                lines.append(f\"- {cid}: {title}\")\n            else:\n                lines.append(f\"- {cid}\")\n        collections_text = \"\\n\".join(lines)\n\n    # Use replace instead of format to avoid conflicts with {{ }} in examples\n    system_prompt = SYSTEM_PROMPT.replace(\"{collections}\", collections_text)\n    self.prompt = ChatPromptTemplate.from_messages(\n        [(\"system\", system_prompt), (\"human\", \"{query}\")]\n    )\n\n    # Build structured output chains \u2014 try strict first, json_mode as fallback\n    self._chain_strict = None\n    self._chain_json = None\n    try:\n        self._chain_strict = self.prompt | self.llm.with_structured_output(\n            _PlannerLLMSchema\n        )\n    except Exception:\n        pass\n    try:\n        self._chain_json = self.prompt | self.llm.with_structured_output(\n            _PlannerLLMSchema, method=\"json_mode\"\n        )\n    except Exception:\n        pass\n</code></pre>"},{"location":"planner/#geoagent.core.planner.Planner.parse_batch","title":"<code>parse_batch(self, queries)</code>","text":"<p>Parse multiple queries in batch.</p> <p>Parameters:</p> Name Type Description Default <code>queries</code> <code>List[str]</code> <p>List of natural language queries</p> required <p>Returns:</p> Type Description <code>List[geoagent.core.models.PlannerOutput]</code> <p>List of PlannerOutput objects</p> Source code in <code>geoagent/core/planner.py</code> <pre><code>def parse_batch(self, queries: List[str]) -&gt; List[PlannerOutput]:\n    \"\"\"\n    Parse multiple queries in batch.\n\n    Args:\n        queries: List of natural language queries\n\n    Returns:\n        List of PlannerOutput objects\n    \"\"\"\n    results = []\n    for query in queries:\n        try:\n            result = self.parse_query(query)\n            results.append(result)\n        except Exception as e:\n            # Create a minimal output for failed queries\n            fallback = PlannerOutput(\n                intent=Intent.SEARCH.value,\n                parameters={\"error\": str(e), \"original_query\": query},\n            )\n            results.append(fallback)\n\n    return results\n</code></pre>"},{"location":"planner/#geoagent.core.planner.Planner.parse_query","title":"<code>parse_query(self, query)</code>","text":"<p>Parse a natural language query into structured parameters.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Natural language query about Earth observation data</p> required <p>Returns:</p> Type Description <code>PlannerOutput</code> <p>PlannerOutput with extracted structured information</p> <p>Exceptions:</p> Type Description <code>Exception</code> <p>If LLM fails to parse the query</p> Source code in <code>geoagent/core/planner.py</code> <pre><code>def parse_query(self, query: str) -&gt; PlannerOutput:\n    \"\"\"\n    Parse a natural language query into structured parameters.\n\n    Args:\n        query: Natural language query about Earth observation data\n\n    Returns:\n        PlannerOutput with extracted structured information\n\n    Raises:\n        Exception: If LLM fails to parse the query\n    \"\"\"\n    last_err = None\n    for chain in (self._chain_strict, self._chain_json):\n        if chain is None:\n            continue\n        try:\n            result = chain.invoke({\"query\": query})\n            if isinstance(result, _PlannerLLMSchema):\n                return self._convert_to_planner_output(result)\n        except Exception as e:\n            last_err = e\n            logger.debug(f\"Structured output attempt failed: {e}\")\n            continue\n\n    raise Exception(\n        f\"Failed to parse query: {last_err or 'no structured output chain available'}\"\n    )\n</code></pre>"},{"location":"planner/#geoagent.core.planner.create_planner","title":"<code>create_planner(llm=None, collections=None)</code>","text":"<p>Create a planner instance.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>Optional[langchain_core.language_models.chat_models.BaseChatModel]</code> <p>Language model to use. Uses default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Planner</code> <p>Configured Planner instance</p> Source code in <code>geoagent/core/planner.py</code> <pre><code>def create_planner(\n    llm: Optional[BaseChatModel] = None,\n    collections: Optional[List[Dict[str, str]]] = None,\n) -&gt; Planner:\n    \"\"\"\n    Create a planner instance.\n\n    Args:\n        llm: Language model to use. Uses default if None.\n\n    Returns:\n        Configured Planner instance\n    \"\"\"\n    return Planner(llm=llm, collections=collections)\n</code></pre>"},{"location":"planner/#geoagent.core.planner.parse_query","title":"<code>parse_query(query, llm=None, collections=None)</code>","text":"<p>Convenience function to parse a single query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Natural language query</p> required <code>llm</code> <code>Optional[langchain_core.language_models.chat_models.BaseChatModel]</code> <p>Language model to use. Uses default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>PlannerOutput</code> <p>PlannerOutput with extracted information</p> Source code in <code>geoagent/core/planner.py</code> <pre><code>def parse_query(\n    query: str,\n    llm: Optional[BaseChatModel] = None,\n    collections: Optional[List[Dict[str, str]]] = None,\n) -&gt; PlannerOutput:\n    \"\"\"\n    Convenience function to parse a single query.\n\n    Args:\n        query: Natural language query\n        llm: Language model to use. Uses default if None.\n\n    Returns:\n        PlannerOutput with extracted information\n    \"\"\"\n    planner = create_planner(llm=llm, collections=collections)\n    return planner.parse_query(query)\n</code></pre>"},{"location":"tools/","title":"Tools","text":"<p>GeoAgent provides LangChain-compatible tools that can be used independently or as part of the agent pipeline.</p>"},{"location":"tools/#stac-search","title":"STAC Search","text":""},{"location":"tools/#geoagent.core.tools.stac","title":"<code>geoagent.core.tools.stac</code>","text":"<p>STAC Search Tool for GeoAgent package.</p> <p>This module provides tools for searching STAC (SpatioTemporal Asset Catalog) data.</p>"},{"location":"tools/#duckdb-spatial-sql","title":"DuckDB Spatial SQL","text":""},{"location":"tools/#geoagent.core.tools.duckdb_tool","title":"<code>geoagent.core.tools.duckdb_tool</code>","text":"<p>DuckDB Spatial SQL Tool for GeoAgent package.</p> <p>This module provides tools for running spatial SQL queries using DuckDB.</p>"},{"location":"tools/#raster-analysis","title":"Raster Analysis","text":""},{"location":"tools/#geoagent.core.tools.raster","title":"<code>geoagent.core.tools.raster</code>","text":"<p>Raster Analysis Tool for GeoAgent package.</p> <p>This module provides tools for raster data analysis using xarray and rioxarray.</p>"},{"location":"tools/#vector-operations","title":"Vector Operations","text":""},{"location":"tools/#geoagent.core.tools.vector","title":"<code>geoagent.core.tools.vector</code>","text":"<p>Vector Analysis Tool for GeoAgent package.</p> <p>This module provides tools for vector data analysis using geopandas.</p>"},{"location":"tools/#visualization","title":"Visualization","text":""},{"location":"tools/#geoagent.core.tools.viz","title":"<code>geoagent.core.tools.viz</code>","text":"<p>Visualization Tool for GeoAgent package.</p> <p>This module provides tools for creating interactive maps using leafmap's MapLibre backend.</p>"},{"location":"ui/","title":"Web UI","text":"<p>GeoAgent includes a Solara-based chat interface for interactive geospatial analysis with a persistent, interactive map.</p>"},{"location":"ui/#quick-start","title":"Quick Start","text":"<pre><code># Install UI dependencies\npip install \"geoagent[ui]\"\n\n# Launch the UI\ngeoagent ui\n</code></pre> <p>Or run directly:</p> <pre><code>solara run geoagent/ui/pages\n</code></pre>"},{"location":"ui/#features","title":"Features","text":"<ul> <li>Persistent map \u2014 layers accumulate across queries on the same interactive MapLibre map</li> <li>Native widget rendering \u2014 full bidirectional map interaction (zoom, pan, click)</li> <li>Chat interface \u2014 type natural language queries with real-time status updates</li> <li>Provider selection \u2014 switch between OpenAI, Anthropic, Google Gemini, or Ollama</li> <li>Generated code \u2014 toggle code display for transparency</li> </ul>"},{"location":"ui/#python-api","title":"Python API","text":"<p>You can also launch the UI programmatically:</p> <pre><code>from geoagent.ui import launch_ui\n\nlaunch_ui()\n</code></pre>"},{"location":"ui/#module-reference","title":"Module Reference","text":""},{"location":"ui/#geoagent.ui.launch_ui","title":"<code>geoagent.ui.launch_ui(extra_args=None)</code>","text":"<p>Launch the Solara UI for GeoAgent.</p> <p>Parameters:</p> Name Type Description Default <code>extra_args</code> <code>Optional[List[str]]</code> <p>Additional args passed to <code>solara run</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Process return code.</p> Source code in <code>geoagent/ui/__init__.py</code> <pre><code>def launch_ui(extra_args: Optional[List[str]] = None) -&gt; int:\n    \"\"\"Launch the Solara UI for GeoAgent.\n\n    Args:\n        extra_args: Additional args passed to `solara run`.\n\n    Returns:\n        Process return code.\n    \"\"\"\n    cmd = [sys.executable, \"-m\", \"solara\", \"run\", PAGES_DIR]\n    if extra_args:\n        cmd.extend(extra_args)\n    try:\n        return subprocess.call(cmd)\n    except FileNotFoundError:\n        raise RuntimeError(\n            \"Solara is not installed. Install with `pip install solara`.\"\n        )\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#basic-usage","title":"Basic Usage","text":"<p>The simplest way to use GeoAgent is through the <code>GeoAgent</code> class:</p> <pre><code>from geoagent import GeoAgent\n\n# Initialize with default LLM (auto-detects from environment)\nagent = GeoAgent()\n\n# Or specify a provider and model\nagent = GeoAgent(provider=\"openai\", model=\"gpt-4o\")\nagent = GeoAgent(provider=\"anthropic\", model=\"claude-sonnet-4-20250514\")\nagent = GeoAgent(provider=\"ollama\", model=\"llama3.1\")\n</code></pre>"},{"location":"usage/#chat-interface","title":"Chat Interface","text":"<p>Use <code>chat()</code> for the full pipeline (plan, search, analyze, visualize):</p> <pre><code>result = agent.chat(\"Show NDVI for San Francisco in July 2024\")\n\n# Access the results\nresult.plan       # PlannerOutput with parsed intent and parameters\nresult.data       # DataResult with retrieved data references\nresult.analysis   # AnalysisResult with computed values\nresult.map        # Interactive leafmap MapLibre map\nresult.code       # Generated Python code for reproducibility\n</code></pre>"},{"location":"usage/#targeted-operations","title":"Targeted Operations","text":"<p>Use specific methods when you only need part of the pipeline:</p> <pre><code># Search for data only\ndata = agent.search(\"Find Sentinel-2 imagery of Tokyo from March 2024\")\n\n# Search and analyze\nanalysis = agent.analyze(\"Calculate NDVI for the Amazon in 2023\")\n\n# Full pipeline with visualization\nresult = agent.visualize(\"Show land cover change in Dubai from 2020 to 2024\")\n</code></pre>"},{"location":"usage/#stac-catalog-search","title":"STAC Catalog Search","text":"<p>Search across multiple STAC catalogs directly:</p> <pre><code>from geoagent.catalogs.registry import CatalogRegistry\n\nreg = CatalogRegistry()\n\n# List available catalogs\nfor cat in reg.list_catalogs():\n    print(f\"{cat.name}: {cat.description}\")\n\n# Get a client for a specific catalog\nclient = reg.get_client(\"earth_search\")\nclient = reg.get_client(\"planetary_computer\")\n\n# Add a custom catalog\nreg.add_catalog(\n    name=\"my_catalog\",\n    url=\"https://stac.example.com\",\n    description=\"My custom STAC catalog\"\n)\n</code></pre>"},{"location":"usage/#using-tools-directly","title":"Using Tools Directly","text":"<p>Each tool can be used independently:</p>"},{"location":"usage/#stac-search","title":"STAC Search","text":"<pre><code>from geoagent.core.tools.stac import search_stac\n\nitems = search_stac.invoke({\n    \"query\": \"Sentinel-2 imagery\",\n    \"catalog\": \"earth_search\",\n    \"bbox\": [-122.5, 37.5, -122.0, 38.0],\n    \"datetime_range\": \"2024-07-01/2024-07-31\",\n    \"collections\": [\"sentinel-2-l2a\"],\n    \"max_items\": 5\n})\n</code></pre>"},{"location":"usage/#duckdb-spatial-queries","title":"DuckDB Spatial Queries","text":"<pre><code>from geoagent.core.tools.duckdb_tool import query_spatial_data\n\nresults = query_spatial_data.invoke({\n    \"sql\": \"SELECT * FROM read_parquet('data.parquet') LIMIT 10\",\n    \"data_path\": \"path/to/data.parquet\"\n})\n</code></pre>"},{"location":"usage/#raster-analysis","title":"Raster Analysis","text":"<pre><code>from geoagent.core.tools.raster import load_raster, compute_index\n\n# Load a COG\ndata = load_raster.invoke({\n    \"url_or_path\": \"https://example.com/cog.tif\",\n    \"bbox\": [-122.5, 37.5, -122.0, 38.0]\n})\n\n# Compute NDVI\nndvi = compute_index.invoke({\n    \"dataset\": data,\n    \"index_name\": \"ndvi\"\n})\n</code></pre>"},{"location":"usage/#maplibre-visualization","title":"MapLibre Visualization","text":"<pre><code>from geoagent.core.tools.viz import show_on_map, add_cog_layer\n\n# Create a map with layers\nresult = show_on_map.invoke({\n    \"layers\": [\n        {\"type\": \"cog\", \"data\": \"https://example.com/cog.tif\", \"name\": \"Satellite\"}\n    ],\n    \"center\": [37.77, -122.42],\n    \"zoom\": 10\n})\n</code></pre>"},{"location":"usage/#llm-provider-selection","title":"LLM Provider Selection","text":"<pre><code>from geoagent.core.llm import get_llm, get_available_providers, check_api_keys\n\n# Check what's available\nprint(get_available_providers())  # ['openai', 'ollama']\nprint(check_api_keys())           # {'openai': True, 'anthropic': False, ...}\n\n# Create a specific LLM\nllm = get_llm(provider=\"openai\", model=\"gpt-4o\", temperature=0.0)\n</code></pre>"},{"location":"usage/#web-ui","title":"Web UI","text":"<p>GeoAgent includes a Solara-based chat interface for interactive geospatial analysis with a persistent map. Install the UI extra and launch:</p> <pre><code>pip install \"geoagent[ui]\"\ngeoagent ui\n</code></pre> <p>Or run the Solara app directly:</p> <pre><code>solara run geoagent/ui/app.py\n</code></pre> <p>You can also launch it programmatically:</p> <pre><code>from geoagent.ui import launch_ui\n\nlaunch_ui()\n</code></pre> <p>The web UI provides: - A chat panel for natural language queries with real-time status updates - A persistent MapLibre map where layers accumulate across queries - A sidebar to switch LLM providers and models on the fly - Toggle-able generated code sections for transparency</p> <p>See Web UI for full details.</p>"},{"location":"usage/#code-transparency","title":"Code Transparency","text":"<p>One of GeoAgent's key features is showing the Python code it generates:</p> <pre><code>result = agent.chat(\"Calculate mean NDVI for Central Park, NYC in August 2024\")\n\n# Print the generated code\nprint(result.code)\n# Output:\n# import rioxarray\n# import xarray as xr\n# ds = rioxarray.open_rasterio(\"s3://...\")\n# nir = ds.sel(band=\"B08\")\n# red = ds.sel(band=\"B04\")\n# ndvi = (nir - red) / (nir + red)\n# mean_ndvi = float(ndvi.mean())\n</code></pre> <p>This makes workflows reproducible and educational. Researchers can take the generated code, modify it, and integrate it into their own scripts.</p>"},{"location":"viz_agent/","title":"Visualization Agent","text":"<p>The Visualization Agent creates interactive maps using leafmap's MapLibre backend.</p>"},{"location":"viz_agent/#geoagent.core.viz_agent","title":"<code>geoagent.core.viz_agent</code>","text":"<p>Visualization Agent for creating geospatial maps and visualizations.</p> <p>The Visualization Agent creates interactive MapLibre GL visualizations using leafmap's maplibregl backend for high-performance 3D mapping.</p>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap","title":"<code> MockMapLibreMap        </code>","text":"<p>Mock MapLibre map object when leafmap.maplibregl is not available.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>class MockMapLibreMap:\n    \"\"\"Mock MapLibre map object when leafmap.maplibregl is not available.\"\"\"\n\n    def __init__(self, center=[0, 0], zoom=5, height=\"600px\", **kwargs):\n        self.layers = []\n        self.center = center\n        self.zoom = zoom\n        self.height = height\n        self.title = \"\"\n        self._style = \"open-street-map\"\n\n    def set_center(self, lon, lat, zoom=None):\n        self.center = [lon, lat]\n        if zoom is not None:\n            self.zoom = zoom\n\n    def add_cog_layer(self, url, name=None, fit_bounds=False, **kwargs):\n        \"\"\"Add Cloud Optimized GeoTIFF layer.\"\"\"\n        self.layers.append(\n            {\n                \"type\": \"cog\",\n                \"url\": url,\n                \"name\": name or f\"COG Layer {len(self.layers)+1}\",\n                \"fit_bounds\": fit_bounds,\n                **kwargs,\n            }\n        )\n\n    def add_raster(self, url, layer_name=None, fit_bounds=False, **kwargs):\n        \"\"\"Add raster layer (fallback to COG).\"\"\"\n        self.add_cog_layer(url, name=layer_name, fit_bounds=fit_bounds, **kwargs)\n\n    def add_geojson(self, data, layer_name=None, style=None, **kwargs):\n        \"\"\"Add GeoJSON layer.\"\"\"\n        self.layers.append(\n            {\n                \"type\": \"geojson\",\n                \"data\": data,\n                \"name\": layer_name or f\"GeoJSON Layer {len(self.layers)+1}\",\n                \"style\": style,\n                **kwargs,\n            }\n        )\n\n    def add_pmtiles(self, url, name=None, **kwargs):\n        \"\"\"Add PMTiles vector layer.\"\"\"\n        self.layers.append(\n            {\n                \"type\": \"pmtiles\",\n                \"url\": url,\n                \"name\": name or f\"PMTiles Layer {len(self.layers)+1}\",\n                **kwargs,\n            }\n        )\n\n    def add_basemap(self, basemap=\"open-street-map\"):\n        \"\"\"Set basemap style.\"\"\"\n        self._style = basemap\n\n    def add_layer(self, layer_dict):\n        \"\"\"Add generic layer.\"\"\"\n        self.layers.append(layer_dict)\n\n    def add_source(self, source_id, source_dict):\n        \"\"\"Add data source.\"\"\"\n        # Mock implementation\n        pass\n\n    def add_title(self, title):\n        \"\"\"Add title to map.\"\"\"\n        self.title = title\n\n    def to_html(self, filename=None):\n        \"\"\"Export map to HTML.\"\"\"\n        html = f\"\"\"\n        &lt;div style=\"text-align: center;\"&gt;\n            &lt;h3&gt;{self.title}&lt;/h3&gt;\n            &lt;p&gt;Mock MapLibre Map&lt;/p&gt;\n            &lt;p&gt;Center: {self.center}, Zoom: {self.zoom}&lt;/p&gt;\n            &lt;p&gt;Layers: {len(self.layers)}&lt;/p&gt;\n            &lt;ul&gt;\n        \"\"\"\n        for layer in self.layers:\n            html += f\"&lt;li&gt;{layer.get('name', 'Unnamed')} ({layer.get('type', 'unknown')})&lt;/li&gt;\"\n        html += \"&lt;/ul&gt;&lt;/div&gt;\"\n\n        if filename:\n            with open(filename, \"w\") as f:\n                f.write(html)\n        return html\n\n    def __repr__(self):\n        return f\"MockMapLibreMap(center={self.center}, zoom={self.zoom}, layers={len(self.layers)})\"\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_basemap","title":"<code>add_basemap(self, basemap='open-street-map')</code>","text":"<p>Set basemap style.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_basemap(self, basemap=\"open-street-map\"):\n    \"\"\"Set basemap style.\"\"\"\n    self._style = basemap\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_cog_layer","title":"<code>add_cog_layer(self, url, name=None, fit_bounds=False, **kwargs)</code>","text":"<p>Add Cloud Optimized GeoTIFF layer.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_cog_layer(self, url, name=None, fit_bounds=False, **kwargs):\n    \"\"\"Add Cloud Optimized GeoTIFF layer.\"\"\"\n    self.layers.append(\n        {\n            \"type\": \"cog\",\n            \"url\": url,\n            \"name\": name or f\"COG Layer {len(self.layers)+1}\",\n            \"fit_bounds\": fit_bounds,\n            **kwargs,\n        }\n    )\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_geojson","title":"<code>add_geojson(self, data, layer_name=None, style=None, **kwargs)</code>","text":"<p>Add GeoJSON layer.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_geojson(self, data, layer_name=None, style=None, **kwargs):\n    \"\"\"Add GeoJSON layer.\"\"\"\n    self.layers.append(\n        {\n            \"type\": \"geojson\",\n            \"data\": data,\n            \"name\": layer_name or f\"GeoJSON Layer {len(self.layers)+1}\",\n            \"style\": style,\n            **kwargs,\n        }\n    )\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_layer","title":"<code>add_layer(self, layer_dict)</code>","text":"<p>Add generic layer.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_layer(self, layer_dict):\n    \"\"\"Add generic layer.\"\"\"\n    self.layers.append(layer_dict)\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_pmtiles","title":"<code>add_pmtiles(self, url, name=None, **kwargs)</code>","text":"<p>Add PMTiles vector layer.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_pmtiles(self, url, name=None, **kwargs):\n    \"\"\"Add PMTiles vector layer.\"\"\"\n    self.layers.append(\n        {\n            \"type\": \"pmtiles\",\n            \"url\": url,\n            \"name\": name or f\"PMTiles Layer {len(self.layers)+1}\",\n            **kwargs,\n        }\n    )\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_raster","title":"<code>add_raster(self, url, layer_name=None, fit_bounds=False, **kwargs)</code>","text":"<p>Add raster layer (fallback to COG).</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_raster(self, url, layer_name=None, fit_bounds=False, **kwargs):\n    \"\"\"Add raster layer (fallback to COG).\"\"\"\n    self.add_cog_layer(url, name=layer_name, fit_bounds=fit_bounds, **kwargs)\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_source","title":"<code>add_source(self, source_id, source_dict)</code>","text":"<p>Add data source.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_source(self, source_id, source_dict):\n    \"\"\"Add data source.\"\"\"\n    # Mock implementation\n    pass\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.add_title","title":"<code>add_title(self, title)</code>","text":"<p>Add title to map.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def add_title(self, title):\n    \"\"\"Add title to map.\"\"\"\n    self.title = title\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.MockMapLibreMap.to_html","title":"<code>to_html(self, filename=None)</code>","text":"<p>Export map to HTML.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def to_html(self, filename=None):\n    \"\"\"Export map to HTML.\"\"\"\n    html = f\"\"\"\n    &lt;div style=\"text-align: center;\"&gt;\n        &lt;h3&gt;{self.title}&lt;/h3&gt;\n        &lt;p&gt;Mock MapLibre Map&lt;/p&gt;\n        &lt;p&gt;Center: {self.center}, Zoom: {self.zoom}&lt;/p&gt;\n        &lt;p&gt;Layers: {len(self.layers)}&lt;/p&gt;\n        &lt;ul&gt;\n    \"\"\"\n    for layer in self.layers:\n        html += f\"&lt;li&gt;{layer.get('name', 'Unnamed')} ({layer.get('type', 'unknown')})&lt;/li&gt;\"\n    html += \"&lt;/ul&gt;&lt;/div&gt;\"\n\n    if filename:\n        with open(filename, \"w\") as f:\n            f.write(html)\n    return html\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.VizAgent","title":"<code> VizAgent        </code>","text":"<p>Agent responsible for creating geospatial visualizations.</p> <p>The Visualization Agent takes data and analysis results and creates appropriate leafmap visualizations for display in Jupyter notebooks.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>class VizAgent:\n    \"\"\"Agent responsible for creating geospatial visualizations.\n\n    The Visualization Agent takes data and analysis results and creates\n    appropriate leafmap visualizations for display in Jupyter notebooks.\n    \"\"\"\n\n    def __init__(self, llm: Any, tools: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the Visualization Agent.\n\n        Args:\n            llm: Language model instance for visualization decisions\n            tools: Dictionary of available visualization tools\n        \"\"\"\n        self.llm = llm\n        self.tools = tools or {}\n        self._setup_tools()\n\n    def _setup_tools(self):\n        \"\"\"Setup and initialize visualization tools.\"\"\"\n        try:\n            # Import visualization tools\n            # TODO: Enable when actual tools are implemented\n            # from ..tools.viz import VizTool\n\n            # if 'viz' not in self.tools:\n            #     self.tools['viz'] = VizTool()\n\n            logger.info(\"Visualization tools setup (using placeholders)\")\n\n        except ImportError as e:\n            logger.warning(f\"Visualization tools not available: {e}\")\n            # Graceful fallback - use leafmap directly\n\n    def create_visualization(\n        self,\n        plan: PlannerOutput,\n        data: Optional[DataResult] = None,\n        analysis: Optional[AnalysisResult] = None,\n        target_map: Optional[Any] = None,\n    ) -&gt; Any:\n        \"\"\"Create appropriate visualization based on available data and analysis.\n\n        Args:\n            plan: Original query plan for context\n            data: Data retrieved by Data Agent\n            analysis: Analysis results from Analysis Agent\n            target_map: Optional existing map to render on instead of creating\n                a new one. When provided, layers are added to this map.\n\n        Returns:\n            MapLibre Map object ready for display\n        \"\"\"\n        self._target_map = target_map\n        if target_map is not None:\n            self._prepare_target_map(target_map)\n        logger.info(\"Creating visualization\")\n\n        try:\n            # Determine visualization type based on available data and analysis\n            viz_type = self._determine_viz_type(plan, data, analysis)\n\n            if viz_type == \"raster_layer\":\n                return self._create_raster_visualization(plan, data, analysis)\n            elif viz_type == \"vector_layer\":\n                return self._create_vector_visualization(plan, data, analysis)\n            elif viz_type == \"analysis_result\":\n                return self._create_analysis_visualization(plan, data, analysis)\n            elif viz_type == \"time_series\":\n                return self._create_time_series_visualization(plan, data, analysis)\n            elif viz_type == \"split_map\":\n                return self._create_split_map_visualization(plan, data, analysis)\n            else:\n                return self._create_default_visualization(plan, data, analysis)\n\n        except Exception as e:\n            logger.error(f\"Visualization creation failed: {e}\")\n            return self._create_error_visualization(str(e))\n\n    def _prepare_target_map(self, target_map: Any) -&gt; None:\n        \"\"\"Ensure an existing map widget can receive dynamic updates.\"\"\"\n        try:\n            if hasattr(target_map, \"use_message_queue\"):\n                target_map.use_message_queue(True)\n            if (\n                hasattr(target_map, \"create_container\")\n                and getattr(target_map, \"container\", None) is None\n            ):\n                target_map.create_container()\n        except Exception as e:\n            logger.debug(f\"Could not prepare target map: {e}\")\n\n    def _determine_viz_type(\n        self,\n        plan: PlannerOutput,\n        data: Optional[DataResult] = None,\n        analysis: Optional[AnalysisResult] = None,\n    ) -&gt; str:\n        \"\"\"Determine the appropriate visualization type.\n\n        Args:\n            plan: Query plan with intent\n            data: Available data\n            analysis: Analysis results\n\n        Returns:\n            Visualization type string\n        \"\"\"\n        # If analysis has specific visualization hints, use those\n        if analysis and analysis.visualization_hints:\n            viz_hints = analysis.visualization_hints\n            if viz_hints.get(\"type\") == \"time_series\":\n                return \"time_series\"\n            elif viz_hints.get(\"type\") == \"split_map\":\n                return \"split_map\"\n\n        # Check for change detection (typically needs split map)\n        if analysis and \"change\" in plan.intent.lower():\n            return \"split_map\"\n\n        # Check data type\n        if data:\n            if data.data_type == \"raster\":\n                if analysis:\n                    return \"analysis_result\"  # Processed raster\n                else:\n                    return \"raster_layer\"  # Raw raster\n            elif data.data_type == \"vector\":\n                return \"vector_layer\"\n\n        # Check for time series in intent\n        if any(\n            term in plan.intent.lower() for term in [\"time series\", \"temporal\", \"trend\"]\n        ):\n            return \"time_series\"\n\n        return \"default\"\n\n    def _create_raster_visualization(\n        self,\n        plan: PlannerOutput,\n        data: DataResult,\n        analysis: Optional[AnalysisResult] = None,\n    ) -&gt; Any:\n        \"\"\"Create visualization for raster data.\n\n        Args:\n            plan: Query plan\n            data: Raster data\n            analysis: Optional analysis results\n\n        Returns:\n            MapLibre Map with raster layers\n        \"\"\"\n        m = create_map(target_map=getattr(self, \"_target_map\", None))\n\n        # Set map center based on data location\n        if plan.location and \"bbox\" in plan.location:\n            bbox = plan.location[\"bbox\"]\n            center_lat = (bbox[1] + bbox[3]) / 2\n            center_lon = (bbox[0] + bbox[2]) / 2\n            m.set_center(center_lon, center_lat, zoom=10)\n\n        # Add raster layers using STAC\n        for i, item in enumerate(data.items[:1]):\n            item_id = item.get(\"id\", f\"Layer {i+1}\")\n            collection = item.get(\"collection\", \"\")\n\n            # Skip mock items\n            assets = item.get(\"assets\", {})\n            if not assets or any(\n                v.get(\"href\", \"\").startswith(\"mock://\") for v in assets.values()\n            ):\n                logger.debug(f\"Skipping mock item {item_id}\")\n                continue\n\n            try:\n                # Use add_stac_layer for best performance\n                if MAPLIBRE_AVAILABLE and collection:\n                    viz_assets = self._select_viz_assets(\n                        assets, plan.intent, collection\n                    )\n                    if isinstance(viz_assets, list):\n                        viz_assets = [a for a in viz_assets if a != \"rendered_preview\"]\n                    elif viz_assets == \"rendered_preview\":\n                        viz_assets = []\n                    if not viz_assets:\n                        best_asset = self._select_best_asset(assets, plan.intent)\n                        if best_asset and best_asset != \"rendered_preview\":\n                            viz_assets = [best_asset]\n                    logger.info(\n                        f\"Adding STAC layer: collection={collection}, \"\n                        f\"item={item_id}, assets={viz_assets}\"\n                    )\n\n                    # Build kwargs for add_stac_layer\n                    layer_kwargs = {\n                        \"collection\": collection,\n                        \"item\": item_id,\n                        \"assets\": viz_assets,\n                        \"name\": f\"{collection[:20]}_{item_id[:15]}\",\n                        \"fit_bounds\": True,\n                        \"overwrite\": True,\n                    }\n\n                    # Add before_id if available (keeps layers below labels)\n                    if hasattr(m, \"first_symbol_layer_id\"):\n                        layer_kwargs[\"before_id\"] = m.first_symbol_layer_id\n\n                    # Add colormap for specific collections\n                    if collection in (\"cop-dem-glo-30\", \"3dep-lidar-hag\"):\n                        layer_kwargs[\"colormap_name\"] = \"terrain\"\n                    elif collection in (\"io-lulc-9-class\",):\n                        # LULC has its own colormap\n                        pass\n\n                    m.add_stac_layer(**layer_kwargs)\n                    logger.info(f\"Successfully added STAC layer: {item_id}\")\n\n                    # Explicitly fit bounds to the item bbox if available\n                    item_bbox = item.get(\"bbox\")\n                    if item_bbox and len(item_bbox) &gt;= 4:\n                        try:\n                            m.fit_bounds(\n                                [\n                                    [item_bbox[0], item_bbox[1]],\n                                    [item_bbox[2], item_bbox[3]],\n                                ]\n                            )\n                            logger.info(f\"Fitted bounds to: {item_bbox}\")\n                        except Exception as e:\n                            logger.debug(f\"Could not fit bounds: {e}\")\n                            # Fallback to set_center\n                            center_lon = (item_bbox[0] + item_bbox[2]) / 2\n                            center_lat = (item_bbox[1] + item_bbox[3]) / 2\n                            m.set_center(center_lon, center_lat, zoom=10)\n                else:\n                    # Fallback to COG layer with signed URL\n                    asset_key = self._select_best_asset(assets, plan.intent)\n                    if asset_key and asset_key in assets:\n                        asset_url = assets[asset_key][\"href\"]\n                        logger.info(f\"Adding COG layer: {asset_url}\")\n                        m.add_cog_layer(\n                            asset_url,\n                            name=item_id,\n                            titiler_endpoint=PC_TITILER_ENDPOINT,\n                            fit_bounds=True,\n                        )\n            except Exception as e:\n                logger.error(f\"Could not add raster layer {item_id}: {e}\")\n                import traceback\n\n                traceback.print_exc()\n\n        # Add title\n        title = f\"Raster Visualization: {plan.intent}\"\n        self._add_title_to_map(m, title)\n\n        return m\n\n    def _create_vector_visualization(\n        self,\n        plan: PlannerOutput,\n        data: DataResult,\n        analysis: Optional[AnalysisResult] = None,\n    ) -&gt; Any:\n        \"\"\"Create visualization for vector data.\n\n        Args:\n            plan: Query plan\n            data: Vector data\n            analysis: Optional analysis results\n\n        Returns:\n            MapLibre Map with vector layers\n        \"\"\"\n        m = create_map(target_map=getattr(self, \"_target_map\", None))\n\n        # Set map center\n        if plan.location and \"bbox\" in plan.location:\n            bbox = plan.location[\"bbox\"]\n            center_lat = (bbox[1] + bbox[3]) / 2\n            center_lon = (bbox[0] + bbox[2]) / 2\n            m.set_center(center_lon, center_lat, zoom=10)\n\n        # Add vector layers\n        for i, item in enumerate(data.items):\n            if \"geometry\" in item:\n                layer_name = f\"Vector Layer {i+1}\"\n\n                # Determine styling based on analysis\n                style = {\"color\": \"blue\", \"weight\": 2, \"fillOpacity\": 0.3}\n                if analysis and analysis.visualization_hints:\n                    style.update(analysis.visualization_hints.get(\"style\", {}))\n\n                try:\n                    if \"viz\" in self.tools:\n                        viz_tool = self.tools[\"viz\"]\n                        viz_tool.add_vector_layer(m, item, layer_name, style)\n                    else:\n                        # Fallback: add as GeoJSON\n                        m.add_geojson(item, name=layer_name, style=style)\n\n                except Exception as e:\n                    logger.warning(f\"Could not add vector layer {layer_name}: {e}\")\n\n        title = f\"Vector Visualization: {plan.intent}\"\n        self._add_title_to_map(m, title)\n\n        return m\n\n    def _create_analysis_visualization(\n        self, plan: PlannerOutput, data: DataResult, analysis: AnalysisResult\n    ) -&gt; Any:\n        \"\"\"Create visualization for analysis results.\n\n        Args:\n            plan: Query plan\n            data: Source data\n            analysis: Analysis results with visualization hints\n\n        Returns:\n            MapLibre Map showing analysis results\n        \"\"\"\n        m = create_map(target_map=getattr(self, \"_target_map\", None))\n\n        # Set map center\n        if plan.location and \"bbox\" in plan.location:\n            bbox = plan.location[\"bbox\"]\n            center_lat = (bbox[1] + bbox[3]) / 2\n            center_lon = (bbox[0] + bbox[2]) / 2\n            m.set_center(center_lon, center_lat, zoom=10)\n\n        # Use visualization hints from analysis\n        viz_hints = analysis.visualization_hints\n\n        try:\n            if \"viz\" in self.tools:\n                viz_tool = self.tools[\"viz\"]\n                viz_tool.add_analysis_layer(m, analysis.result_data, viz_hints)\n            else:\n                # Fallback visualization based on analysis type\n                self._add_analysis_fallback(m, data, analysis)\n\n        except Exception as e:\n            logger.warning(f\"Could not create analysis visualization: {e}\")\n            # Fall back to data visualization\n            return self._create_raster_visualization(plan, data)\n\n        # Add analysis info\n        title = f\"Analysis Results: {plan.intent}\"\n        self._add_title_to_map(m, title)\n        self._add_analysis_legend(m, analysis)\n\n        return m\n\n    def _create_time_series_visualization(\n        self,\n        plan: PlannerOutput,\n        data: DataResult,\n        analysis: Optional[AnalysisResult] = None,\n    ) -&gt; Any:\n        \"\"\"Create time series visualization.\n\n        Args:\n            plan: Query plan\n            data: Time series data\n            analysis: Optional analysis results\n\n        Returns:\n            MapLibre Map with time series visualization\n        \"\"\"\n        m = create_map(target_map=getattr(self, \"_target_map\", None))\n\n        # Set map center\n        if plan.location:\n            if \"bbox\" in plan.location:\n                bbox = plan.location[\"bbox\"]\n                center_lat = (bbox[1] + bbox[3]) / 2\n                center_lon = (bbox[0] + bbox[2]) / 2\n            elif \"lat\" in plan.location and \"lon\" in plan.location:\n                center_lat = plan.location[\"lat\"]\n                center_lon = plan.location[\"lon\"]\n            else:\n                center_lat, center_lon = 0, 0\n\n            m.set_center(center_lon, center_lat, zoom=10)\n\n        # Add time series layers\n        try:\n            if \"viz\" in self.tools:\n                viz_tool = self.tools[\"viz\"]\n                viz_tool.add_time_series_layers(m, data.items)\n            else:\n                # Fallback: add first and last items\n                if len(data.items) &gt;= 2:\n                    first_item = data.items[0]\n                    last_item = data.items[-1]\n\n                    # Add layers if they have assets\n                    if \"assets\" in first_item and \"assets\" in last_item:\n                        asset_key = self._select_best_asset(\n                            first_item[\"assets\"], plan.intent\n                        )\n                        if asset_key:\n                            first_url = first_item[\"assets\"][asset_key][\"href\"]\n                            last_url = last_item[\"assets\"][asset_key][\"href\"]\n\n                            m.add_cog_layer(\n                                first_url, name=\"Time Series Start\", fit_bounds=True\n                            )\n                            m.add_cog_layer(\n                                last_url, name=\"Time Series End\", fit_bounds=False\n                            )\n\n        except Exception as e:\n            logger.warning(f\"Could not create time series visualization: {e}\")\n\n        title = f\"Time Series Visualization: {plan.intent}\"\n        self._add_title_to_map(m, title)\n\n        return m\n\n    def _create_split_map_visualization(\n        self,\n        plan: PlannerOutput,\n        data: DataResult,\n        analysis: Optional[AnalysisResult] = None,\n    ) -&gt; Any:\n        \"\"\"Create split map for before/after comparisons.\n\n        Args:\n            plan: Query plan\n            data: Comparison data\n            analysis: Optional analysis results\n\n        Returns:\n            Split-panel leafmap Map\n        \"\"\"\n        try:\n            # Create split map if we have multiple time periods\n            if len(data.items) &gt;= 2:\n                first_item = data.items[0]\n                last_item = data.items[-1]\n\n                if \"assets\" in first_item and \"assets\" in last_item:\n                    asset_key = self._select_best_asset(\n                        first_item[\"assets\"], plan.intent\n                    )\n                    if asset_key:\n                        left_url = first_item[\"assets\"][asset_key][\"href\"]\n                        right_url = last_item[\"assets\"][asset_key][\"href\"]\n\n                        # Create split map\n                        m = create_map(target_map=getattr(self, \"_target_map\", None))\n\n                        # Set center\n                        if plan.location and \"bbox\" in plan.location:\n                            bbox = plan.location[\"bbox\"]\n                            center_lat = (bbox[1] + bbox[3]) / 2\n                            center_lon = (bbox[0] + bbox[2]) / 2\n                            m.set_center(center_lon, center_lat, zoom=10)\n\n                        # Add layers to both sides\n                        m.add_cog_layer(left_url, name=\"Before\", fit_bounds=True)\n                        m.add_cog_layer(right_url, name=\"After\", fit_bounds=False)\n\n                        title = f\"Before/After Comparison: {plan.intent}\"\n                        self._add_title_to_map(m, title)\n\n                        return m\n\n            # Fallback if split map cannot be created\n            return self._create_raster_visualization(plan, data, analysis)\n\n        except Exception as e:\n            logger.warning(f\"Could not create split map: {e}\")\n            return self._create_default_visualization(plan, data, analysis)\n\n    def _create_default_visualization(\n        self,\n        plan: PlannerOutput,\n        data: Optional[DataResult] = None,\n        analysis: Optional[AnalysisResult] = None,\n    ) -&gt; Any:\n        \"\"\"Create default visualization when specific type cannot be determined.\n\n        Args:\n            plan: Query plan\n            data: Available data\n            analysis: Available analysis\n\n        Returns:\n            Basic leafmap Map\n        \"\"\"\n        m = create_map(target_map=getattr(self, \"_target_map\", None))\n\n        # Set center based on location if available\n        if plan.location:\n            if \"bbox\" in plan.location:\n                bbox = plan.location[\"bbox\"]\n                center_lat = (bbox[1] + bbox[3]) / 2\n                center_lon = (bbox[0] + bbox[2]) / 2\n                m.set_center(center_lon, center_lat, zoom=10)\n            elif \"geometry\" in plan.location:\n                # Try to get centroid from geometry\n                try:\n                    import shapely.geometry as sg\n\n                    geom = sg.shape(plan.location[\"geometry\"])\n                    centroid = geom.centroid\n                    m.set_center(centroid.x, centroid.y, zoom=10)\n                except Exception:\n                    pass\n\n        # Add simple data visualization if available\n        if data and data.items:\n            try:\n                if data.data_type == \"raster\":\n                    # Try to add first raster item using STAC layer\n                    item = data.items[0]\n                    item_id = item.get(\"id\", \"\")\n                    collection = item.get(\"collection\", \"\")\n                    assets = item.get(\"assets\", {})\n\n                    # Skip mock items\n                    if assets and not any(\n                        v.get(\"href\", \"\").startswith(\"mock://\") for v in assets.values()\n                    ):\n                        if MAPLIBRE_AVAILABLE and collection:\n                            viz_assets = self._select_viz_assets(\n                                assets, plan.intent, collection\n                            )\n                            if isinstance(viz_assets, list):\n                                viz_assets = [\n                                    a for a in viz_assets if a != \"rendered_preview\"\n                                ]\n                            elif viz_assets == \"rendered_preview\":\n                                viz_assets = []\n                            if not viz_assets:\n                                best_asset = self._select_best_asset(\n                                    assets, plan.intent\n                                )\n                                if best_asset and best_asset != \"rendered_preview\":\n                                    viz_assets = [best_asset]\n                            logger.info(\n                                f\"Default viz: adding STAC layer {collection}/{item_id}\"\n                            )\n\n                            layer_kwargs = {\n                                \"collection\": collection,\n                                \"item\": item_id,\n                                \"assets\": viz_assets,\n                                \"name\": f\"{collection[:20]}_{item_id[:15]}\",\n                                \"fit_bounds\": True,\n                                \"overwrite\": True,\n                            }\n\n                            if hasattr(m, \"first_symbol_layer_id\"):\n                                layer_kwargs[\"before_id\"] = m.first_symbol_layer_id\n\n                            # Add colormap for specific collections\n                            if collection in (\"cop-dem-glo-30\", \"3dep-lidar-hag\"):\n                                layer_kwargs[\"colormap_name\"] = \"terrain\"\n\n                            m.add_stac_layer(**layer_kwargs)\n\n                            # Fit bounds to item\n                            item_bbox = item.get(\"bbox\")\n                            if item_bbox and len(item_bbox) &gt;= 4:\n                                try:\n                                    m.fit_bounds(\n                                        [\n                                            [item_bbox[0], item_bbox[1]],\n                                            [item_bbox[2], item_bbox[3]],\n                                        ]\n                                    )\n                                except Exception:\n                                    center_lon = (item_bbox[0] + item_bbox[2]) / 2\n                                    center_lat = (item_bbox[1] + item_bbox[3]) / 2\n                                    m.set_center(center_lon, center_lat, zoom=10)\n                        else:\n                            # Fallback to COG\n                            asset_key = self._select_best_asset(assets, plan.intent)\n                            if asset_key and asset_key in assets:\n                                asset_url = assets[asset_key][\"href\"]\n                                if not asset_url.startswith(\"mock://\"):\n                                    m.add_cog_layer(\n                                        asset_url, name=\"Data Layer\", fit_bounds=True\n                                    )\n\n                elif data.data_type == \"vector\":\n                    # Try to add vector data\n                    for item in data.items[:3]:  # Limit to 3 items\n                        if \"geometry\" in item:\n                            m.add_geojson(item, name=\"Vector Data\")\n\n            except Exception as e:\n                logger.error(f\"Could not add data to default visualization: {e}\")\n                import traceback\n\n                traceback.print_exc()\n\n        title = f\"GeoAgent Map: {plan.intent}\"\n        self._add_title_to_map(m, title)\n\n        return m\n\n    def _create_error_visualization(self, error_message: str) -&gt; Any:\n        \"\"\"Create error visualization when something goes wrong.\n\n        Args:\n            error_message: Error description\n\n        Returns:\n            Basic leafmap Map with error information\n        \"\"\"\n        m = create_map(target_map=getattr(self, \"_target_map\", None))\n        m.add_basemap(\"OpenStreetMap\")\n\n        # Add error message\n        self._add_title_to_map(m, f\"Visualization Error: {error_message}\")\n\n        return m\n\n    def _select_viz_assets(\n        self, assets: Dict[str, Any], intent: str, collection: str = \"\"\n    ) -&gt; list:\n        \"\"\"Select asset names for STAC layer visualization.\n\n        Returns a list of asset keys suitable for add_stac_layer.\n\n        Args:\n            assets: Available STAC assets\n            intent: Analysis intent\n            collection: STAC collection name (helps determine appropriate assets)\n\n        Returns:\n            List of asset key strings (e.g., [\"visual\"] or [\"B04\", \"B03\", \"B02\"])\n        \"\"\"\n        intent_lower = intent.lower()\n        collection_lower = collection.lower() if collection else \"\"\n\n        # Collection-specific asset selection (like geoai pattern)\n        if \"sentinel-2\" in collection_lower:\n            # Sentinel-2 true color RGB\n            if \"B04\" in assets and \"B03\" in assets and \"B02\" in assets:\n                return [\"B04\", \"B03\", \"B02\"]\n            if \"visual\" in assets:\n                return [\"visual\"]\n\n        if \"landsat\" in collection_lower:\n            # Landsat RGB (L2 has blue, L1 may not)\n            if \"red\" in assets and \"green\" in assets and \"blue\" in assets:\n                return [\"red\", \"green\", \"blue\"]\n            # Or use available bands\n            if \"red\" in assets and \"green\" in assets:\n                if \"nir08\" in assets:\n                    return [\"nir08\", \"red\", \"green\"]  # False color\n                return [\"red\", \"green\", \"red\"]  # Fallback\n\n        if \"naip\" in collection_lower:\n            # NAIP imagery\n            if \"image\" in assets:\n                return [\"image\"]\n\n        if \"sentinel-1\" in collection_lower:\n            # Sentinel-1 SAR\n            if \"vv\" in assets:\n                return [\"vv\"]\n\n        if \"cop-dem\" in collection_lower or \"3dep\" in collection_lower:\n            # DEM data\n            if \"data\" in assets:\n                return [\"data\"]\n\n        if \"aster\" in collection_lower:\n            # ASTER imagery\n            if \"VNIR\" in assets:\n                return [\"VNIR\"]\n\n        # DEM and land cover collections use \"data\" or \"map\" asset\n        if any(\n            term in intent_lower\n            for term in [\n                \"dem\",\n                \"elevation\",\n                \"terrain\",\n                \"land_cover\",\n                \"land cover\",\n                \"landcover\",\n                \"lulc\",\n                \"land use\",\n            ]\n        ):\n            if \"data\" in assets:\n                return [\"data\"]\n            if \"map\" in assets:\n                return [\"map\"]\n\n        # For imagery/visual requests, prefer true color composite\n        if \"visual\" in assets:\n            return [\"visual\"]\n\n        # For NDVI, show NIR-Red false color or just visual\n        if any(term in intent_lower for term in [\"ndvi\", \"vegetation\"]):\n            if \"nir\" in assets and \"red\" in assets and \"green\" in assets:\n                return [\"nir\", \"red\", \"green\"]\n            if \"B08\" in assets and \"B04\" in assets and \"B03\" in assets:\n                return [\"B08\", \"B04\", \"B03\"]\n\n        # RGB composite\n        if \"red\" in assets and \"green\" in assets and \"blue\" in assets:\n            return [\"red\", \"green\", \"blue\"]\n        if \"B04\" in assets and \"B03\" in assets and \"B02\" in assets:\n            return [\"B04\", \"B03\", \"B02\"]\n\n        # Fallback: look for common asset names\n        for possible in [\"visual\", \"image\", \"data\"]:\n            if possible in assets:\n                return [possible]\n\n        # Last resort: first available asset\n        if assets:\n            return [list(assets.keys())[0]]\n\n        return []\n\n    def _select_best_asset(self, assets: Dict[str, Any], intent: str) -&gt; Optional[str]:\n        \"\"\"Select the best asset for visualization based on intent.\n\n        Args:\n            assets: Available STAC assets\n            intent: Analysis intent\n\n        Returns:\n            Best asset key or None\n        \"\"\"\n        intent_lower = intent.lower()\n\n        # For NDVI and vegetation analysis, prefer red or nir\n        if any(term in intent_lower for term in [\"ndvi\", \"vegetation\", \"green\"]):\n            for key in [\"nir\", \"red\", \"B04\", \"B08\"]:\n                if key in assets:\n                    return key\n\n        # For RGB visualization\n        if any(term in intent_lower for term in [\"rgb\", \"color\", \"visual\"]):\n            for key in [\"visual\", \"rgb\", \"red\"]:\n                if key in assets:\n                    return key\n\n        # Default preference order\n        preference_order = [\n            \"visual\",\n            \"rgb\",\n            \"red\",\n            \"nir\",\n            \"B04\",\n            \"B03\",\n            \"B02\",\n            \"B08\",\n            \"swir\",\n            \"B11\",\n            \"B12\",\n        ]\n\n        for key in preference_order:\n            if key in assets and key != \"rendered_preview\":\n                return key\n\n        # Return first available asset\n        if assets:\n            for key in assets.keys():\n                if key != \"rendered_preview\":\n                    return key\n        return None\n\n    def _add_analysis_fallback(\n        self, m: Any, data: DataResult, analysis: AnalysisResult\n    ):\n        \"\"\"Add analysis visualization fallback when viz tools are not available.\n\n        Args:\n            m: Map to add layers to\n            data: Source data\n            analysis: Analysis results\n        \"\"\"\n        viz_hints = analysis.visualization_hints\n        viz_type = viz_hints.get(\"type\", \"\") if viz_hints else \"\"\n\n        # Handle land cover and elevation data via STAC layer\n        if viz_type in (\"land_cover\", \"elevation\") and data and data.items:\n            item = data.items[0]\n            item_id = item.get(\"id\", \"\")\n            collection = item.get(\"collection\", \"\")\n\n            if MAPLIBRE_AVAILABLE and collection:\n                asset_key = viz_hints.get(\"asset_key\", \"data\")\n                try:\n                    layer_kwargs = {\n                        \"collection\": collection,\n                        \"item\": item_id,\n                        \"assets\": [asset_key],\n                        \"name\": viz_hints.get(\n                            \"title\", f\"{collection[:20]}_{item_id[:15]}\"\n                        ),\n                        \"fit_bounds\": True,\n                        \"overwrite\": True,\n                    }\n\n                    # Add before_id if available\n                    if hasattr(m, \"first_symbol_layer_id\"):\n                        layer_kwargs[\"before_id\"] = m.first_symbol_layer_id\n\n                    # Add colormap for specific viz types\n                    if viz_type == \"elevation\":\n                        layer_kwargs[\"colormap_name\"] = \"terrain\"\n\n                    m.add_stac_layer(**layer_kwargs)\n                    logger.info(f\"Added {viz_type} STAC layer: {collection}/{item_id}\")\n\n                    # Fit bounds to item\n                    item_bbox = item.get(\"bbox\")\n                    if item_bbox and len(item_bbox) &gt;= 4:\n                        try:\n                            m.fit_bounds(\n                                [\n                                    [item_bbox[0], item_bbox[1]],\n                                    [item_bbox[2], item_bbox[3]],\n                                ]\n                            )\n                        except Exception:\n                            center_lon = (item_bbox[0] + item_bbox[2]) / 2\n                            center_lat = (item_bbox[1] + item_bbox[3]) / 2\n                            m.set_center(center_lon, center_lat, zoom=10)\n                    return\n                except Exception as e:\n                    logger.warning(f\"Could not add {viz_type} STAC layer: {e}\")\n\n        # Check if we have a computed NDVI raster to display\n        ndvi_path = None\n        if viz_hints and \"ndvi_path\" in viz_hints:\n            ndvi_path = viz_hints[\"ndvi_path\"]\n        elif isinstance(analysis.result_data, dict):\n            ndvi_path = analysis.result_data.get(\"ndvi_path\")\n\n        if ndvi_path and os.path.exists(ndvi_path):\n            try:\n                m.add_raster(\n                    ndvi_path,\n                    layer_name=\"NDVI\",\n                    colormap=\"RdYlGn\",\n                    vmin=-0.2,\n                    vmax=0.8,\n                    fit_bounds=True,\n                )\n                logger.info(f\"Added NDVI raster layer from {ndvi_path}\")\n                return\n            except Exception as e:\n                logger.warning(f\"Could not add NDVI raster: {e}\")\n\n        # Fallback: try to add raw band from data\n        if data.items and \"assets\" in data.items[0]:\n            asset_key = self._select_best_asset(data.items[0][\"assets\"], \"ndvi\")\n            if asset_key:\n                asset_url = data.items[0][\"assets\"][asset_key][\"href\"]\n                if not asset_url.startswith(\"mock://\"):\n                    try:\n                        m.add_cog_layer(\n                            asset_url, name=\"NDVI Analysis\", fit_bounds=True\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Could not add COG layer: {e}\")\n\n    def _add_title_to_map(self, m: Any, title: str):\n        \"\"\"Add title to the map.\n\n        Args:\n            m: MapLibre map to add title to\n            title: Title text\n        \"\"\"\n        try:\n            # Try to add title using MapLibre functionality\n            if hasattr(m, \"add_title\"):\n                m.add_title(title)\n            elif hasattr(m, \"title\"):\n                # For MockMapLibreMap\n                m.title = title\n            else:\n                # Fallback: log the title\n                logger.info(f\"Map title: {title}\")\n        except Exception as e:\n            logger.debug(f\"Could not add title to map: {e}\")\n\n    def _add_analysis_legend(self, m: Any, analysis: AnalysisResult):\n        \"\"\"Add legend for analysis results.\n\n        Args:\n            m: Map to add legend to\n            analysis: Analysis results with visualization hints\n        \"\"\"\n        try:\n            viz_hints = analysis.visualization_hints\n\n            if \"colormap\" in viz_hints and \"vmin\" in viz_hints and \"vmax\" in viz_hints:\n                # Add colorbar legend (leafmap maplibregl uses cmap/label)\n                if hasattr(m, \"add_colorbar\"):\n                    m.add_colorbar(\n                        cmap=viz_hints[\"colormap\"],\n                        vmin=viz_hints[\"vmin\"],\n                        vmax=viz_hints[\"vmax\"],\n                        label=viz_hints.get(\"title\", \"Analysis Result\"),\n                    )\n\n        except Exception as e:\n            logger.debug(f\"Could not add legend to map: {e}\")\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.VizAgent.__init__","title":"<code>__init__(self, llm, tools=None)</code>  <code>special</code>","text":"<p>Initialize the Visualization Agent.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>Any</code> <p>Language model instance for visualization decisions</p> required <code>tools</code> <code>Optional[Dict[str, Any]]</code> <p>Dictionary of available visualization tools</p> <code>None</code> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def __init__(self, llm: Any, tools: Optional[Dict[str, Any]] = None):\n    \"\"\"Initialize the Visualization Agent.\n\n    Args:\n        llm: Language model instance for visualization decisions\n        tools: Dictionary of available visualization tools\n    \"\"\"\n    self.llm = llm\n    self.tools = tools or {}\n    self._setup_tools()\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.VizAgent.create_visualization","title":"<code>create_visualization(self, plan, data=None, analysis=None, target_map=None)</code>","text":"<p>Create appropriate visualization based on available data and analysis.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>PlannerOutput</code> <p>Original query plan for context</p> required <code>data</code> <code>Optional[geoagent.core.models.DataResult]</code> <p>Data retrieved by Data Agent</p> <code>None</code> <code>analysis</code> <code>Optional[geoagent.core.models.AnalysisResult]</code> <p>Analysis results from Analysis Agent</p> <code>None</code> <code>target_map</code> <code>Optional[Any]</code> <p>Optional existing map to render on instead of creating a new one. When provided, layers are added to this map.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>MapLibre Map object ready for display</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def create_visualization(\n    self,\n    plan: PlannerOutput,\n    data: Optional[DataResult] = None,\n    analysis: Optional[AnalysisResult] = None,\n    target_map: Optional[Any] = None,\n) -&gt; Any:\n    \"\"\"Create appropriate visualization based on available data and analysis.\n\n    Args:\n        plan: Original query plan for context\n        data: Data retrieved by Data Agent\n        analysis: Analysis results from Analysis Agent\n        target_map: Optional existing map to render on instead of creating\n            a new one. When provided, layers are added to this map.\n\n    Returns:\n        MapLibre Map object ready for display\n    \"\"\"\n    self._target_map = target_map\n    if target_map is not None:\n        self._prepare_target_map(target_map)\n    logger.info(\"Creating visualization\")\n\n    try:\n        # Determine visualization type based on available data and analysis\n        viz_type = self._determine_viz_type(plan, data, analysis)\n\n        if viz_type == \"raster_layer\":\n            return self._create_raster_visualization(plan, data, analysis)\n        elif viz_type == \"vector_layer\":\n            return self._create_vector_visualization(plan, data, analysis)\n        elif viz_type == \"analysis_result\":\n            return self._create_analysis_visualization(plan, data, analysis)\n        elif viz_type == \"time_series\":\n            return self._create_time_series_visualization(plan, data, analysis)\n        elif viz_type == \"split_map\":\n            return self._create_split_map_visualization(plan, data, analysis)\n        else:\n            return self._create_default_visualization(plan, data, analysis)\n\n    except Exception as e:\n        logger.error(f\"Visualization creation failed: {e}\")\n        return self._create_error_visualization(str(e))\n</code></pre>"},{"location":"viz_agent/#geoagent.core.viz_agent.create_map","title":"<code>create_map(target_map=None, **kwargs)</code>","text":"<p>Create a MapLibre map object (real if available, otherwise mock).</p> <p>Parameters:</p> Name Type Description Default <code>target_map</code> <p>If provided, return this map instead of creating a new one. Allows rendering on an existing map widget (e.g., the Solara UI map).</p> <code>None</code> <code>**kwargs</code> <p>Passed to MapLibreMap or MockMapLibreMap constructors.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Map object for visualization.</p> Source code in <code>geoagent/core/viz_agent.py</code> <pre><code>def create_map(target_map=None, **kwargs):\n    \"\"\"Create a MapLibre map object (real if available, otherwise mock).\n\n    Args:\n        target_map: If provided, return this map instead of creating a new one.\n            Allows rendering on an existing map widget (e.g., the Solara UI map).\n        **kwargs: Passed to MapLibreMap or MockMapLibreMap constructors.\n\n    Returns:\n        Map object for visualization.\n    \"\"\"\n    if target_map is not None:\n        return target_map\n    if MAPLIBRE_AVAILABLE:\n        kwargs[\"add_sidebar\"] = True\n        kwargs[\"sidebar_visible\"] = False\n        kwargs[\"add_floating_sidebar\"] = False\n        return MapLibreMap(**kwargs)\n    else:\n        return MockMapLibreMap(**kwargs)\n</code></pre>"},{"location":"examples/intro/","title":"Intro","text":"In\u00a0[\u00a0]: Copied! <pre># %pip install geoagent\n</pre> # %pip install geoagent In\u00a0[\u00a0]: Copied! <pre>import geoagent\n\nprint(f\"GeoAgent version: {geoagent.__version__}\")\n</pre> import geoagent  print(f\"GeoAgent version: {geoagent.__version__}\") In\u00a0[\u00a0]: Copied! <pre>from geoagent.core.llm import get_available_providers, check_api_keys\n\nprint(\"Available providers:\", get_available_providers())\nprint(\"API key status:\", check_api_keys())\n</pre> from geoagent.core.llm import get_available_providers, check_api_keys  print(\"Available providers:\", get_available_providers()) print(\"API key status:\", check_api_keys()) In\u00a0[\u00a0]: Copied! <pre>from geoagent import GeoAgent\n\n# Use any available provider:\n# agent = GeoAgent()  # auto-detect\n# agent = GeoAgent(provider=\"openai\", model=\"gpt-4.1\")\n# agent = GeoAgent(provider=\"anthropic\", model=\"claude-sonnet-4-5-20250929\")\n# agent = GeoAgent(provider=\"google\", model=\"gemini-2.5-flash\")\nagent = GeoAgent(provider=\"ollama\", model=\"llama3.1\")\n</pre> from geoagent import GeoAgent  # Use any available provider: # agent = GeoAgent()  # auto-detect # agent = GeoAgent(provider=\"openai\", model=\"gpt-4.1\") # agent = GeoAgent(provider=\"anthropic\", model=\"claude-sonnet-4-5-20250929\") # agent = GeoAgent(provider=\"google\", model=\"gemini-2.5-flash\") agent = GeoAgent(provider=\"ollama\", model=\"llama3.1\") In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Show Sentinel-2 imagery of San Francisco in July 2025\")\nprint(\n    f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\"\n)\nresult.map\n</pre> result = agent.chat(\"Show Sentinel-2 imagery of San Francisco in July 2025\") print(     f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\" ) result.map In\u00a0[\u00a0]: Copied! <pre>print(result.code)\n</pre> print(result.code) In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\n    \"Find Sentinel-2 images of Tokyo with less than 10% cloud cover in March 2024\"\n)\nprint(f\"Success: {result.success} | Items: {result.data.total_items}\")\nif result.data.items:\n    for item in result.data.items[:3]:\n        cc = item[\"properties\"].get(\"eo:cloud_cover\", \"N/A\")\n        print(f\"  {item['id']}: cloud cover {cc}%\")\nresult.map\n</pre> result = agent.chat(     \"Find Sentinel-2 images of Tokyo with less than 10% cloud cover in March 2024\" ) print(f\"Success: {result.success} | Items: {result.data.total_items}\") if result.data.items:     for item in result.data.items[:3]:         cc = item[\"properties\"].get(\"eo:cloud_cover\", \"N/A\")         print(f\"  {item['id']}: cloud cover {cc}%\") result.map In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Compute NDVI for Knoxville Tennessee in July 2024\")\nprint(f\"Success: {result.success} | Time: {result.execution_time:.1f}s\")\nif result.analysis:\n    stats = result.analysis.result_data.get(\"ndvi_stats\", {})\n    if stats:\n        print(f\"NDVI mean: {stats['mean']:.3f}\")\n        print(f\"NDVI range: [{stats['min']:.3f}, {stats['max']:.3f}]\")\n        print(f\"Pixels analyzed: {stats['pixels']:,}\")\nresult.map\n</pre> result = agent.chat(\"Compute NDVI for Knoxville Tennessee in July 2024\") print(f\"Success: {result.success} | Time: {result.execution_time:.1f}s\") if result.analysis:     stats = result.analysis.result_data.get(\"ndvi_stats\", {})     if stats:         print(f\"NDVI mean: {stats['mean']:.3f}\")         print(f\"NDVI range: [{stats['min']:.3f}, {stats['max']:.3f}]\")         print(f\"Pixels analyzed: {stats['pixels']:,}\") result.map In\u00a0[\u00a0]: Copied! <pre>print(result.code)\n</pre> print(result.code) In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Show NDVI for the Amazon rainforest in August 2024\")\nprint(\n    f\"Success: {result.success} | Items: {result.data.total_items if result.data else 0}\"\n)\nif result.analysis:\n    stats = result.analysis.result_data.get(\"ndvi_stats\", {})\n    if stats and stats.get(\"mean\"):\n        print(f\"NDVI mean: {stats['mean']:.3f}\")\nresult.map\n</pre> result = agent.chat(\"Show NDVI for the Amazon rainforest in August 2024\") print(     f\"Success: {result.success} | Items: {result.data.total_items if result.data else 0}\" ) if result.analysis:     stats = result.analysis.result_data.get(\"ndvi_stats\", {})     if stats and stats.get(\"mean\"):         print(f\"NDVI mean: {stats['mean']:.3f}\") result.map In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Show land cover for Denver Colorado\")\nprint(\n    f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\"\n)\nif result.data.items:\n    print(f\"Collection: {result.data.items[0].get('collection')}\")\nresult.map\n</pre> result = agent.chat(\"Show land cover for Denver Colorado\") print(     f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\" ) if result.data.items:     print(f\"Collection: {result.data.items[0].get('collection')}\") result.map In\u00a0[\u00a0]: Copied! <pre>print(result.code)\n</pre> print(result.code) In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Show land cover for New York City\")\nprint(f\"Success: {result.success} | Items: {result.data.total_items}\")\nresult.map\n</pre> result = agent.chat(\"Show land cover for New York City\") print(f\"Success: {result.success} | Items: {result.data.total_items}\") result.map In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Show DEM for Grand Canyon\")\nprint(\n    f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\"\n)\nif result.data.items:\n    print(f\"Collection: {result.data.items[0].get('collection')}\")\nresult.map\n</pre> result = agent.chat(\"Show DEM for Grand Canyon\") print(     f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\" ) if result.data.items:     print(f\"Collection: {result.data.items[0].get('collection')}\") result.map In\u00a0[\u00a0]: Copied! <pre>print(result.code)\n</pre> print(result.code) In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Show elevation map of Mount Rainier\")\nprint(f\"Success: {result.success} | Items: {result.data.total_items}\")\nresult.map\n</pre> result = agent.chat(\"Show elevation map of Mount Rainier\") print(f\"Success: {result.success} | Items: {result.data.total_items}\") result.map In\u00a0[\u00a0]: Copied! <pre>result = agent.chat(\"Find Landsat images of Denver in June 2024\")\nprint(\n    f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\"\n)\nif result.data.items:\n    for item in result.data.items[:3]:\n        cc = item[\"properties\"].get(\"eo:cloud_cover\", \"N/A\")\n        print(f\"  {item['id']}: cloud cover {cc}%\")\nresult.map\n</pre> result = agent.chat(\"Find Landsat images of Denver in June 2024\") print(     f\"Success: {result.success} | Items: {result.data.total_items} | Time: {result.execution_time:.1f}s\" ) if result.data.items:     for item in result.data.items[:3]:         cc = item[\"properties\"].get(\"eo:cloud_cover\", \"N/A\")         print(f\"  {item['id']}: cloud cover {cc}%\") result.map In\u00a0[\u00a0]: Copied! <pre>print(result.code)\n</pre> print(result.code) In\u00a0[\u00a0]: Copied! <pre># African location\nresult = agent.chat(\"Show Sentinel-2 imagery of Lagos Nigeria in January 2024\")\nprint(f\"Lagos - Success: {result.success} | Items: {result.data.total_items}\")\nresult.map\n</pre> # African location result = agent.chat(\"Show Sentinel-2 imagery of Lagos Nigeria in January 2024\") print(f\"Lagos - Success: {result.success} | Items: {result.data.total_items}\") result.map In\u00a0[\u00a0]: Copied! <pre># European location\nresult = agent.chat(\"Show land cover for Paris France\")\nprint(f\"Paris - Success: {result.success} | Items: {result.data.total_items}\")\nresult.map\n</pre> # European location result = agent.chat(\"Show land cover for Paris France\") print(f\"Paris - Success: {result.success} | Items: {result.data.total_items}\") result.map In\u00a0[\u00a0]: Copied! <pre># Asian location\nresult = agent.chat(\"Show DEM for Mount Fuji\")\nprint(f\"Mount Fuji - Success: {result.success} | Items: {result.data.total_items}\")\nresult.map\n</pre> # Asian location result = agent.chat(\"Show DEM for Mount Fuji\") print(f\"Mount Fuji - Success: {result.success} | Items: {result.data.total_items}\") result.map In\u00a0[\u00a0]: Copied! <pre># Winter\nresult = agent.chat(\"Show Sentinel-2 imagery of Chicago in December 2023\")\nprint(\n    f\"Chicago Dec 2023 - Success: {result.success} | Items: {result.data.total_items}\"\n)\nresult.map\n</pre> # Winter result = agent.chat(\"Show Sentinel-2 imagery of Chicago in December 2023\") print(     f\"Chicago Dec 2023 - Success: {result.success} | Items: {result.data.total_items}\" ) result.map In\u00a0[\u00a0]: Copied! <pre># Summer\nresult = agent.chat(\"Show Sentinel-2 imagery of Chicago in July 2024\")\nprint(\n    f\"Chicago Jul 2024 - Success: {result.success} | Items: {result.data.total_items}\"\n)\nresult.map\n</pre> # Summer result = agent.chat(\"Show Sentinel-2 imagery of Chicago in July 2024\") print(     f\"Chicago Jul 2024 - Success: {result.success} | Items: {result.data.total_items}\" ) result.map In\u00a0[\u00a0]: Copied! <pre>data = agent.search(\n    \"Find Sentinel-2 images of Seattle in August 2024 with low cloud cover\"\n)\nprint(f\"Found {data.total_items} items\")\nprint(f\"Search params: {data.search_query}\")\nfor item in data.items[:5]:\n    cc = item[\"properties\"].get(\"eo:cloud_cover\", \"N/A\")\n    dt = item[\"properties\"].get(\"datetime\", \"\")\n    print(f\"  {item['id']}: {dt[:10]} cloud={cc}%\")\n</pre> data = agent.search(     \"Find Sentinel-2 images of Seattle in August 2024 with low cloud cover\" ) print(f\"Found {data.total_items} items\") print(f\"Search params: {data.search_query}\") for item in data.items[:5]:     cc = item[\"properties\"].get(\"eo:cloud_cover\", \"N/A\")     dt = item[\"properties\"].get(\"datetime\", \"\")     print(f\"  {item['id']}: {dt[:10]} cloud={cc}%\") In\u00a0[\u00a0]: Copied! <pre>from geoagent.catalogs.registry import CatalogRegistry\n\nreg = CatalogRegistry()\nfor cat in reg.list_catalogs():\n    auth = \" (auth required)\" if cat.requires_auth else \"\"\n    print(f\"{cat.name:25s} {cat.url}{auth}\")\n</pre> from geoagent.catalogs.registry import CatalogRegistry  reg = CatalogRegistry() for cat in reg.list_catalogs():     auth = \" (auth required)\" if cat.requires_auth else \"\"     print(f\"{cat.name:25s} {cat.url}{auth}\") In\u00a0[\u00a0]: Copied! <pre># Direct STAC search via registry\nclient = reg.get_client(\"planetary_computer\")\n\nresults = client.search(\n    collections=[\"cop-dem-glo-30\"],\n    bbox=[-112.2, 36.0, -111.8, 36.3],  # Grand Canyon\n    max_items=3,\n)\n\nitems = list(results.items())\nprint(f\"Found {len(items)} DEM tiles:\")\nfor item in items:\n    print(f\"  {item.id}: bbox={item.bbox}\")\n</pre> # Direct STAC search via registry client = reg.get_client(\"planetary_computer\")  results = client.search(     collections=[\"cop-dem-glo-30\"],     bbox=[-112.2, 36.0, -111.8, 36.3],  # Grand Canyon     max_items=3, )  items = list(results.items()) print(f\"Found {len(items)} DEM tiles:\") for item in items:     print(f\"  {item.id}: bbox={item.bbox}\")"},{"location":"examples/intro/#getting-started-with-geoagent","title":"Getting Started with GeoAgent\u00b6","text":"<p>This notebook demonstrates the core features of GeoAgent \u2014 an AI agent for geospatial data search, analysis, and visualization. It covers multiple data types, locations, time ranges, and analysis workflows.</p>"},{"location":"examples/intro/#setup","title":"Setup\u00b6","text":""},{"location":"examples/intro/#1-sentinel-2-satellite-imagery","title":"1. Sentinel-2 Satellite Imagery\u00b6","text":"<p>Search for Sentinel-2 images over a specific location and time range.</p>"},{"location":"examples/intro/#sentinel-2-with-cloud-cover-filter","title":"Sentinel-2 with cloud cover filter\u00b6","text":""},{"location":"examples/intro/#2-ndvi-analysis","title":"2. NDVI Analysis\u00b6","text":"<p>Compute real NDVI from Sentinel-2 red and NIR bands.</p>"},{"location":"examples/intro/#ndvi-for-a-different-location","title":"NDVI for a different location\u00b6","text":""},{"location":"examples/intro/#3-land-cover-esri-10m","title":"3. Land Cover (ESRI 10m)\u00b6","text":"<p>Visualize land use / land cover data from the ESRI 10m annual dataset (Planetary Computer <code>io-lulc-9-class</code> collection).</p>"},{"location":"examples/intro/#land-cover-for-another-location","title":"Land cover for another location\u00b6","text":""},{"location":"examples/intro/#4-digital-elevation-model-dem","title":"4. Digital Elevation Model (DEM)\u00b6","text":"<p>Visualize elevation data from the Copernicus DEM 30m dataset (Planetary Computer <code>cop-dem-glo-30</code> collection).</p>"},{"location":"examples/intro/#elevation-for-another-location","title":"Elevation for another location\u00b6","text":""},{"location":"examples/intro/#5-landsat-imagery","title":"5. Landsat Imagery\u00b6","text":"<p>Search for Landsat Collection 2 Level-2 data.</p>"},{"location":"examples/intro/#6-different-locations","title":"6. Different Locations\u00b6","text":"<p>GeoAgent automatically geocodes place names to bounding boxes.</p>"},{"location":"examples/intro/#7-different-time-ranges","title":"7. Different Time Ranges\u00b6","text":""},{"location":"examples/intro/#8-data-search-only","title":"8. Data Search Only\u00b6","text":"<p>Use <code>agent.search()</code> to search for data without analysis or visualization.</p>"},{"location":"examples/intro/#9-stac-catalog-registry","title":"9. STAC Catalog Registry\u00b6","text":"<p>Browse and use pre-configured STAC catalog endpoints.</p>"},{"location":"examples/intro/#summary","title":"Summary\u00b6","text":"Data Type Collection Example Query Sentinel-2 Imagery <code>sentinel-2-l2a</code> \"Show Sentinel-2 imagery of Tokyo in March 2024\" Landsat Imagery <code>landsat-c2-l2</code> \"Find Landsat images of Denver in June 2024\" NDVI Analysis <code>sentinel-2-l2a</code> \"Compute NDVI for Knoxville in July 2024\" Land Cover (ESRI) <code>io-lulc-9-class</code> \"Show land cover for Denver\" DEM / Elevation <code>cop-dem-glo-30</code> \"Show DEM for Grand Canyon\""},{"location":"examples/maplibre_viz/","title":"Maplibre viz","text":"In\u00a0[\u00a0]: Copied! <pre># %pip install geoagent\n</pre> # %pip install geoagent In\u00a0[\u00a0]: Copied! <pre>from leafmap.maplibregl import Map\n\nm = Map(center=[-122.4194, 37.7749], zoom=10)\nm\n</pre> from leafmap.maplibregl import Map  m = Map(center=[-122.4194, 37.7749], zoom=10) m In\u00a0[\u00a0]: Copied! <pre>m = Map(center=[-122.4194, 37.7749], zoom=10)\n\nurl = (\n    \"https://github.com/opengeos/datasets/releases/download/raster/Libya-2023-07-01.tif\"\n)\nm.add_cog_layer(url, name=\"Libya Satellite\")\nm\n</pre> m = Map(center=[-122.4194, 37.7749], zoom=10)  url = (     \"https://github.com/opengeos/datasets/releases/download/raster/Libya-2023-07-01.tif\" ) m.add_cog_layer(url, name=\"Libya Satellite\") m In\u00a0[\u00a0]: Copied! <pre>m = Map(center=[-100, 40], zoom=3)\n\ngeojson_url = \"https://d2ad6b4ur7yvpq.cloudfront.net/naturalearth-3.3.0/ne_110m_admin_1_states_provinces_lines.geojson\"\nm.add_geojson(geojson_url, name=\"US States\")\nm\n</pre> m = Map(center=[-100, 40], zoom=3)  geojson_url = \"https://d2ad6b4ur7yvpq.cloudfront.net/naturalearth-3.3.0/ne_110m_admin_1_states_provinces_lines.geojson\" m.add_geojson(geojson_url, name=\"US States\") m In\u00a0[\u00a0]: Copied! <pre>m = Map(center=[0, 20], zoom=2)\n\npmtiles_url = \"https://pmtiles.io/protomaps(vector)ODbL_firenze.pmtiles\"\n# m.add_pmtiles(pmtiles_url, name=\"Firenze\")\nm\n</pre> m = Map(center=[0, 20], zoom=2)  pmtiles_url = \"https://pmtiles.io/protomaps(vector)ODbL_firenze.pmtiles\" # m.add_pmtiles(pmtiles_url, name=\"Firenze\") m In\u00a0[\u00a0]: Copied! <pre>from geoagent.catalogs.registry import CatalogRegistry\n\nreg = CatalogRegistry()\nclient = reg.get_client(\"earth_search\")\n\nresults = client.search(\n    collections=[\"sentinel-2-l2a\"],\n    bbox=[-122.5, 37.5, -122.0, 38.0],\n    datetime=\"2024-07-01/2024-07-31\",\n    max_items=1,\n)\n\nitems = list(results.items())\nif items:\n    item = items[0]\n    print(f\"Item: {item.id}\")\n    print(f\"Visual asset: {item.assets.get('visual', {})}\")\n</pre> from geoagent.catalogs.registry import CatalogRegistry  reg = CatalogRegistry() client = reg.get_client(\"earth_search\")  results = client.search(     collections=[\"sentinel-2-l2a\"],     bbox=[-122.5, 37.5, -122.0, 38.0],     datetime=\"2024-07-01/2024-07-31\",     max_items=1, )  items = list(results.items()) if items:     item = items[0]     print(f\"Item: {item.id}\")     print(f\"Visual asset: {item.assets.get('visual', {})}\") In\u00a0[\u00a0]: Copied! <pre>if items and \"visual\" in item.assets:\n    m = Map(center=[-122.25, 37.75], zoom=10)\n    m.add_cog_layer(item.assets[\"visual\"].href, name=item.id)\n    m\n</pre> if items and \"visual\" in item.assets:     m = Map(center=[-122.25, 37.75], zoom=10)     m.add_cog_layer(item.assets[\"visual\"].href, name=item.id)     m"},{"location":"examples/maplibre_viz/#maplibre-visualization","title":"MapLibre Visualization\u00b6","text":"<p>This notebook demonstrates GeoAgent's visualization capabilities using leafmap's MapLibre backend.</p>"},{"location":"examples/maplibre_viz/#create-a-basic-map","title":"Create a Basic Map\u00b6","text":""},{"location":"examples/maplibre_viz/#add-a-cog-layer","title":"Add a COG Layer\u00b6","text":"<p>Load a Cloud-Optimized GeoTIFF directly on the map:</p>"},{"location":"examples/maplibre_viz/#add-geojson-data","title":"Add GeoJSON Data\u00b6","text":""},{"location":"examples/maplibre_viz/#add-pmtiles-layer","title":"Add PMTiles Layer\u00b6","text":""},{"location":"examples/maplibre_viz/#stac-search-and-visualization","title":"STAC Search and Visualization\u00b6","text":"<p>Search for data and display it on a map:</p>"},{"location":"examples/stac_search/","title":"Stac search","text":"In\u00a0[\u00a0]: Copied! <pre># %pip install geoagent\n</pre> # %pip install geoagent In\u00a0[\u00a0]: Copied! <pre>from geoagent.catalogs.registry import CatalogRegistry\n\nreg = CatalogRegistry()\nfor cat in reg.list_catalogs():\n    auth = \"(auth required)\" if cat.requires_auth else \"\"\n    print(f\"{cat.name:25s} {cat.url} {auth}\")\n</pre> from geoagent.catalogs.registry import CatalogRegistry  reg = CatalogRegistry() for cat in reg.list_catalogs():     auth = \"(auth required)\" if cat.requires_auth else \"\"     print(f\"{cat.name:25s} {cat.url} {auth}\") In\u00a0[\u00a0]: Copied! <pre>client = reg.get_client(\"earth_search\")\nprint(f\"Connected to: {client.title or client.id}\")\n\nresults = client.search(\n    collections=[\"sentinel-2-l2a\"],\n    bbox=[-122.5, 37.5, -122.0, 38.0],\n    datetime=\"2024-07-01/2024-07-31\",\n    max_items=5,\n)\n\nitems = list(results.items())\nprint(f\"\\nFound {len(items)} items:\")\nfor item in items:\n    print(f\"  {item.id}: {item.datetime}\")\n</pre> client = reg.get_client(\"earth_search\") print(f\"Connected to: {client.title or client.id}\")  results = client.search(     collections=[\"sentinel-2-l2a\"],     bbox=[-122.5, 37.5, -122.0, 38.0],     datetime=\"2024-07-01/2024-07-31\",     max_items=5, )  items = list(results.items()) print(f\"\\nFound {len(items)} items:\") for item in items:     print(f\"  {item.id}: {item.datetime}\") In\u00a0[\u00a0]: Copied! <pre>if items:\n    item = items[0]\n    print(f\"Item: {item.id}\")\n    print(f\"Datetime: {item.datetime}\")\n    print(f\"Bbox: {item.bbox}\")\n    print(f\"\\nAssets:\")\n    for name, asset in item.assets.items():\n        print(f\"  {name}: {asset.title or 'N/A'}\")\n</pre> if items:     item = items[0]     print(f\"Item: {item.id}\")     print(f\"Datetime: {item.datetime}\")     print(f\"Bbox: {item.bbox}\")     print(f\"\\nAssets:\")     for name, asset in item.assets.items():         print(f\"  {name}: {asset.title or 'N/A'}\") In\u00a0[\u00a0]: Copied! <pre>pc_client = reg.get_client(\"planetary_computer\")\n\nresults = pc_client.search(\n    collections=[\"landsat-c2-l2\"],\n    bbox=[-105.3, 39.9, -104.9, 40.1],  # Denver, CO\n    datetime=\"2024-06-01/2024-06-30\",\n    max_items=3,\n)\n\nitems = list(results.items())\nprint(f\"Found {len(items)} Landsat items near Denver:\")\nfor item in items:\n    cloud = item.properties.get(\"eo:cloud_cover\", \"N/A\")\n    print(f\"  {item.id}: {item.datetime} (cloud: {cloud}%)\")\n</pre> pc_client = reg.get_client(\"planetary_computer\")  results = pc_client.search(     collections=[\"landsat-c2-l2\"],     bbox=[-105.3, 39.9, -104.9, 40.1],  # Denver, CO     datetime=\"2024-06-01/2024-06-30\",     max_items=3, )  items = list(results.items()) print(f\"Found {len(items)} Landsat items near Denver:\") for item in items:     cloud = item.properties.get(\"eo:cloud_cover\", \"N/A\")     print(f\"  {item.id}: {item.datetime} (cloud: {cloud}%)\") In\u00a0[\u00a0]: Copied! <pre>reg.add_catalog(\n    name=\"my_stac\",\n    url=\"https://earth-search.aws.element84.com/v1\",\n    description=\"My custom STAC endpoint\",\n)\n\nprint(f\"Total catalogs: {len(reg.list_catalogs())}\")\ncat = reg.get_catalog(\"my_stac\")\nprint(f\"Custom catalog URL: {cat.url}\")\n</pre> reg.add_catalog(     name=\"my_stac\",     url=\"https://earth-search.aws.element84.com/v1\",     description=\"My custom STAC endpoint\", )  print(f\"Total catalogs: {len(reg.list_catalogs())}\") cat = reg.get_catalog(\"my_stac\") print(f\"Custom catalog URL: {cat.url}\")"},{"location":"examples/stac_search/#stac-catalog-search","title":"STAC Catalog Search\u00b6","text":"<p>This notebook demonstrates how to search STAC catalogs using GeoAgent's catalog registry and search tools.</p>"},{"location":"examples/stac_search/#browse-available-catalogs","title":"Browse Available Catalogs\u00b6","text":""},{"location":"examples/stac_search/#search-earth-search-aws","title":"Search Earth Search (AWS)\u00b6","text":"<p>Search for Sentinel-2 imagery over San Francisco:</p>"},{"location":"examples/stac_search/#inspect-item-assets","title":"Inspect Item Assets\u00b6","text":""},{"location":"examples/stac_search/#search-planetary-computer","title":"Search Planetary Computer\u00b6","text":""},{"location":"examples/stac_search/#add-a-custom-catalog","title":"Add a Custom Catalog\u00b6","text":""}]}